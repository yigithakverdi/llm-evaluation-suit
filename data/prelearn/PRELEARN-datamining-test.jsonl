{"wikipedia_passage_concept_A": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_A": "Rete bayesiana", "wikipedia_passage_concept_B": ["40388", "Funzione di densit\u00e0 di probabilit\u00e0", "In matematica, una funzione di densit\u00e0 di probabilit\u00e0 (o PDF dall'inglese \"probability density function\") \u00e8 l'analogo della funzione di probabilit\u00e0 di una variabile casuale nel caso in cui la variabile casuale formula_1 sia continua, cio\u00e8 l'insieme dei possibili valori che ha la potenza del continuo.\nEssa descrive la \"densit\u00e0\" di probabilit\u00e0 in ogni punto nello spazio campionario.\nLa funzione di densit\u00e0 di probabilit\u00e0 di una variabile casuale formula_1 \u00e8 un'applicazione formula_3 non negativa integrabile secondo Lebesgue e reale di variabile reale tale che la probabilit\u00e0 dell'insieme \"A\" sia data da\nper tutti i sottinsiemi \"A\" dello spazio campionario.\nIntuitivamente, se una distribuzione di probabilit\u00e0 ha densit\u00e0 formula_3, allora l'intervallo formula_6 ha probabilit\u00e0 formula_7. Da ci\u00f2 deriva che la funzione formula_3 \u00e8 un'applicazione definita come\nAssumendo formula_10, ci\u00f2 corrisponde al limite della probabilit\u00e0 che formula_11 si trovi nell'intervallo formula_6 per formula_13 che tende a zero. Di qui il nome di funzione di 'densit\u00e0', in quanto essa rappresenta il rapporto tra una probabilit\u00e0 e un'ampiezza.\nPer la condizione di normalizzazione l'integrale su tutto lo spazio di formula_3 deve essere 1. Di conseguenza ogni funzione non negativa, integrabile secondo Lebesgue, con integrale su tutto lo spazio uguale a 1, \u00e8 la funzione densit\u00e0 di probabilit\u00e0 di una ben definita distribuzione di probabilit\u00e0. Una variabile casuale che possiede densit\u00e0 si dice \"variabile casuale continua\".\nPer le variabili casuali multivariate (o vettoriali) la trattazione formale \u00e8 assolutamente identica: formula_15 si dice assolutamente continua se esiste una funzione a valori reali definita in formula_16, detta densit\u00e0 congiunta, tale che per ogni sottoinsieme \"A\" dello spazio campionario\nEssa conserva tutte le propriet\u00e0 di una densit\u00e0 scalare: \u00e8 una funzione non negativa a integrale unitario su tutto lo spazio. Una propriet\u00e0 importante \u00e8 che se formula_15 \u00e8 assolutamente continua allora lo \u00e8 ogni sua componente; il viceversa invece non vale. La densit\u00e0 di una componente, detta densit\u00e0 marginale, si ottiene con un ragionamento analogo al teorema della probabilit\u00e0 assoluta, cio\u00e8 fissando l'insieme di suoi valori di cui si vuole determinare la probabilit\u00e0 e lasciando libere di variare tutte le altre componenti. Infatti (nel caso bivariato per semplicit\u00e0) l'evento formula_19 \u00e8 l'evento formula_20, dunque\nutilizzando il teorema di Fubini. La densit\u00e0 marginale di formula_1 \u00e8 data dunque da\nLa funzione di densit\u00e0 della variabile casuale normale di media 0\ne varianza 1 (detta \"normale standard\"), di cui a destra \u00e8 riportato il grafico e l'espressione analitica della corrispondente densit\u00e0 nel caso generico (media formula_24 e varianza formula_25).\nUn altro esempio pu\u00f2 essere dato dalla densit\u00e0 di probabilit\u00e0 uniforme su un segmento (0,1). Si pu\u00f2 verificare immediatamente che \u00e8 densit\u00e0 di probabilit\u00e0 facendo l'integrale tra (0,1)."], "concept_B": "Funzione di densit\u00e0 di probabilit\u00e0", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_A": "Data mining", "wikipedia_passage_concept_B": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_B": "Outlier", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1103542", "K-medoids", "\u00e8 un algoritmo di clustering partizionale correlato all'algoritmo K-means. Prevede in input un insieme di n oggetti e un numero k che determina quanti cluster si vogliono in output.\nEntrambi gli algoritmi sono partizionali (suddividendo il dataset in gruppi) ed entrambi cercano di minimizzare l'errore quadratico medio, la distanza tra punti di un cluster e il punto designato per esserne il centro. In K-means il punto \u00e8 \"artificiale\" \u2014 \u00e8 la pura media di tutti i punti nel cluster. Nel K-medoids \u00e8 usato il punto collocato pi\u00f9 centralmente, in questo modo il centro \u00e8 uno dei datapoint attuali. K-medoids \u00e8 pi\u00f9 robusto al rumore e agli outlier rispetto al k-means.\nUn medoid pu\u00f2 essere definito come un oggetto di un cluster la cui dissimilarit\u00e0 media rispetto a tutti gli oggetti nel cluster \u00e8 minima, in questo modo esso sar\u00e0 il punto pi\u00f9 centrale di un dato dataset.\nL'algoritmo di clustering \u00e8 il seguente:\nSi deve clusterizzare il seguente data set di 10 oggetti in 2 cluster, quindi n \u00e8 10 e k \u00e8 2:\nSi inizializzano i k centri.\nAssumiamo che C1=(3,4) e C2=(7,4) siano i nostri medoid iniziali.\nCalcoliamo la distanza cos\u00ec da associare ogni data object al suo medoid pi\u00f9 vicino.\nIniziamo quindi il clustering:\nEssendo (3,4) (2,6) (3,8) e (4,7) punti vicini a c1 essi formeranno un cluster mentre i punti rimanenti ne formeranno un altro.\nIl costo totale sar\u00e0 20.\nIl costo tra 2 punti qualsiasi \u00e8 trovato usando la formula\nformula_1\nIl costo totale \u00e8 la somma dei costi per gli oggetti dal proprio medoid.\nCosto totale= {cost((3,4),(2,6)) + cost((3,4),(3,8)) + cost((3,4),(4,7))} + {cost((7,4),(6,2)) + cost((7,4),(6,4)) + cost((7,4),(7,3)) + cost((7,4),(8,5)) + cost((7,4),(7,6))} = 3 + 4 + 4 + 3 + 1 + 1 + 2 + 2 = 20\nSelezione di un nonmedoid O' in modo casuale.\nAssumiamo O'=(7,3)\nI medoid sono quindi c1(3,4) e O'(7,3).\nSe c1 e O' sono nuovi medoid, si calcola il costo totale usando la formula al passo 1.\nCosto totale = 3 + 4 + 4 + 2 + 2 + 1 + 3 + 3 = 22\nCos\u00ec il costo per cambiare il medoid da c2 a O' sar\u00e0:\nS = Costo totale attuale \u2013 Costo totale precedente = 22 - 20 = 2 > 0\nQuindi cambiare medoid in O' non \u00e8 una buona idea, la scelta precedente \u00e8 stata buona e l'algoritmo termina in questo punto (in quanto non ci sono cambiamenti per i medoid).\nPu\u00f2 accadere che qualche data point possa migrare da un cluster ad un altro, ci\u00f2 dipende dalla vicinanza rispetto al nuovo medoid scelto."], "concept_A": "K-medoids", "wikipedia_passage_concept_B": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_B": "Clustering", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_A": "K-means", "wikipedia_passage_concept_B": ["605", "Apprendimento automatico", "L\u2019apprendimento automatico (noto anche come machine learning) \u00e8 una branca dell'intelligenza artificiale che raccoglie un insieme di metodi, sviluppati a partire dagli ultimi decenni del XX secolo in varie comunit\u00e0 scientifiche, sotto diversi nomi quali: statistica computazionale, riconoscimento di pattern, reti neurali artificiali, filtraggio adattivo, teoria dei sistemi dinamici, elaborazione delle immagini, data mining, algoritmi adattivi, ecc; che utilizza metodi statistici per migliorare progressivamente la performance di un algoritmo nell'identificare pattern nei dati. Nell'ambito dell'informatica, l'apprendimento automatico \u00e8 una variante alla programmazione tradizionale nella quale si predispone in una macchina l'abilit\u00e0 di apprendere qualcosa dai dati in maniera autonoma, senza ricevere istruzioni esplicite a riguardo.\nLo stesso Arthur Samuel che coni\u00f2 il termine nel 1959 in linea di principio identifica due approcci distinti. Il primo metodo, indicato come rete neurale, porta allo sviluppo di macchine ad apprendimento automatico per impiego generale in cui il comportamento \u00e8 appreso da una rete di commutazione connessa casualmente, a seguito di una routine di apprendimento basata su ricompensa e punizione (apprendimento per rinforzo). Il secondo metodo, pi\u00f9 specifico, consiste nel riprodurre l'equivalente di una rete altamente organizzata progettata per imparare solo alcune attivit\u00e0 specifiche. La seconda procedura, che necessita di supervisione, richiede la riprogrammazione per ogni nuova applicazione, ma risulta essere molto pi\u00f9 efficiente dal punto di vista computazionale.\nL'apprendimento automatico \u00e8 strettamente legato al riconoscimento di pattern e alla teoria computazionale dell'apprendimento ed esplora lo studio e la costruzione di algoritmi che possano apprendere da un insieme di dati e fare delle predizioni su questi, costruendo in modo induttivo un modello basato su dei campioni. L'apprendimento automatico viene impiegato in quei campi dell'informatica nei quali progettare e programmare algoritmi espliciti \u00e8 impraticabile; tra le possibili applicazioni citiamo il filtraggio delle email per evitare spam, l'individuazione di intrusioni in una rete o di intrusi che cercano di violare dati, il riconoscimento ottico dei caratteri, i motori di ricerca e la visione artificiale.\nL'apprendimento automatico \u00e8 strettamente collegato, e spesso si sovrappone con la statistica computazionale, che si occupa dell'elaborazione di predizioni tramite l'uso di computer. L'apprendimento automatico \u00e8 anche fortemente legato all'ottimizzazione matematica, che fornisce metodi, teorie e domini di applicazione a questo campo. Per usi commerciali, l'apprendimento automatico \u00e8 conosciuto come analisi predittiva.\nL'apprendimento automatico si sviluppa con lo studio dell'intelligenza artificiale, e vi \u00e8 strettamente collegato: infatti gi\u00e0 dai primi tentativi di definire l'intelligenza artificiale come disciplina accademica, alcuni ricercatori si erano mostrati interessati alla possibilit\u00e0 che le macchine imparassero dai dati. Questi ricercatori, in particolare Marvin Minsky, Arthur Samuel e Frank Rosenblatt, provarono ad avvicinarsi al problema sia attraverso vari metodi formali, sia con quelle che vengono definite reti neurali nei tardi anni '50. Le reti neurali erano allora costituite da singoli percettroni e da modelli matematici derivati dal modello lineare generalizzato della statistica, come l'ADALINE di Widrow. Si prov\u00f2 a sfruttare anche ragionamenti probabilistici, in particolare nelle diagnosi mediche automatiche.\nSempre negli anni '50, Alan Turing propose l'idea di una \"macchina che apprende\", ovvero in grado di imparare e dunque diventare intelligente. La proposta specifica di Turing anticipa gli algoritmi genetici.\nTuttavia gi\u00e0 dalla met\u00e0 degli anni '50 lo studio dell'intelligenza artificiale si stava concentrando su approcci logici di tipo \"knowledge-based\", nota oggi sotto il nome di GOFAI, causando un distacco tra lo studio dell'IA e quello dell'apprendimento automatico. Sistemi di tipo probabilistico erano invasi di problemi sia teoretici sia pratici in termini di acquisizione e rappresentazione dei dati. Negli anni Ottanta, i sistemi esperti dominavano il campo dell'IA, e i sistemi basati sulla statistica non venivano pi\u00f9 studiati.\nLo studio dell'apprendimento simbolico e \"knowledge-based\" continu\u00f2 nell'ambito dell'IA, portando a sviluppare la programmazione logica induttiva, ma ora la ricerca pi\u00f9 prettamente statistica si svolgeva al di fuori del campo vero e proprio dell'intelligenza artificiale, nel riconoscimento di pattern e nell'information retrieval.\nUn altro motivo per cui lo studio dell'apprendimento automatico fu abbandonato fu la pubblicazione del libro \"Perceptrons: an introduction to computational geometry\" di Marvin Minsky e Seymour Papert, che vi descrivevano alcune delle limitazioni dei percettroni e delle reti neurali. La ricerca sulle reti neurali sub\u00ec un significativo rallentamento a causa dell'interpretazione del libro, che le descriveva come intrinsecamente limitate. Anche la linea di ricerca sulle reti neurali continu\u00f2 al di fuori del campo dell'IA, portata avanti da ricercatori provenienti da altre discipline quali Hopfield, Rumelhart, Hinton e Fukushima. Il loro successo principale fu a met\u00e0 degli anni '80 con la riscoperta della \"backpropagation\" e della self-organization.\nL'apprendimento automatico, sviluppatosi come campo di studi separato dall'IA classica, cominci\u00f2 a rifiorire negli anni '90. Il suo obiettivo cambi\u00f2 dall'ottenere l'intelligenza artificiale ad affrontare problemi risolvibili di natura pratica. Distolse inoltre la propria attenzione dagli approcci simbolici che aveva ereditato dall'IA, e si diresse verso metodi e modelli presi in prestito dalla statistica e dalla teoria della probabilit\u00e0. L'apprendimento automatico ha inoltre beneficiato dalla nascita di Internet, che ha reso l'informazione digitale pi\u00f9 facilmente reperibile e distribuibile.\nTom M. Mitchell ha fornito la definizione pi\u00f9 citata di apprendimento automatico nel suo libro \"\"Machine Learning\"\": \"\"Si dice che un programma apprende dall'esperienza E con riferimento a alcune classi di compiti T e con misurazione della performance P, se le sue performance nel compito T, come misurato da P, migliorano con l'esperienza E.\"\" In poche parole, si potrebbe semplificare dicendo che un programma apprende se c'\u00e8 un miglioramento delle prestazioni dopo un compito svolto. Questa definizione di Mitchell \u00e8 rilevante poich\u00e9 fornisce una definizione operativa dell'apprendimento automatico, invece che in termini cognitivi. Fornendo questa definizione, Mitchell di fatto segue la proposta che Alan Turing fece nel suo articolo \"\"Computing Machinery and Intelligence\"\", sostituendo la domanda \"\"Le macchine possono pensare?\"\" con la domanda \"\"Le macchine possono fare quello che noi (in quanto entit\u00e0 pensanti) possiamo fare?\"\".\nL'obiettivo principe dell'apprendimento automatico \u00e8 che una macchina sia in grado di generalizzare dalla propria esperienza, ossia che sia in grado di svolgere ragionamenti induttivi. In questo contesto, per generalizzazione si intende l'abilit\u00e0 di una macchina di portare a termine in maniera accurata esempi o compiti nuovi, che non ha mai affrontato, dopo aver fatto esperienza su un insieme di dati di apprendimento. Gli esempi di addestramento (in inglese chiamati \"training examples\") si assume provengano da una qualche distribuzione di probabilit\u00e0, generalmente sconosciuta e considerata rappresentativa dello spazio delle occorrenze del fenomeno da apprendere; la macchina ha il compito di costruire un modello probabilistico generale dello spazio delle occorrenze, in maniera tale da essere in grado di produrre previsioni sufficientemente accurate quando sottoposta a nuovi casi.\nL'analisi computazionale degli algoritmi di apprendimento automatico e delle loro prestazioni \u00e8 una branca dell'Informatica teorica chiamata teoria dell'apprendimento. Dato che gli esempi di addestramento sono insiemi finiti di dati e non c'\u00e8 modo di sapere l'evoluzione futura di un modello, la teoria dell'apprendimento non offre alcuna garanzia sulle prestazioni degli algoritmi. D'altro canto, \u00e8 piuttosto comune che tali prestazioni siano vincolate da limiti probabilistici. Il bias-variance tradeoff \u00e8 uno dei modi di quantificare l'errore di generalizzazione.\nAffinch\u00e9 la generalizzazione offra le migliori prestazioni possibili, la complessit\u00e0 dell'ipotesi induttiva deve essere pari alla complessit\u00e0 della funzione sottostante i dati. Se l'ipotesi \u00e8 meno complessa della funzione, allora il modello manifesta \"underfitting\". Quando la complessit\u00e0 del modello viene aumentata in risposta, allora l'errore di apprendimento diminuisce. Al contrario invece se l'ipotesi \u00e8 troppo complessa, allora il modello manifesta overfitting e la generalizzazione sar\u00e0 pi\u00f9 scarsa.\nOltre ai limiti di prestazioni, i teorici dell'apprendimento studiano la complessit\u00e0 temporale e la fattibilit\u00e0 dell'apprendimento stesso. Una computazione \u00e8 considerata fattibile se pu\u00f2 essere svolta in tempo polinomiale.\nI compiti dell'apprendimento automatico vengono tipicamente classificati in tre ampie categorie, a seconda della natura del \"segnale\" utilizzato per l'apprendimento o del \"feedback\" disponibile al sistema di apprendimento. Queste categorie, anche dette paradigmi, sono:\nA met\u00e0 strada tra l'apprendimento supervisionato e quello non supervisionato c'\u00e8 l'apprendimento semi-supervisionato, nel quale l'insegnante fornisce un dataset incompleto per l'allenamento, cio\u00e8 un insieme di dati per l'allenamento tra i quali ci sono dati senza il rispettivo output desiderato. La trasduzione \u00e8 un caso speciale di questo principio, nel quale l'intero insieme delle istanze del problema \u00e8 noto durante l'apprendimento, eccetto la parte degli output desiderati che \u00e8 mancante.\nUn'altra categorizzazione dei compiti dell'apprendimento automatico si rileva quando si considera l'output desiderato del sistema di apprendimento automatico.\nL'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo Michael I. Jordan, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. Jordan ha anche suggerito il termine data science come nome con cui chiamare l'intero campo di studi.\nLeo Breiman ha distinto due paradigmi statistici di modellazione: modello basato sui dati e modello basato sugli algoritmi, dove \"modello basato sugli algoritmi\" indica approssimativamente algoritmi di apprendimento automatico come la foresta casuale.\nAlcuni statistici hanno adottato metodi provenienti dall'apprendimento automatico, il che ha portato alla creazione di una disciplina combinata chiamata \"apprendimento statistico\".\nL'apprendimento automatico viene a volte unito al data mining, che si focalizza maggiormente sull'analisi esplorativa dei dati ed utilizza principalmente il paradigma di apprendimento chiamato \"apprendimento non supervisionato\". Invece, l'apprendimento automatico pu\u00f2 essere anche supervisionato.\nL'apprendimento automatico e il \"data mining\" infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su propriet\u00e0 note apprese dai dati, il data mining si concentra sulla scoperta di propriet\u00e0 prima \"sconosciute\" nei dati. Il data mining sfrutta i metodi dell'apprendimento automatico, ma con obiettivi differenti; d'altro canto, l'apprendimento automatico utilizza i metodi di data mining come metodi di apprendimento non supervisionato o come passi di preprocessing per aumentare l'accuratezza dell'apprendimento. Gran parte della confusione tra le due comunit\u00e0 di ricerca scaturisce dall'assunzione di base del loro operato: nell'apprendimento automatico, le prestazioni sono generalmente valutate in base all'abilit\u00e0 di riprodurre conoscenza gi\u00e0 acquisita, mentre in data mining il compito chiave \u00e8 la scoperta di conoscenza che prima non si aveva.\nL'apprendimento automatico ha legami molto stretti con l'ottimizzazione: molti problemi di apprendimento sono formulati come la minimizzazione di una qualche funzione di costo su un insieme di esempi di apprendimento. La funzione di costo (o funzione di perdita) rappresenta la discrepanza tra le previsioni del modello che si sta addestrando e le istanze del problema reale. Le differenze tra i due campi (l'apprendimento automatico e l'ottimizzazione) sorgono dall'obiettivo della generalizzazione: mentre gli algoritmi di ottimizzazione possono minimizzare la perdita su un insieme di apprendimento, l'apprendimento automatico si preoccupa di minimizzare la perdita su campioni mai visti dalla macchina.\nLa risoluzione automatica di problemi avviene, nel campo dell'informatica, in due modi differenti: tramite paradigmi di \"hard computing\" o tramite paradigmi di \"soft computing\". Per \"hard computing\" si intende la risoluzione di un problema tramite l'esecuzione di un algoritmo ben definito e decidibile. La maggior parte dei paradigmi di \"hard computing\" sono metodi ormai consolidati, ma presentano alcuni lati negativi: infatti richiedono sempre un modello analitico preciso e definibile, e spesso un alto tempo di computazione. \nLe tecniche di \"soft computing\" d'altro canto antepongono il guadagno nella comprensione del comportamento di un sistema a scapito della precisione, spesso non necessaria. I paradigmi di \"soft computing\" si basano su due principi: \nL'apprendimento automatico si avvale delle tecniche di \"soft computing\".\nLa programmazione logica induttiva (anche ILP, dall'inglese \"inductive logic programming\") \u00e8 un approccio all'apprendimento di regole che usa la programmazione logica come rappresentazione uniforme per gli esempi di input, per la conoscenza di base della macchina, e per le ipotesi. Data una codifica della (nota) conoscenza di base e un insieme di esempi rappresentati come fatti in una base di dati logica, un sistema ILP deriva un programma logico ipotetico da cui conseguono tutti gli esempi positivi, e nessuno di quelli negativi. La programmazione induttiva \u00e8 un campo simile che considera ogni tipo di linguaggio di programmazione per rappresentare le ipotesi invece che soltanto la programmazione logica, come ad esempio programmi funzionali.\nL'albero di decisione \u00e8 un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende \u00e8 rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilit\u00e0 umana.\nL'apprendimento automatico basato su regole di associazione \u00e8 un metodo di apprendimento che identifica, apprende ed evolve delle \"regole\" con l'intento di immagazzinare, manipolare e applicare conoscenza. La caratteristica principale di questo tipo di apprendimento \u00e8 l'identificazione ed utilizzo di un insieme di regole relazionali che rappresenta nel suo insieme la conoscenza catturata dal sistema. Ci\u00f2 si pone in controtendenza con altri tipi di apprendimento automatico che normalmente identificano un singolo modello che pu\u00f2 essere applicato universalmente ad ogni istanza per riuscire a fare su di essa una previsione. Gli approcci dell'apprendimento basato su regole di associazione includono il sistema immunitario artificiale.\nUna rete neurale artificiale \u00e8 un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.\nGli algoritmi genetici forniscono un approccio all'apprendimento che \u00e8 liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi pi\u00f9 adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una variet\u00e0 di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.\nIl ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantit\u00e0 di interesse sono disciplinate da distribuzioni di probabilit\u00e0 e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilit\u00e0 insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana \u00e8 importante perch\u00e9 fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilit\u00e0.\nMacchine a vettori di supporto (\"Support Vector Machine\", SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.\nLa discesa dei prezzi per l'hardware e lo sviluppo di GPU per uso personale negli ultimi anni hanno contribuito allo sviluppo del concetto di apprendimento profondo, che consiste nello sviluppare livelli nascosti multipli nelle reti neurali artificiali. Questo approccio tenta di modellizzare il modo in cui il cervello umano processa luce e suoni e li interpreta in vista e udito. Alcune delle applicazioni pi\u00f9 affermate dell'apprendimento profondo sono la visione artificiale e il riconoscimento vocale.\nLa cluster analisi, o clustering, \u00e8 in grado di rilevare similarit\u00e0 strutturali tra le osservazioni di un dataset attraverso l'assegnazione di un insieme di osservazioni in sottogruppi (\"cluster\") di elementi tra loro omogenei. Il clustering \u00e8 un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.\nTutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.\nMetodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.\nMetodi di apprendimento automatico sono stati applicati ad una variet\u00e0 di database di grandi dimensioni per imparare regolarit\u00e0 generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema \u00e8 oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.\nI programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.\nL'apprendimento automatico solleva un numero di problematiche etiche. I sistemi addestrati con insiemi di dati faziosi o pregiudizievoli possono esibire questi pregiudizi quando vengono interpellati: in questo modo possono essere digitalizzati pregiudizi culturali quali il razzismo istituzionale e il classismo. Di conseguenza la raccolta responsabile dei dati pu\u00f2 diventare un aspetto critico dell'apprendimento automatico.\nIn ragione dell'innata ambiguit\u00e0 dei linguaggi naturali, le macchine addestrate su corpi linguistici necessariamente apprenderanno questa ambiguit\u00e0."], "concept_B": "Apprendimento automatico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_A": "Macchine a vettori di supporto", "wikipedia_passage_concept_B": ["40388", "Funzione di densit\u00e0 di probabilit\u00e0", "In matematica, una funzione di densit\u00e0 di probabilit\u00e0 (o PDF dall'inglese \"probability density function\") \u00e8 l'analogo della funzione di probabilit\u00e0 di una variabile casuale nel caso in cui la variabile casuale formula_1 sia continua, cio\u00e8 l'insieme dei possibili valori che ha la potenza del continuo.\nEssa descrive la \"densit\u00e0\" di probabilit\u00e0 in ogni punto nello spazio campionario.\nLa funzione di densit\u00e0 di probabilit\u00e0 di una variabile casuale formula_1 \u00e8 un'applicazione formula_3 non negativa integrabile secondo Lebesgue e reale di variabile reale tale che la probabilit\u00e0 dell'insieme \"A\" sia data da\nper tutti i sottinsiemi \"A\" dello spazio campionario.\nIntuitivamente, se una distribuzione di probabilit\u00e0 ha densit\u00e0 formula_3, allora l'intervallo formula_6 ha probabilit\u00e0 formula_7. Da ci\u00f2 deriva che la funzione formula_3 \u00e8 un'applicazione definita come\nAssumendo formula_10, ci\u00f2 corrisponde al limite della probabilit\u00e0 che formula_11 si trovi nell'intervallo formula_6 per formula_13 che tende a zero. Di qui il nome di funzione di 'densit\u00e0', in quanto essa rappresenta il rapporto tra una probabilit\u00e0 e un'ampiezza.\nPer la condizione di normalizzazione l'integrale su tutto lo spazio di formula_3 deve essere 1. Di conseguenza ogni funzione non negativa, integrabile secondo Lebesgue, con integrale su tutto lo spazio uguale a 1, \u00e8 la funzione densit\u00e0 di probabilit\u00e0 di una ben definita distribuzione di probabilit\u00e0. Una variabile casuale che possiede densit\u00e0 si dice \"variabile casuale continua\".\nPer le variabili casuali multivariate (o vettoriali) la trattazione formale \u00e8 assolutamente identica: formula_15 si dice assolutamente continua se esiste una funzione a valori reali definita in formula_16, detta densit\u00e0 congiunta, tale che per ogni sottoinsieme \"A\" dello spazio campionario\nEssa conserva tutte le propriet\u00e0 di una densit\u00e0 scalare: \u00e8 una funzione non negativa a integrale unitario su tutto lo spazio. Una propriet\u00e0 importante \u00e8 che se formula_15 \u00e8 assolutamente continua allora lo \u00e8 ogni sua componente; il viceversa invece non vale. La densit\u00e0 di una componente, detta densit\u00e0 marginale, si ottiene con un ragionamento analogo al teorema della probabilit\u00e0 assoluta, cio\u00e8 fissando l'insieme di suoi valori di cui si vuole determinare la probabilit\u00e0 e lasciando libere di variare tutte le altre componenti. Infatti (nel caso bivariato per semplicit\u00e0) l'evento formula_19 \u00e8 l'evento formula_20, dunque\nutilizzando il teorema di Fubini. La densit\u00e0 marginale di formula_1 \u00e8 data dunque da\nLa funzione di densit\u00e0 della variabile casuale normale di media 0\ne varianza 1 (detta \"normale standard\"), di cui a destra \u00e8 riportato il grafico e l'espressione analitica della corrispondente densit\u00e0 nel caso generico (media formula_24 e varianza formula_25).\nUn altro esempio pu\u00f2 essere dato dalla densit\u00e0 di probabilit\u00e0 uniforme su un segmento (0,1). Si pu\u00f2 verificare immediatamente che \u00e8 densit\u00e0 di probabilit\u00e0 facendo l'integrale tra (0,1)."], "concept_B": "Funzione di densit\u00e0 di probabilit\u00e0", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["480718", "Discesa del gradiente", "In ottimizzazione e analisi numerica il metodo di discesa del gradiente (detto anche \"metodo del gradiente\", \"metodo steepest descent\" o \"metodo di discesa pi\u00f9 ripida\") \u00e8 una tecnica che consente di determinare i punti di massimo e minimo di una funzione di pi\u00f9 variabili.\nIl metodo \u00e8 stato sviluppato - e pubblicato nel 1847 - dal matematico francese Augustin-Louis Cauchy nel tentativo di risolvere il problema di determinare l'orbita di un corpo celeste a partire dalle sue equazioni del moto.\nSi supponga di voler minimizzare la funzioneformula_1 e si scelga come soluzione iniziale il vettore formula_2. Allora\ne, muovendosi in un intorno di formula_4:\nQuesti calcoli mostrano che, per individuare dei punti - \"vicini\" a formula_4 - in corrispondenza dei quali la funzione assuma un valore minore di formula_7, conviene spostarsi lungo direzioni che abbiano la prima e la terza componente formula_8 pi\u00f9 piccole o seconda componente formula_9 pi\u00f9 grande. Inoltre esistono delle direzioni \"preferenziali\" lungo le quali la funzione formula_10 decresce pi\u00f9 velocemente (ad esempio scegliere una coordinata formula_11 pi\u00f9 piccola \u00e8 preferibile, ad esempio, rispetto a far diminuire formula_12).\nLa procedura pu\u00f2 essere iterata partendo da un nuovo punto, ad esempio formula_13, fino ad individuare un minimo per formula_10. L'esempio mostra che una procedura che aggiorni la soluzione in modo iterativo sulla base delle informazioni disponibili \"localmente\" pu\u00f2 portare ad individuare un punto di minimo per la funzione assegnata.\nSi voglia risolvere il seguente problema di ottimizzazione non vincolata nello spazio formula_15-dimensionale formula_16\nLa tecnica di discesa secondo gradiente si basa sul fatto che, per una data funzione formula_18, la direzione di massima discesa in un assegnato punto formula_19 corrisponde a quella determinata dall'opposto del suo gradiente in quel punto formula_20. Questa scelta per la direzione di discesa garantisce che la soluzione tenda a un punto di minimo di formula_10. Il metodo del gradiente prevede dunque di partire da una soluzione iniziale formula_4 scelta arbitrariamente e di procedere iterativamente aggiornandola come\ndove formula_24 corrisponde alla lunghezza del passo di discesa, la cui scelta diventa cruciale nel determinare la velocit\u00e0 con cui l'algoritmo converger\u00e0 alla soluzione richiesta.\nSi parla di metodo \"stazionario\" nel caso in cui si scelga un passo formula_25 costante per ogni formula_26, viceversa il metodo si definisce \"dinamico\". In quest'ultimo caso una scelta conveniente, ma computazionalmente pi\u00f9 onerosa rispetto a un metodo stazionario, consiste nell'ottimizzare, una volta determinata la direzione di discesa formula_27, la funzione di una variabile formula_28 in maniera analitica o in maniera approssimata. Si noti che, a seconda della scelta del passo di discesa, l'algoritmo potr\u00e0 convergere a uno qualsiasi dei minimi della funzione formula_10, sia esso locale o globale.\nLo schema generale per l'ottimizzazione di una funzione formula_18 mediante metodo del gradiente \u00e8 il seguente:\nUn caso particolare di applicazione del metodo del gradiente consiste nella risoluzione di sistemi lineari della forma\ndove formula_33 \u00e8 una matrice simmetrica e definita positiva.\nPer le propriet\u00e0 di formula_33 la soluzione di tale problema \u00e8 equivalente alla procedura di minimizzazione della forma quadratica associata:\nInfatti:\nda cui\nPer la funzione formula_38 si ha che la direzione di massima discesa nel punto formula_39 \u00e8:\ncoincidente con il residuo formula_41 del sistema lineare. Dunque la direzione di discesa scelta a ogni iterazione \u00e8 formula_42.\nInoltre vale la seguente relazione:\nche permette di calcolare analiticamente il passo formula_44 ottimale. Infatti, imponendo la condizione di stazionariet\u00e0\nsi ricava\nL'algoritmo del metodo del gradiente per la risoluzione di sistemi lineari \u00e8 dunque\nIn aritmetica floating point la condizione del ciclo while pu\u00f2 essere valutata verificando che la norma del residuo formula_48 non sia pi\u00f9 piccola di una tolleranza impostata dall'utente.\nIn molti casi \u00e8 possibile accelerare la velocit\u00e0 di convergenza dell'algoritmo migliorando le propriet\u00e0 di condizionamento della matrice formula_33. Si introduca a tal fine una matrice di precondizionamento formula_50 simmetrica e definita positiva.\nLo schema risolutivo in questo caso diventa:\nIl metodo del gradiente coniugato costituisce una variante del metodo del gradiente in cui viene effettuata una scelta diversa, ma particolarmente conveniente nel caso di sistemi lineari simmetrici e definiti positivi, per le direzioni di discesa formula_27. Tale scelta garantisce la convergenza del metodo (in aritmetica esatta) in un numero di iterazioni pari al pi\u00f9 alla dimensione del sistema da risolvere.\n\u00c8 possibile dimostrare che l'errore commesso alla formula_26-esima iterazione del metodo del gradiente soddisfa la seguente stima:\ndove\nformula_56 indica il numero di condizionamento in norma formula_57 di formula_33 e formula_59 \u00e8 la norma indotta da formula_33.\nNel caso precondizionato vale la stessa stima con\nSi riporta un esempio di possibile implementazione del metodo del gradiente nella versione precondizionata compatibile con i linguaggi di programmazione Octave e MATLAB.\nQuando la funzione obiettivo \u00e8 troppo costosa da calcolare ad ogni iterazione, ma pu\u00f2 essere scomposta in una somma di molti addendi (ad esempio, la somma del costo calcolato su ogni singolo record in un dataset), il gradiente pu\u00f2 essere approssimato stocasticamente restringendo la somma su un sottinsieme di addendi ad ogni iterazione, metodo noto come discesa stocastica del gradiente.\nLa discesa del gradiente \u00e8 ampiamente utilizzata in statistica e apprendimento automatico per l'addestramento tramite apprendimento supervisionato di modelli come reti neurali artificiali e modelli grafici. Il principio \u00e8 noto come regola delta, e consiste nel valutare il modello su un input il cui corrispondente output esatto sia noto, e correggere ciascun parametro del modello in una quantit\u00e0 proporzionale (ma di segno opposto) rispetto al suo contributo all'errore sul risultato. L'algoritmo usato nelle reti neurali per implementare questo principio \u00e8 noto come retropropagazione dell'errore, che consiste in un'applicazione della discesa del gradiente, essendo il contributo di ciascun parametro all'errore del modello dato dalla derivata parziale della funzione di perdita rispetto al parametro stesso.\nLa regola, classificabile fra i metodi per l'apprendimento supervisionato, pu\u00f2 essere applicata a reti neurali di tipo \"in avanti\" (cio\u00e8 con propagazione unidirezionale dei segnali, in inglese: \"feedforward\") e permette di calcolare la differenza tra i valori di output che la rete ottiene e quelli che invece dovrebbe apprendere. La regola deve essere applicata a reti che usano unit\u00e0 di output ad attivazione continua e differenziabile ed \u00e8 l'elemento fondamentale dell'algoritmo di retropropagazione dell'errore (\"backpropagation\"), alla base dell'approccio connessionista.\nData una rete \"in avanti\" con le propriet\u00e0 sopra descritte, l'obiettivo che ci si prefigge \u00e8 minimizzare la diversit\u00e0 tra i valori di attivazione delle unit\u00e0 di output formula_62 della rete (ottenuti sommando i segnali provenienti dalle diverse unit\u00e0 di input formula_63 moltiplicati per l'efficacia, o \"pesi sinaptici\" formula_64 delle connessioni in ingresso), e i valori formula_65 della risposta desiderata. Tale diversit\u00e0 viene quantificata attraverso una funzione di perdita. La funzione obiettivo che si vuole minimizzare \u00e8 il valore atteso della perdita (in pratica la perdita media sui dati).\nPer applicare il metodo del gradiente, la funzione di perdita deve essere derivabile rispetto ai valori di output formula_62. Una scelta adatta a problemi di regressione \u00e8 lo scarto quadratico medio tra formula_62 e formula_65 (valutato per tutte le unit\u00e0 di output e per tutti i pattern d'apprendimento); per problemi di classificazione si pu\u00f2 utilizzare la divergenza di Kullback-Leibler o equivalentemente l'entropia incrociata.\nNella fase di addestramento, variando i pesi sinaptici formula_64 (parametri del modello) si pu\u00f2 aumentare o diminuire la funzione obiettivo; la \"prestazione\" della rete sar\u00e0 funzione delle variabili formula_64, e sar\u00e0 massima quando si raggiunge il minimo della funzione obiettivo, il che si ottiene applicando il metodo del gradiente e aggiornando iterativamente i valori dei pesi sinaptici.\nPoich\u00e9 nelle applicazioni pratiche le dimensioni dei modelli e dei relativi dataset usati nell'addestramento sono molto grandi, in pratica si fa generalmente uso della discesa stocastica del gradiente per l'addestramento delle reti neurali e di altri modelli statistici e di apprendimento automatico."], "concept_A": "Discesa del gradiente", "wikipedia_passage_concept_B": ["253357", "Massimo e minimo di una funzione", "In matematica si dice che una funzione a valori reali:\nha in un punto formula_2 del proprio dominio formula_3 un massimo globale (o assoluto) se in formula_2 assume un valore maggiore o uguale a quello che assume negli altri punti di formula_3, ovvero\nViceversa formula_7 ha un minimo globale (o assoluto) in un punto formula_2 di formula_3 se\nSi dice che una funzione formula_7 ha in formula_2 un massimo locale (o relativo) se formula_2 appartiene al dominio formula_3 di formula_7, \u00e8 di accumulazione per formula_3, e inoltre formula_17 in un intorno di formula_2. \nformula_7 ha invece un minimo locale (o relativo) in formula_2 se formula_2 appartiene al dominio formula_3 di formula_7, \u00e8 di accumulazione per formula_3, e inoltre formula_25 in un intorno di formula_2.\nIn tutti questi casi, si parla di formula_2 come di \"punto di massimo\" (o \"di minimo\") \"assoluto\" (o \"relativo\").\nI punti di massimo e minimo vengono anche detti punti estremanti, e i valori assunti dalla funzione in questi punti sono detti estremi della funzione.\nNel caso di una funzione derivabile di una variabile reale la condizione necessaria, ma non sufficiente, affinch\u00e9 un punto possa, eventualmente, essere di massimo o di minimo locale \u00e8 data dal teorema di Fermat, in base al quale la derivata prima di una funzione deve annullarsi se calcolata in corrispondenza di un punto di massimo o minimo locale:\nTale condizione permette di trovare un certo numero di punti (\"x\", \"x\", ...) che si chiamano punti critici o stazionari. Naturalmente questa condizione vale per tutti i punti interni al dominio di derivabilit\u00e0, cio\u00e8 nei punti interni di questo insieme, mentre negli estremi dell'insieme non \u00e8 detto che la derivata esista e proprio per questo motivo la condizione vale per gli intervalli aperti. Questa condizione si pu\u00f2 dimostrare: infatti se formula_2 \u00e8 un punto di massimo locale, allora in un intorno formula_30 di \"x\" vale che il rapporto incrementale:\nformula_31\nper cui passando al limite di una funzione per formula_32 si deduce che necessariamente formula_33.\nGeometricamente questa condizione significa che la retta tangente nel punto \"x\" \u00e8 orizzontale. Tale condizione non \u00e8 n\u00e9 necessaria n\u00e9 sufficiente per avere un massimo o un minimo locale: infatti da un lato ci possono essere punti di massimo o minimo locale anche laddove la funzione non \u00e8 derivabile, e dall'altro ci possono essere punti (di flesso) dove la derivata si annulla ma la funzione non ha massimo o minimo locale.\nPossiamo utilizzare la derivata prima per classificare i punti critici. Un punto formula_2 \u00e8 di massimo locale per \"f\" se nei suoi intorni destro e sinistro:\nViceversa \u00e8 di minimo locale se:\nSe infine il valore della derivata non cambia attraversando il punto formula_2 allora questo \u00e8 un punto di flesso ascendente o discendente a seconda che la derivata prima rimanga sempre positiva o sempre negativa.\nAlternativamente se la funzione ammette la derivata seconda in un punto, un punto \u00e8 di massimo o minimo relativo se la derivata prima della funzione si annulla (quindi formula_2 \u00e8 un punto stazionario) e la derivata seconda non si annulla. Pi\u00f9 precisamente, posto che la derivata prima si annulli, se la derivata seconda risulta essere maggiore di 0, allora significa che la concavit\u00e0 sar\u00e0 rivolta verso l'alto, perci\u00f2 il punto \u00e8 di minimo. Mentre, se la derivata seconda \u00e8 minore di zero, significa che la concavit\u00e0 \u00e8 rivolta verso il basso e quindi si tratter\u00e0 di un punto di massimo. Se invece la derivata seconda si annulla, nel caso in cui la derivata terza sia diversa da zero, avremo in quel punto un flesso a tangenza orizzontale ascendente o discendente e, per la definizione di flesso, la funzione cambier\u00e0 concavit\u00e0 in tale punto.\nNel caso di funzioni in pi\u00f9 variabili, il discorso fatto \u00e8 analogo, ma ad annullarsi \u00e8 il differenziale (e quindi il gradiente) della funzione. \nNel caso di funzioni di 2 variabili, per verificare se il punto \u00e8 di massimo o minimo, si guarda il segno del determinante della matrice hessiana e il primo termine della matrice: \nNel caso di funzioni di 3 o pi\u00f9 variabili, invece, si deve studiare il segno degli autovalori della matrice hessiana (nei punti critici, cio\u00e8 dove si annulla il gradiente) e:\nIn caso di funzioni di due o pi\u00f9 variabili, la ricerca dei punti di massimo e minimo non si esaurisce all'interno del dominio dove la funzione \u00e8 derivabile, ma si devono cercare i massimi e i minimi anche sulla frontiera, in cui in generale la funzione non \u00e8 differenziabile. In tal caso, nelle funzioni di due variabili si parametrizza la frontiera e si cercano i punti di massimo e di minimo come visto per una variabile reale.\nSi consideri \nCalcoliamo la derivata prima:\nCalcoliamo la derivata seconda: \nLa derivata prima si annulla nei punti \nNel punto formula_43 la derivata seconda \u00e8 negativa, quindi \u00e8 un punto di massimo, mentre nel punto formula_44 la derivata seconda \u00e8 positiva, quindi \u00e8 un punto di minimo.\nSi consideri la funzione di 2 variabili\nCalcoliamo le derivate parziali prime:\nQuindi il gradiente di formula_48 \u00e8:\nI punti critici sono dati dalla soluzione del sistema:\nQuindi... \nformula_51 \noppure\nformula_52 \nCalcoliamo le derivate parziali seconde:\nQuindi la matrice hessiana di z sar\u00e0:\nBasandosi sul modello:\nCalcoliamo la matrice hessiana nei punti critici (anche detti \"punti stazionari\"):\nQuesta matrice ha determinante negativo (-9), quindi \u00e8 un punto di sella.\nQuesta seconda matrice ha invece determinante positivo (27) e primo termine (-6) negativo quindi \u00e8 un punto di massimo relativo."], "concept_B": "Massimo e minimo di una funzione", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["6394873", "F1 score", "Nell'analisi statistica della classificazione binaria, lF score (nota anche come F-score o F-measure, letteralmente \"misura F\") \u00e8 una misura dell'accuratezza di un test. La misura tiene in considerazione precisione e recupero del test, dove la precisione \u00e8 il numero di veri positivi diviso il numero di tutti i risultati positivi, mentre il recupero \u00e8 il numero di veri positivi diviso il numero di tutti i test che sarebbero dovuti risultare positivi (ovvero veri positivi pi\u00f9 falsi negativi). L'F viene calcolato tramite la media armonica di precisione e recupero:\nPu\u00f2 assumere valori compresi fra 0 e 1. Assume valore 0 solo se almeno uno dei due vale 0, mentre assume valore 1 sia precisione che recupero valgono 1. L'F score \u00e8 anche noto come coefficiente di S\u00f8rensen-Dice (DSC), o semplicemente coefficiente di Dice.\nLa formula generale \u00e8:\nper valori di \u03b2 reali positivi.\nLa formula in termini di errori di primo e secondo tipo:\nDue particolari istanze della formula solitamente utilizzate sono la misura formula_4 (che pone maggiore enfasi sui falsi negativi) ed formula_5 (la quale attenua l'influenza dei falsi negativi).\nIn generale, formula_6 \"misura l'efficacia del recupero rispetto ad un utente attribuisce al recupero un'importanza di \u03b2 volte quella della precisione\".\nL'F-score \u00e8 solitamente usata nel campo del recupero dell'informazione per misurare l'accuratezza delle ricerche o della classificazione dei documenti. Inizialmente l'F score era l'unica misura ad essere considerata, ma con la proliferazione in larga scala di motori di ricerca gli obiettivi di prestazione iniziarono a variare, divenendo necessario porre maggiore enfasi su precisione o recupero.\nL'F-score \u00e8 usata anche nel campo dell'apprendimento automatico ed \u00e8 vastamente impiegata nella letteratura sull'elaborazione del linguaggio naturale.\nDa notare, comunque, che non viene mai preso in considerazione il numero di veri negativi. In tal senso, misure come il coefficiente di correlazione di Matthews o il Kappa di Cohen possono generare risultati pi\u00f9 adeguati alle proprie esigenze.\nMentre l'F-measure \u00e8 una media armonica di recupero e precisione, la cosiddetta G-measure \u00e8 una media geometrica:\nDove \"PPV\" sta per \"Positive Predictive Value\" (\"valore predittivo positivo\") e \"TPR\" per \"True Positive Rate\" (o indice di sensibilit\u00e0).\n\u00c8 nota anche come indice di Fowlkes-Mallows."], "concept_A": "F1 score", "wikipedia_passage_concept_B": ["847", "Campionamento statistico", "In statistica il campionamento statistico (che si appoggia alla teoria dei campioni o teoria del campionamento), sta alla base dell'inferenza statistica, la quale si divide in due grandi capitoli: la teoria della stima e la verifica d'ipotesi.\nIn particolare, una rilevazione si dice \"campionaria\" quando \u00e8 utile per fare inferenza ossia per desumere dal campione stesso un'informazione relativa all'intera popolazione.\nLe indagini censuarie riguardano l'intera popolazione e pur essendo pi\u00f9 affidabili riguardo al parametro oggetto d'indagine soffrono di:\nQuindi mentre l'indagine censuaria fornisce il valore vero dei parametri di interesse (proporzioni, percentuali, medie, totali...) quella campionaria restituisce una sua stima al quale \u00e8 associato un certo grado di fiducia (ovvero un'incertezza) quantificabile quando la formazione del campione risponde a determinati criteri di tipo probabilistico.\nIl campionamento si usa quando si vuole conoscere uno o pi\u00f9 parametri di una popolazione, senza doverne analizzare ogni elemento: questo per motivi di costi intesi in termini monetari, di tempo, di qualit\u00e0 o di disagio o perch\u00e9 analizzare un elemento lo distrugge rendendo inutilizzabile l'informazione ottenuta.\nModalit\u00e0 di selezione del campione sono:\nNella pratica quotidiana dei sondaggi di opinione e delle ricerche di mercato vengono usati tutti e quattro gli approcci.\nLa scelta di un tipo di campionamento avviene in base alle propriet\u00e0 degli stimatori di alcuni parametri oppure per tener conto di problemi di costo, mobilit\u00e0 o altro.\nConcetti chiave sono:\nBench\u00e9 gi\u00e0 nel Settecento si sia notato il vantaggio nell'esaminare un sottinsieme della popolazione per generalizzare i risultati alla popolazione complessiva, \u00e8 solo dalla fine dell'Ottocento che la discussione sulla \"scientificit\u00e0\" del campionamento viene posta in modo esplicito alla comunit\u00e0 statistica.\nGi\u00e0 agli inizi del Novecento si vanno delineando le caratteristiche che un campione deve avere, ovvero che deve essere scelto in maniera casuale, e nell'arco di pochi anni compaiono i primi studi che mettono in evidenza che il campione non deve essere necessariamente un campione semplice ma pu\u00f2 essere pi\u00f9 complesso, per esempio stratificando.\nImportanti autori che hanno fatto la storia della teoria dei campioni sono stati tra gli altri: \nNel 1925, durante il congresso di Roma, l'Istituto Internazionale di Statistica accetta definitivamente come scientifico il metodo campionario, distinguendo il campionamento casuale dal campionamento ragionato.\nAltri autori importanti nella ricerca teorica ed applicata sul campionamento furono George Gallup e William G. Cochran."], "concept_B": "Campionamento statistico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_A": "Rete bayesiana", "wikipedia_passage_concept_B": ["4145289", "Distribuzione di probabilit\u00e0 a priori", "Nell'ambito dell'inferenza statistica bayesiana, una distribuzione di probabilit\u00e0 a priori, detta spesso anche distribuzione a priori, di una quantit\u00e0 incognita \"p\" (per esempio, supponiamo \"p\" essere la proporzione di votanti che voteranno per il politico Rossi in un'elezione futura) \u00e8 la distribuzione di probabilit\u00e0 che esprimerebbe l'incertezza di \"p\" prima che i \"dati\" (per esempio, un sondaggio di opinione) siano presi in considerazione. Il proposito \u00e8 di attribuire incertezza piuttosto che casualit\u00e0 a una quantit\u00e0 incerta. La quantit\u00e0 incognita pu\u00f2 essere un parametro o una variabile latente.\nSi applica il teorema di Bayes, moltiplicando la distribuzione a priori per la funzione di verosimiglianza e quindi normalizzando, per ottenere la distribuzione di probabilit\u00e0 a posteriori, la quale \u00e8 la distribuzione condizionata della quantit\u00e0 incerta una volta ottenuti i dati.\nSpesso una distribuzione a priori \u00e8 l'accertamento soggettivo (elicitazione) di una persona esperta. Quando possibile, alcuni sceglieranno una \"distribuzione a priori coniugata\" per rendere pi\u00f9 semplice il calcolo della distribuzione a posteriori.\nI parametri di una distribuzione a priori sono chiamati \"iperparametri\", per distinguerli dai parametri del modello dei dati sottostanti. Per esempio, se si sta usando una distribuzione beta per modellare la distribuzione di un parametro \"p\" di una distribuzione di Bernoulli, allora:\nUna \"distribuzione a priori informativa\" esprime una specifica, definita informazione circa una variabile.\nUn esempio \u00e8 la distribuzione a priori per la temperatura di domattina.\nUn approccio ragionevole \u00e8 costruire la distribuzione a priori come una distribuzione normale con valore atteso uguale alla temperatura mattutina di oggi, con una varianza uguale alla varianza giorno per giorno della temperatura atmosferica, oppure come una distribuzione della temperatura per quel tal giorno dell'anno.\nQuesto esempio ha una propriet\u00e0 in comune con molte distribuzioni a priori, ovvero che la distribuzione a posteriori di un problema (temperatura odierna) diventa la distribuzione a priori per un altro problema (temperatura di domani); l'evidenza preesistente, che \u00e8 gi\u00e0 stata tenuta in conto, \u00e8 parte della distribuzione a priori e come ulteriore evidenza viene accumulata. \nLa distribuzione a priori \u00e8 largamente determinata dall'evidenza piuttosto che da qualche assunzione originale, sempre che l'assunzione originale ammetta la possibilit\u00e0 (ossia sia compatibile) con quello che l'evidenza suggerisce. I termini \"a priori\" e \"a posteriori\" sono generalmente relativi a un dato o un'osservazione specifica.\nUna \"distribuzione a priori non informativa\" esprime vaghezza o informazione a carattere generale circa una variabile.\nIl termine \"non informativa\" pu\u00f2 essere un po' fuorviante; spesso, tale tipo di distribuzione \u00e8 chiamata \"a priori non molto informativa\", oppure \"a priori oggettiva\", cio\u00e8 una distribuzione che non \u00e8 soggettivamente esplicitata.\nLe distribuzioni a priori non informative possono esprimere informazione \"oggettiva\" come ad esempio \"la variabile \u00e8 positiva\" oppure \"la variabile \u00e8 minore di tal limite\".\nLa pi\u00f9 semplice e vecchia regola per determinare una distribuzione a priori non informativa \u00e8 il principio d'indifferenza, il quale assegna a tutti gli eventi uguale probabilit\u00e0.\nIn problemi di stima parametrica, l'uso di una distribuzione a priori non informativa d\u00e0 risultati che sono non troppo differenti dall'analisi statistica convenzionale. Questo accade in quanto la funzione di verosimiglianza fornisce la parte maggiore dell'informazione rispetto a quella fornita dalla distribuzione a priori non informativa nel determinare una distribuzione a posteriori.\nVari tentativi sono stati fatti per trovare probabilit\u00e0 a priori, cio\u00e8 distribuzioni di probabilit\u00e0 in un certo senso logicamente richieste dalla natura di uno stato di incertezza; queste sono soggette a controversia filosofica, con i sostenitori del metodo bayesiano approssimativamente divisi in due scuole: i \"bayesiani oggettivistici\", che credono che tali distribuzioni a priori esistano in molte situazioni, e i \"bayesiani soggettivisti\" che credono che in pratica le distribuzioni a priori rappresentino giudizi di opinione che non possono essere rigorosamente giustificati. Per la maggiore le pi\u00f9 forti argomentazioni a favore della scuola oggettivistica furono date da Edwin T. Jaynes.\nCome esempio di una distribuzione a priori, dovuta a, consideriamo una situazione in cui sappiamo che una pallina \u00e8 nascosta sotto una di tre tazze rovesciate, A, B o C, ma nessun'altra informazione \u00e8 disponibile circa la sua posizione. In questo caso una distribuzione a priori uniforme di formula_1 sembra intuitivamente verosimile la sola scelta ragionevole. Pi\u00f9 formalmente, noi possiamo vedere che il problema rimane lo stesso se scambiamo le lettere identificative \"A\", \"B\" e \"C\" delle tazze. Sarebbe perci\u00f2 strano scegliere una distribuzione a priori per la quale una permutazione delle lettere causerebbe un cambio nella nostra predizione circa la posizione dove la pallina sar\u00e0 trovata; la distribuzione a priori uniforme \u00e8 la sola che preserva questa invarianza. Se si accetta questo principio di invarianza allora si pu\u00f2 vedere che la distribuzione a priori uniforme \u00e8 la distribuzione logicamente corretta che rappresenta questo stato di conoscenza a priori. Si avr\u00e0 notato che questa distribuzione a priori \u00e8 \"oggettiva\" nel senso di essere la scelta corretta per rappresentare un particolare stato di conoscenza, ma non \u00e8 oggettiva nel senso di essere una caratteristica del sistema osservato indipendente dall'osservatore: in realt\u00e0 la pallina esiste sotto una specifica tazza e in questa situazione ha solo senso parlare di probabilit\u00e0 se c'\u00e8 un osservatore con una conoscenza limitata del sistema ossia della posizione della pallina sotto le tazze.\nCome esempio pi\u00f9 controverso, Jaynes pubblic\u00f2 un argomento basato sui gruppi di Lie suggerente che la distribuzione a priori rappresentante in maniera completa l'incertezza sarebbe la distribuzione a priori di Haldane \"p\"(1\u00a0\u2212\u00a0\"p\"). L'esempio fornito da Jaynes \u00e8 quello di trovare un chimico in un laboratorio e di chiedergli di eseguire ripetutamente degli esperimenti di dissoluzione in acqua. La distribuzione a priori di Haldane da prevalentemente la maggiore probabilit\u00e0 agli eventi formula_2 and formula_3, indicando che il campione ogni volta si scioglier\u00e0 oppure no, con uguale probabilit\u00e0. Tuttavia se sono stati osservati campioni non disciogliersi in un esperimento e disciogliersi in un altro, allora questa distribuzione a priori \u00e8 aggiornata alla distribuzione uniforme sull'intervallo [0, 1]. Questo risultato si ottiene applicando il teorema di Bayes all'insieme di dati consistente in un'osservazione di dissoluzione e una di non dissoluzione, usando la distribuzione a priori precedente. sulla base che essa fornisce una distribuzione a posteriori impropria che pone il 100% del contenuto di probabilit\u00e0 sia a \"p\" = 0 o a \"p\" = 1 se un numero finito di esperimenti ha dato lo stesso risultato (ad esempio il discioglimento). La distribuzione a priori di Jeffreys \"p\"(1\u00a0\u2212\u00a0\"p\") \u00e8 perci\u00f2 preferita (\"cfr.\" sotto).\nSe lo spazio parametrico X \u00e8 dotato di una struttura di gruppo naturale che lascia invariato il nostro stato di conoscenza bayesiano, allora la distribuzione a priori pu\u00f2 essere costruita proporzionale alla Misura di Haar. Questo pu\u00f2 essere visto come una generalizzazione del principio di invarianza che giustificava la distribuzione a priori uniforme dell'esempio delle tre tazze visto sopra. Per esempio, in fisica ci si aspetta che un esperimento dia i medesimi risultati indipendentemente dalla scelta dell'origine del sistema di coordinate. Questo induce la struttura gruppale del gruppo delle traslazioni su \"X\", il quale determina la distribuzione di probabilit\u00e0 a priori come una distribuzione a priori impropria costante. Analogamente alcuni sistemi fisici presentano un'invarianza di scala (ossia i risultati sperimentali sono indipendenti dal fatto che, ad esempio, usiamo centimetri o pollici). In tal caso il gruppo di scala \u00e8 la struttura di gruppo naturale, e la corrispondente distribuzione a priori su \"X\" \u00e8 proporzionale a 1/\"x\". Qualche volta risulta importante se viene usata la misura di Haar invariante a sinistra piuttosto che quella invariante a destra. Per esempio, le misure di Haar invarianti a destra e a sinistra sul gruppo affine non sono uguali. Berger (1985, p.\u00a0413) arguisce che la scelta corretta \u00e8 la misura di Haar invariante a destra.\nUn'altra idea, supportata da Edwin T. Jaynes, \u00e8 di usare il principio di massima entropia (MAXENT). La motivazione \u00e8 che l'entropia di Shannon di una distribuzione di probabilit\u00e0 misura l'ammontare di informazione contenuta nella distribuzione. Maggiore \u00e8 l'entropia, minore \u00e8 l'informazione fornita dalla distribuzione. Perci\u00f2, mediante la massimizzazione dell'entropia sopra un adeguato insieme di distribuzioni di probabilit\u00e0 su \"X\", si trova la distribuzione che \u00e8 meno informativa nel senso che essa contiene il minore ammontare di informazione consistente con le costrizioni definite dall'insieme scelto. Per esempio, la distribuzione a priori di massima entropia su uno spazio discreto, dato solo il fatto che la probabilit\u00e0 \u00e8 normalizzata a 1, \u00e8 la distribuzione a priori che assegna uguale probabilit\u00e0 ad ogni stato. Mentre nel caso continuo, la distribuzione a priori di massima entropia con densit\u00e0 normalizzata, media nulla e varianza unitaria, \u00e8 la ben nota distribuzione normale. Il principio di minima entropia incrociata generalizza il principio di massima entropia al caso di \"aggiornamento\" di una distribuzione a priori arbitraria con adeguate costrizioni nel senso di massima entropia.\nUn'idea collegata, la distribuzione a priori di riferimento, fu introdotta da Jos\u00e9-Miguel Bernardo. Qui l'idea \u00e8 di massimizzare il valore atteso della divergenza di Kullback\u2013Leibler della distribuzione a posteriori rispetto alla distribuzione a priori. Questo massimizza l'informazione attesa riguardante \"X\" quando la densit\u00e0 a priori \u00e8 \"p\"(\"x\"); perci\u00f2, in un certo senso, \"p\"(\"x\") \u00e8 la distribuzione a priori \"meno informativa\" riguardo X. La distribuzione a priori di riferimento \u00e8 definita nel limite asintotico, cio\u00e8 si considera il limite delle distribuzioni a priori cos\u00ec ottenute come il numero di dati va all'infinito. Nei problemi multivariati spesso vengono scelte come distribuzioni a priori oggettive le distribuzioni a priori di riferimento, dato che altre scelte (ad esempio la regola di Jeffreys possono portare a distribuzioni a priori dal comportamento problematico.\nDistribuzioni a priori oggettive possono anche essere derivate da altri principi, come le teorie dell'informazione o le teorie della codifica (vedi ad esempio lunghezza di descrizione minima) oppure della statistica frequentista.\nProblemi filosofici legati alle distribuzioni a priori non informative sono associati alla scelta di una metrica appropriata o scala di misurazione. Supponiamo di volere una distribuzione a priori per la valocit\u00e0 di un corridore a noi sconosciuto. Potremmo specificare, diciamo, per la sua velocit\u00e0 una distribuzione a priori di tipo normale, ma in alternativa potremmo specificare una distribuzione a priori normale per il tempo impiegato a percorrere 100 metri, il quale \u00e8 proporzionale al reciproco della prima distribuzione a priori. Queste due distribuzioni a priori sono effettivamente differenti, ma non \u00e8 chiaro quale delle due preferire. Il metodo, spesso sopravvalutato, di trasformazione dei gruppi di Jaynes pu\u00f2 rispondere a tale questione in varie situazioni.\nIn maniera simile, se ci \u00e8 chiesto di stimare una proporzione incognita tra 0 e 1, noi possiamo affermare che tutte le proporzioni sono ugualmente probabili ed usare una distribuzione a priori uniforme. Alternativamente, potremmo dire che tutti gli ordini di grandezza per la proporzione sono ugualmente probabili, e scegliere la distribuzione a priori logaritmica, la quale \u00e8 la distribuzione a priori uniforme sul logaritmo della proporzione. La distribuzione a priori di Jeffreys tenta di risolvere questo problema calcolando una distribuzione a priori che esprime la medesima credenza indipendentemente dalla metrica utilizzata. La distribuzione a priori di Jeffreys per una proporzione incognita \"p\" \u00e8 \"p\"(1\u00a0\u2212\u00a0\"p\"), che differisce da quella raccomandata da Jaynes.\nDistribuzioni a priori basate sulla nozione di probabilit\u00e0 algoritmica vengono impiegate nel campo dell'inferenza induttiva come base induttiva in configurazioni del tutto generali.\nProblemi pratici associati con le distribuzioni a priori non informative includono il requisito che la distribuzione a posteriori sia propria. Le distribuzioni a priori non informative su variabili continue, non limitate sono improprie. Questo non \u00e8 necessariamente un problema se la distribuzione a posteriori \u00e8 propria. Un altro argomento importante \u00e8 quello in cui se una distribuzione a priori non informativa viene usata in maniera regolare, cio\u00e8 con svariati insiemi di dati, allora essa avrebbe buone propriet\u00e0 frequentiste. Normalmente un bayesiano non dovrebbe porsi questo problema, ma potrebbe essere importante farlo in questa situazione. Per esempio, uno potrebbe volere che qualsiasi regola di decisione basata sulla distribuzione a posteriori sia ammissibile sotto la funzionedi perdita adottata. Sfortunatamente, l'ammissibilit\u00e0 \u00e8 difficile da verificare, nonostante vari risultati siano noti (\"cfr.\" ad esempio, Berger and Strawderman, 1996). Il problema \u00e8 particolarmente acuto con i modelli di Bayes gerarchici; le distribuzioni a priori usuali (ad esempio la distribuzione a priori di Jeffreys) possono dare regole di decisione praticamente inammissibili se impiegate ai livelli gerarchici pi\u00f9 elevati.\nSe il teorema di Bayes viene scritto come\nallora \u00e8 chiaro che si otterrebbe il medesimo risultato se tutte le probabilit\u00e0 a priori \"P\"(\"A\") e \"P\"(\"A\") fossero moltiplicate per una data costante; lo stesso sarebbe vero per una variabile casuale continua. Se la sommatoria al denominatore converge, le probabilit\u00e0 a posteriori sommeranno (o integreranno) ancora a 1 anche se i valori della distribuzione a priori non lo fanno, e in tal modo pu\u00f2 solo essere necessario richiedere alle distribuzioni a priori di essere specificate nella proporzione corretta. Spingendo oltre questa idea, in molti casi non \u00e8 neanche richiesto che la somma o l'integrale dei valori della distribuzione a priori sia finita per ottenere risposte significative circa le probabilit\u00e0 a posteriori. Quando questo \u00e8 il caso, la distribuzione a priori \u00e8 chiamata distribuzione a priori impropria. Tuttavia, se la distribuzione a priori \u00e8 impropria, allora non \u00e8 necessario che la distribuzione a posteriori sia propria. Questo \u00e8 chiaro nella situazione in cui l'evento \"B\" \u00e8 indipendente da tutti gli altri eventi \"A\".\nVari statistici usano le distribuzioni a priori improprie come distribuzioni a priori non informative. Per esempio, se hanno bisogno di una distribuzione a priori per la media e la varianza di una variabile casuale, allora essi assumono \"p\"(\"m\",\u00a0\"v\")\u00a0~\u00a01/\"v\" (per \"v\" > 0) il che suggerirebbe che qualsiasi valore per la media \u00e8 \"ugualmente probabile\" e che un valore per la varianza positiva diventa \"meno probabile\" in proporzione inversa al suo valore. Molti autori (Lindley, 1973; De Groot, 1937; Kass and Wasserman, 1996) mettono in guardia contro il pericolo di sovra-interpretare tali distribuzioni a priori poich\u00e9 non sono densit\u00e0 di probabilit\u00e0. La loro sola rilevanza che esse hanno si trova nella distribuzione a posteriori corrispondente, fintanto che questa \u00e8 ben definita per tutte le osservazioni. (La distribuzione a priori di Haldane \u00e8 un tipico controesempio.)\nEsempi di distribuzioni a priori includono:\nIl concetto di probabilit\u00e0 algoritmica fornisce una via per specificare la probabilit\u00e0 delle distribuzioni a priori basata sulla complessit\u00e0 relativa di modelli presi in considerazione e tra loro alternativi."], "concept_B": "Distribuzione di probabilit\u00e0 a priori", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1105351", "Dbscan", "Il DBSCAN (\"Density-Based Spatial Clustering of Applications with Noise\") \u00e8 un metodo di clustering proposto nel 1996 da Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander and Xiaowei Xu. \u00c8 basato sulla densit\u00e0 perch\u00e9 connette regioni di punti con densit\u00e0 sufficientemente alta. DBSCAN \u00e8 l'algoritmo pi\u00f9 comunemente usato ed \u00e8 anche il pi\u00f9 citato nella letteratura scientifica.\nDBSCAN usa una definizione di cluster basata sulla nozione di \"density-reachability\". Un punto formula_1 \u00e8 direttamente raggiungibile da un punto formula_2 se la loro distanza \u00e8 minore di un assegnato formula_3 (cio\u00e8, \u00e8 parte del suo formula_3-vicinato) e se formula_2 \u00e8 circondato da un sufficiente numero di punti, allora formula_2 e formula_1 possono essere considerati parti di un cluster. Il punto formula_1 \u00e8 \"density-reachable\" da formula_2 se c'\u00e8 una sequenza formula_10 di punti con formula_11 e formula_12 dove ogni formula_13 \u00e8 density-reachable direttamente da formula_14. Si osservi che la relazione density-reachable non \u00e8 simmetrica dato che formula_1 potrebbe situarsi su una periferia del cluster, avendo un numero insufficiente di vicini per considerarlo un elemento genuino del cluster. Di conseguenza la nozione \"density-connected\" diventa: due punti formula_2 e formula_1 sono density-connected se c'\u00e8 un punto formula_18 tale che sia formula_18 e formula_2 sia formula_18 e formula_1 sono density-reachable.\nUn cluster, che \u00e8 un sotto-insieme dei punti del database, soddisfa due propriet\u00e0:\nDBSCAN necessita di due parametri: formula_3 (eps) e del numero minimo di punti richiesti per formare un cluster (minPts). Si comincia con un punto casuale che non \u00e8 stato ancora visitato. Viene calcolato il suo formula_3-vicinato e se contiene un numero sufficiente di punti viene creato un nuovo cluster. Se ci\u00f2 non avviene il punto viene etichettato come rumore e successivamente potrebbe essere ritrovato in un formula_3-vicinato sufficientemente grande riconducibile ad un punto differente entrando a far parte di un cluster.\nSe un punto \u00e8 associato ad un cluster anche i punti del suo formula_3-vicinato sono parte del cluster. Conseguentemente tutti i punti trovati all'interno del suo formula_3-vicinato sono aggiunti al cluster, cos\u00ec come i loro formula_3-vicinati. Questo processo continua fino a quando il cluster viene completato. Il processo continua fino a quando non sono stati visitati tutti i punti.\n DBSCAN(D, eps, MinPts)\nDBSCAN visita ogni punto del database, anche pi\u00f9 volte nel caso di punti candidati a cluster differenti. Tuttavia per considerazioni pratiche la complessit\u00e0 temporale \u00e8 per lo pi\u00f9 governata dal numero di invocazioni a getVicini, in riferimento allo pseudo codice di cui sopra. DBSCAN esegue esattamente una invocazione per ogni punto e se viene utilizzata una struttura indicizzata che esegue un'interrogazione del vicinato in formula_29, si ottiene un tempo globale di esecuzione pari a formula_30. Senza l'uso di strutture indicizzate, il tempo di esecuzione \u00e8 pari a formula_31. Spesso la matrice delle distanze di dimensione formula_32 viene creata per evitare appunto il ricalcolo delle distanze riducendo il tempo di elaborazione a spese della memoria utilizzata pari a formula_31.\nDBSCAN presenta i seguenti vantaggi:\nIl rilevamento del vicinato pi\u00f9 vicino avviene nella funzione getVicini(P,epsilon). Per ogni punto P vengono determinati tutti gli altri punti che sono all'interno dell'intervallo epsilon, basandosi sulla funzione della distanza usata nell'algoritmo. L'analisi richiede che sia calcolata una matrice delle distanze per l'intero data set. La generazione della matrice delle distanze ha una complessit\u00e0 di formula_34dato che \u00e8 necessaria solo una matrice triangolare superiore. All'interno della matrice delle distanze il vicinato pi\u00f9 vicino pu\u00f2 essere calcolato selezionando la tupla che ha come valori il minimo delle funzioni su riga e colonna. La ricerca ha spinto il rilevamento del vicinato, nei database tradizionali, per migliorare la velocit\u00e0. Questi ultimi risolvono il problema utilizzando indici specificamente progettati per questo tipo di applicazioni.\nOgni processo di data mining ha il problema dei parametri. Ogni parametro influenza l'algoritmo in modo specifico. Per il DBSCAN i parametri epsilon e MinPnts sono necessari. I parametri devono essere specificati dall'utente dato che ogni data set richiede parametri differenti. Un valore iniziale per formula_3 pu\u00f2 essere determinato come un k-distance graph. Come per le regole del pollice, formula_36 pu\u00f2 essere derivato dal numero di dimensioni nel data set formula_37 come formula_38. Tuttavia valori maggiori sono usualmente migliori per data set con rumore.\nAnche se questa stima dei parametri restituisce un insieme sufficiente di parametri, la classificazione risultante pu\u00f2 rivelarsi diversa da ci\u00f2 che si aspetta, pertanto la ricerca ha realizzato un'incrementale ottimizzazione dei parametri su particolari valori.\nPer ogni oggetto vengono trovati i vicini che ricadono in un raggio dato come parametro in ingresso; se il numero di questi vicini \u00e8 superiore ad un fattore di soglia, anch'esso fornito in input all'algoritmo, allora questi punti fanno parte del medesimo cluster di quello dell'oggetto che si sta osservando e in questo caso il punto \u00e8 denominato core point.\nAl termine dell'algoritmo ci potrebbero essere alcuni punti non appartenenti a cluster catalogati come \"rumore\".\nSe c'\u00e8 una catena di oggetti da attraversare (con i consueti vincoli) per raggiungere un punto \"q\" da uno \"p\", allora \"q\" sar\u00e0 detto semplicemente rintracciabile.\nUltimo caso \u00e8 quello in cui due oggetti \"p\" e \"q\" sono detti connessi: per essere definiti in tal modo, deve esistere un terzo punto \"o\", per cui \"p\" e \"q\" sono entrambi rintracciabili."], "concept_A": "Dbscan", "wikipedia_passage_concept_B": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_B": "Clustering", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["2354612", "Clustering gerarchico", "In statistica e apprendimento automatico, il clustering gerarchico \u00e8 un approccio di clustering che mira a costruire una gerarchia di cluster. Le strategie per il clustering gerarchico sono tipicamente di due tipi:\nIl risultato di un clustering gerarchico \u00e8 rappresentato in un dendrogramma.\nPer decidere quali cluster devono essere combinati (approccio agglomerativo) o quale cluster deve essere suddiviso (approccio divisivo) \u00e8 necessario definire una misura di dissimilarit\u00e0 tra cluster. Nella maggior parte dei metodi di clustering gerarchico si fa uso di metriche specifiche che quantificano la distanza tra coppie di elementi e di un criterio di collegamento che specifica la dissimilarit\u00e0 di due insiemi di elementi (cluster) come funzione della distanza a coppie tra elementi nei due insiemi.\nLa scelta di una metrica appropriata influenza la forma dei cluster, poich\u00e9 alcuni elementi possono essere pi\u00f9 \"vicini\" utilizzando una distanza e pi\u00f9 \"lontani\" utilizzandone un'altra. Per esempio, in uno spazio a 2 dimensioni, la distanza tra il punto (1, 1) e l'origine (0, 0) \u00e8 2, formula_1 or 1 se si utilizzando rispettivamente le norme 1, 2 o infinito.\nMetriche comuni sono le seguenti:\nIl criterio di collegamento (\"linkage criterion\") specifica la distanza tra insiemi di elementi come funzione di distanze tra gli elementi negli insiemi.\nDati due insiemi di elementi \"A\" e \"B\" alcuni criteri comunemente utilizzati sono:\ndove \"d\" \u00e8 la metrica prescelta per determinare la similarit\u00e0 tra coppie di elementi."], "concept_A": "Clustering gerarchico", "wikipedia_passage_concept_B": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_B": "Clustering", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["2246484", "Precisione e recupero", ", o richiamo (in inglese \"precision\" e \"recall\") sono due comuni classificazioni statistiche, utilizzate in diversi ambiti del sapere, come per es. l'information retrieval. La precisione pu\u00f2 essere vista come una misura di \"esattezza\" o fedelt\u00e0, mentre il recupero \u00e8 una misura di \"completezza\".\nNell'Information Retrieval, la precisione \u00e8 definita come il numero di documenti attinenti recuperati da una ricerca diviso il numero totale di documenti recuperati dalla stessa ricerca, e il recupero \u00e8 definito come il numero di documenti attinenti recuperati da una ricerca diviso il numero totale di documenti attinenti esistenti (che dovrebbe essere stato recuperato).\nIn un processo di classificazione statistica, la precisione per una classe \u00e8 il numero di veri positivi (il numero di oggetti etichettati correttamente come appartenenti alla classe) diviso il numero totale di elementi etichettati come appartenenti alla classe (la somma di veri positivi e falsi positivi, che sono oggetti etichettati erroneamente come appartenenti alla classe).\nRecupero in questo contesto \u00e8 definito come il numero di veri positivi diviso il numero totale di elementi che attualmente appartengono alla classe (per esempio la somma di veri positivi e falsi negativi, che sono oggetti che non sono stati etichettati come appartenenti alla classe ma dovrebbero esserlo).\nNell'Information Retrieval, un valore di precisione di 1.0 significa che ogni risultato recuperato da una ricerca \u00e8 attinente mentre un valore di recupero pari a 1.0 significa che tutti i documenti attinenti sono stati recuperati dalla ricerca.\nIn un processo di classificazione, un valore di precisione di 1.0 per la classe C significa che ogni oggetto che \u00e8 stato etichettato come appartenente alla classe C vi appartiene davvero (ma non dice niente sul numero di elementi della classe C che non sono stati etichettati correttamente) mentre un valore di recupero pari ad 1.0 significa che ogni oggetto della classe C \u00e8 stato etichettato come appartenente ad essa (ma non dice niente sul numero di elementi etichettati non correttamente con C).\nNell'information retrieval, precisione e recupero sono definite in termini di insieme di documenti recuperati (lista di documenti restituiti da un motore di ricerca rispetto ad una query) e un insieme di documenti attinenti (lista di tutti i documenti che sono attinenti per l'argomento cercato).\nformula_1\nformula_2\nIn un processo di classificazione, i termini vero positivo, vero negativo, falso positivo e falso negativo sono usati per confrontare la classificazione di un oggetto (l'etichetta di classe assegnata all'oggetto da un classificatore) con la corretta classificazione desiderata (la classe a cui in realt\u00e0 appartiene l'oggetto).\nPrecisione e recupero sono definite come:"], "concept_A": "Precisione e recupero", "wikipedia_passage_concept_B": ["2292", "Ipotesi nulla", "Un'ipotesi nulla (in inglese \"null hypothesis,\" che significa letteralmente ipotesi zero) \u00e8 un'affermazione sulla distribuzione di probabilit\u00e0 di una o pi\u00f9 variabili casuali. Si intende per ipotesi nulla l'affermazione secondo la quale non ci sia differenza oppure non vi sia relazione tra due fenomeni misurati, o associazione tra due gruppi. Solitamente viene assunta vera finch\u00e9 non si trova evidenza che la confuti.\nNel test statistico viene verificata in termini probabilistici la validit\u00e0 di un'ipotesi statistica, detta appunto ipotesi nulla, di solito indicata con \"H\".\nAttraverso una funzione dei dati campionari si decide se accettare l'ipotesi nulla o meno. Nel caso l'ipotesi nulla venga rifiutata si accetter\u00e0 l'ipotesi alternativa, indicata con \"H\".\nSe si rifiuta un'ipotesi nulla che nella realt\u00e0 \u00e8 vera allora si dice che si \u00e8 commesso un errore di prima specie (o falso positivo). Accettando invece un'ipotesi nulla falsa si commette un errore di seconda specie (o falso negativo).\nL'ipotesi pu\u00f2 essere di tipo funzionale se riferita alla forma della f (x;\u03b8) con f funzione di densit\u00e0 o di probabilit\u00e0, o parametrica se riferita al vettore incognito \u03b8.\nL'ipotesi \u00e8 semplice quando specifica completamente la f (x;\u03b8). Nel caso un'ipotesi non sia semplice si dir\u00e0 composta.\nQuando si considera un solo parametro l'ipotesi semplice \u00e8 del tipo \u03b8=\u03b8, dove \u03b8 \u00e8 un valore particolare. Un'ipotesi \u00e8 unilaterale se \u00e8 del tipo \u03b8 > \u03b8 oppure del tipo \u03b8 < \u03b8.\nUn'ipotesi \u00e8 bilaterale se \u00e8 del tipo \u03b8 \u2260 \u03b8 oppure del tipo \u03b8 < \u03b8 e \u03b8 > \u03b8."], "concept_B": "Ipotesi nulla", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1105351", "Dbscan", "Il DBSCAN (\"Density-Based Spatial Clustering of Applications with Noise\") \u00e8 un metodo di clustering proposto nel 1996 da Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander and Xiaowei Xu. \u00c8 basato sulla densit\u00e0 perch\u00e9 connette regioni di punti con densit\u00e0 sufficientemente alta. DBSCAN \u00e8 l'algoritmo pi\u00f9 comunemente usato ed \u00e8 anche il pi\u00f9 citato nella letteratura scientifica.\nDBSCAN usa una definizione di cluster basata sulla nozione di \"density-reachability\". Un punto formula_1 \u00e8 direttamente raggiungibile da un punto formula_2 se la loro distanza \u00e8 minore di un assegnato formula_3 (cio\u00e8, \u00e8 parte del suo formula_3-vicinato) e se formula_2 \u00e8 circondato da un sufficiente numero di punti, allora formula_2 e formula_1 possono essere considerati parti di un cluster. Il punto formula_1 \u00e8 \"density-reachable\" da formula_2 se c'\u00e8 una sequenza formula_10 di punti con formula_11 e formula_12 dove ogni formula_13 \u00e8 density-reachable direttamente da formula_14. Si osservi che la relazione density-reachable non \u00e8 simmetrica dato che formula_1 potrebbe situarsi su una periferia del cluster, avendo un numero insufficiente di vicini per considerarlo un elemento genuino del cluster. Di conseguenza la nozione \"density-connected\" diventa: due punti formula_2 e formula_1 sono density-connected se c'\u00e8 un punto formula_18 tale che sia formula_18 e formula_2 sia formula_18 e formula_1 sono density-reachable.\nUn cluster, che \u00e8 un sotto-insieme dei punti del database, soddisfa due propriet\u00e0:\nDBSCAN necessita di due parametri: formula_3 (eps) e del numero minimo di punti richiesti per formare un cluster (minPts). Si comincia con un punto casuale che non \u00e8 stato ancora visitato. Viene calcolato il suo formula_3-vicinato e se contiene un numero sufficiente di punti viene creato un nuovo cluster. Se ci\u00f2 non avviene il punto viene etichettato come rumore e successivamente potrebbe essere ritrovato in un formula_3-vicinato sufficientemente grande riconducibile ad un punto differente entrando a far parte di un cluster.\nSe un punto \u00e8 associato ad un cluster anche i punti del suo formula_3-vicinato sono parte del cluster. Conseguentemente tutti i punti trovati all'interno del suo formula_3-vicinato sono aggiunti al cluster, cos\u00ec come i loro formula_3-vicinati. Questo processo continua fino a quando il cluster viene completato. Il processo continua fino a quando non sono stati visitati tutti i punti.\n DBSCAN(D, eps, MinPts)\nDBSCAN visita ogni punto del database, anche pi\u00f9 volte nel caso di punti candidati a cluster differenti. Tuttavia per considerazioni pratiche la complessit\u00e0 temporale \u00e8 per lo pi\u00f9 governata dal numero di invocazioni a getVicini, in riferimento allo pseudo codice di cui sopra. DBSCAN esegue esattamente una invocazione per ogni punto e se viene utilizzata una struttura indicizzata che esegue un'interrogazione del vicinato in formula_29, si ottiene un tempo globale di esecuzione pari a formula_30. Senza l'uso di strutture indicizzate, il tempo di esecuzione \u00e8 pari a formula_31. Spesso la matrice delle distanze di dimensione formula_32 viene creata per evitare appunto il ricalcolo delle distanze riducendo il tempo di elaborazione a spese della memoria utilizzata pari a formula_31.\nDBSCAN presenta i seguenti vantaggi:\nIl rilevamento del vicinato pi\u00f9 vicino avviene nella funzione getVicini(P,epsilon). Per ogni punto P vengono determinati tutti gli altri punti che sono all'interno dell'intervallo epsilon, basandosi sulla funzione della distanza usata nell'algoritmo. L'analisi richiede che sia calcolata una matrice delle distanze per l'intero data set. La generazione della matrice delle distanze ha una complessit\u00e0 di formula_34dato che \u00e8 necessaria solo una matrice triangolare superiore. All'interno della matrice delle distanze il vicinato pi\u00f9 vicino pu\u00f2 essere calcolato selezionando la tupla che ha come valori il minimo delle funzioni su riga e colonna. La ricerca ha spinto il rilevamento del vicinato, nei database tradizionali, per migliorare la velocit\u00e0. Questi ultimi risolvono il problema utilizzando indici specificamente progettati per questo tipo di applicazioni.\nOgni processo di data mining ha il problema dei parametri. Ogni parametro influenza l'algoritmo in modo specifico. Per il DBSCAN i parametri epsilon e MinPnts sono necessari. I parametri devono essere specificati dall'utente dato che ogni data set richiede parametri differenti. Un valore iniziale per formula_3 pu\u00f2 essere determinato come un k-distance graph. Come per le regole del pollice, formula_36 pu\u00f2 essere derivato dal numero di dimensioni nel data set formula_37 come formula_38. Tuttavia valori maggiori sono usualmente migliori per data set con rumore.\nAnche se questa stima dei parametri restituisce un insieme sufficiente di parametri, la classificazione risultante pu\u00f2 rivelarsi diversa da ci\u00f2 che si aspetta, pertanto la ricerca ha realizzato un'incrementale ottimizzazione dei parametri su particolari valori.\nPer ogni oggetto vengono trovati i vicini che ricadono in un raggio dato come parametro in ingresso; se il numero di questi vicini \u00e8 superiore ad un fattore di soglia, anch'esso fornito in input all'algoritmo, allora questi punti fanno parte del medesimo cluster di quello dell'oggetto che si sta osservando e in questo caso il punto \u00e8 denominato core point.\nAl termine dell'algoritmo ci potrebbero essere alcuni punti non appartenenti a cluster catalogati come \"rumore\".\nSe c'\u00e8 una catena di oggetti da attraversare (con i consueti vincoli) per raggiungere un punto \"q\" da uno \"p\", allora \"q\" sar\u00e0 detto semplicemente rintracciabile.\nUltimo caso \u00e8 quello in cui due oggetti \"p\" e \"q\" sono detti connessi: per essere definiti in tal modo, deve esistere un terzo punto \"o\", per cui \"p\" e \"q\" sono entrambi rintracciabili."], "concept_A": "Dbscan", "wikipedia_passage_concept_B": ["3216546", "Analisi dei dati", "Nell'ambito della scienza dei dati l'analisi dei dati \u00e8 un processo di ispezione, pulizia, trasformazione e modellazione di dati con il fine di evidenziare informazioni che suggeriscano conclusioni e supportino le decisioni strategiche aziendali. L'analisi di dati ha molti approcci e sfaccettature, il che comprende tecniche diversissime tra loro che si riconoscono con una serie di definizioni varie nel commercio, le scienze naturali e sociali.\nIl data mining \u00e8 una tecnica particolare di analisi dei dati che si focalizza nella modellazione e scoperta di conoscenza per scopi predittivi piuttosto che descrittivi. Il business intelligence identifica l'analisi di dati che si basa fondamentalmente sull'aggregazione, focalizzandosi sulle informazioni aziendali. Nell'ambito dei big data si parla di big data analytics. Nelle applicazioni statistiche, gli studiosi dividono l'analisi dei dati in statistica descrittiva, analisi dei dati esplorativa (ADE) e analisi dei dati di conferma (ADC). L'ADE si concentra sullo scoprire nuove caratteristiche presenti nei dati, mentre l'ADC nel confermare o falsificare le ipotesi esistenti. L'analisi predittiva si concentra sull'applicazione di modelli statistici o strutturali per classificazione o il forecasting predittivo, mentre l'analisi testuale applica tecniche statistiche, linguistiche e strutturali per estrarre e classificare informazioni da fonti testuali, una categoria di dati non-strutturati.\nL'integrazione di dati \u00e8 un precursore dell'analisi dei dati, la quale \u00e8 collegata alla visualizzazione di dati."], "concept_B": "Analisi dei dati", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["100003", "Albero di decisione", "Nella teoria delle decisioni (per esempio nella gestione dei rischi), un albero di decisione \u00e8 un grafo di decisioni e delle loro possibili conseguenze, (incluso i relativi costi, risorse e rischi) utilizzato per creare un 'piano di azioni' (\"plan\") mirato ad uno scopo (\"goal\"). Un albero di decisione \u00e8 costruito al fine di supportare l'azione decisionale (\"decision making\").\nNel machine learning un albero di decisione \u00e8 un modello predittivo, dove ogni nodo interno rappresenta una variabile, un arco verso un nodo figlio rappresenta un possibile valore per quella propriet\u00e0 e una foglia il valore predetto per la variabile obiettivo a partire dai valori delle altre propriet\u00e0, che nell'albero \u00e8 rappresentato dal cammino (\"path\") dal nodo radice (\"root\") al nodo foglia.\nNormalmente un albero di decisione viene costruito utilizzando tecniche di apprendimento a partire dall'insieme dei dati iniziali (\"data set\"), il quale pu\u00f2 essere diviso in due sottoinsiemi: il \"training set\" sulla base del quale si crea la struttura dell'albero e il \"test set\" che viene utilizzato per testare l'accuratezza del modello predittivo cos\u00ec creato.\nNel data mining un albero di decisione viene utilizzato per classificare le istanze di grandi quantit\u00e0 di dati (per questo viene anche chiamato albero di classificazione). In questo ambito un albero di decisione descrive una struttura ad albero dove i nodi foglia rappresentano le classificazioni e le ramificazioni l'insieme delle propriet\u00e0 che portano a quelle classificazioni. Di conseguenza ogni nodo interno risulta essere una macro-classe costituita dall'unione delle classi associate ai suoi nodi figli.\nIl predicato che si associa ad ogni nodo interno (sulla base del quale avviene la ripartizione dei dati) \u00e8 chiamato \"condizione di split\".\nIn molte situazioni \u00e8 utile definire un criterio di arresto (\"halting\"), o anche \"criterio di potatura\" (\"pruning\") al fine di determinarne la profondit\u00e0 massima. Questo perch\u00e9 il crescere della profondit\u00e0 di un albero (ovvero della sua dimensione) non influisce direttamente sulla bont\u00e0 del modello. Infatti, una crescita eccessiva della dimensione dell'albero potrebbe portare solo ad aumento sproporzionato della complessit\u00e0 computazionale rispetto ai benefici riguardanti l'accuratezza delle previsioni/classificazioni.\nUna sua evoluzione \u00e8 la tecnica foresta casuale (\"random forest\").\nI parametri pi\u00f9 largamente usati per le condizioni di split sono:\nformula_1\nL'indice di Gini raggiunge il suo minimo (zero) quando il nodo appartiene ad una singola categoria. \nformula_2\nIn entrambe le formule \"f\" rappresenta la frequenza del valore \"j\" nel nodo \"i\".\nL'indice di Gini e la variazione di entropia sono i parametri che vengono usualmente utilizzati per guidare la costruzione dell'albero, mentre la valutazione del tasso di errore nella classificazione viene utilizzato per effettuare una ottimizzazione dell'albero nota come processo di \"pruning\" (\"potatura\" dei nodi superflui). Poich\u00e9, in generale, in un buon albero di decisione i nodi foglia dovrebbero essere il pi\u00f9 possibile \"puri\" (ovvero contenere solo istanze di dati che appartengono ad una sola classe), un'ottimizzazione dell'albero consiste nel cercare di minimizzare il livello di entropia man mano che si scende dalla radice verso le foglie. In tal senso, la valutazione dell'entropia determina quali sono, fra le varie scelte a disposizione, le condizioni di split ottimali per l'albero di classificazione."], "concept_A": "Albero di decisione", "wikipedia_passage_concept_B": ["3612028", "Classificazione statistica", "La classificazione statistica \u00e8 quell'attivit\u00e0 che si serve di un algoritmo statistico al fine di individuare una rappresentazione di alcune caratteristiche di un'entit\u00e0 da classificare (oggetto o nozione), associandole una etichetta classificatoria. Tale attivit\u00e0 pu\u00f2 essere svolta mediante algoritmi di apprendimento automatico supervisionato o non supervisionato. Esempi di questi algoritmi sono:\nI programmi che effettuano l'attivit\u00e0 di classificazione sono detti classificatori. Talora si usa l'aggettivo \"statistica\" anche per classificazioni utilizzate per costruire indicazioni statistiche sulle entit\u00e0 assegnate ai diversi contenitori di una classificazione, soprattutto nel caso delle tassonomie, mentre nella definizione della classificazione non si sono utilizzati precisi metodi statistici."], "concept_B": "Classificazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["1216500", "Bootstrap (statistica)", "Il bootstrap \u00e8 una tecnica statistica di ricampionamento con reimmissione per approssimare la distribuzione campionaria di una statistica. \nPermette perci\u00f2 di approssimare media e varianza di uno stimatore, costruire intervalli di confidenza e calcolare p-values di test quando, in particolare, non si conosce la distribuzione della statistica di interesse.\nNel caso semplice di campionamento casuale semplice, il funzionamento \u00e8 il seguente: consideriamo un campione effettivamente osservato di numerosit\u00e0 pari ad \"n\", diciamo formula_1. Da formula_2 si ricampionano \"m\" altri campioni di numerosit\u00e0 costante pari ad \"n\", diciamo formula_3; in ciascuna estrazione bootstrap, i dati provenienti dal primo elemento del campione, cio\u00e8 formula_4, possono essere estratti pi\u00f9 di una volta e ciascun dato ha probabilit\u00e0 pari a \"1/n\" di essere estratto.\nSia formula_5 lo stimatore di formula_6 che ci interessa studiare, diciamo formula_7. Si calcola tale quantit\u00e0 per ogni campione bootstrap, formula_8. In questo modo si hanno a disposizione \"m\" stime di formula_6, dalle quali \u00e8 possibile calcolare la media bootstrap, la varianza bootstrap, i percentili bootstrap etc. che sono approssimazioni dei corrispondenti valori ignoti e portano informazioni sulla distribuzione di formula_10. \nPartendo quindi da queste quantit\u00e0 stimate \u00e8 possibile calcolare intervalli di confidenza, saggiare ipotesi, etc."], "concept_B": "Bootstrap (statistica)", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_A": "Rete bayesiana", "wikipedia_passage_concept_B": ["71808", "Funzione di verosimiglianza", "In statistica, la funzione di verosimiglianza (o funzione di likelihood) \u00e8 una funzione di probabilit\u00e0 condizionata, considerata come funzione del suo \"secondo\" argomento, mantenendo fissato il primo argomento.\nIn gergo colloquiale spesso \"verosimiglianza\" \u00e8 usato come sinonimo di \"probabilit\u00e0\", ma in campo statistico vi \u00e8 una distinzione tecnica precisa. Questo esempio chiarisce la differenza tra i due concetti: una persona potrebbe chiedere \"Se lanciassi una moneta non truccata 100 volte, qual \u00e8 la probabilit\u00e0 che esca testa tutte le volte?\" oppure \"Dato che ho lanciato una moneta 100 volte ed \u00e8 uscita testa 100 volte, qual \u00e8 la verosimiglianza che la moneta sia truccata?\". Scambiare tra loro, nelle due frasi, i termini \"verosimiglianza\" e \"probabilit\u00e0\" sarebbe errato.\nUna distribuzione di probabilit\u00e0 che dipende da un parametro pu\u00f2 essere considerata in due modi differenti:\nFormalmente la funzione di verosimiglianza \u00e8 una funzione:\nSi definisce ancora funzione di verosimiglianza ogni funzione proporzionale a tale probabilit\u00e0. Dunque, la funzione di verosimiglianza per formula_2 \u00e8 la classe delle funzioni:\nper ogni costante formula_4. A causa di ci\u00f2, l'esatto valore di formula_5 non \u00e8 in generale rilevante; ci\u00f2 che \u00e8 importante sono rapporti nella forma: formula_6, invarianti rispetto alla costante di proporzionalit\u00e0.\nA livello interpretativo, l'uso di una funzione di verosimiglianza trae giustificazione dal teorema di Bayes, in base al quale, per due qualsiasi eventi formula_7 e formula_2:\ndove sia formula_10 che formula_11 sono funzioni di verosimiglianza. L'uso di funzioni di verosimiglianza ai fini dell'inferenza statistica costituisce un tratto distintivo dell'inferenza classica, o \"frequentista\"; esso rappresenta inoltre una fondamentale differenza rispetto alla scuola dell'inferenza bayesiana, in quanto lo statistico bayesiano conduce inferenza tramite la probabilit\u00e0 formula_12 nell'espressione sopra.\nAlcune idee relative alla funzione di verosimiglianza sembrano essere state introdotte da T. N. Thiele in un lavoro del 1889. Il primo contributo in cui il concetto di funzione di verosimiglianza \u00e8 esplicitamente formulato \u00e8 tuttavia dovuto a Ronald Fisher in un suo lavoro del 1922. In tale lavoro, Fisher usa inoltre l'espressione metodo della massima verosimiglianza; argomenta inoltre contro il ricorso alla condizionata nella forma formula_13 nell'espressione sopra, da lui ritenuta ingiustificabile a causa dell'elemento di soggettivit\u00e0 introdotto tramite la probabilit\u00e0 \"a priori\" (nel linguaggio che ora \u00e8 proprio della statistica bayesiana) formula_14. \nIl metodo della massima verosimiglianza ha le sue applicazioni pi\u00f9 rilevanti nella prassi come metodo di stima di modelli parametrici. Considerando un insieme di osservazioni formula_15, e una famiglia di funzioni di densit\u00e0 (o di massa, nel caso di distribuzioni discrete), parametrizzate tramite il vettore formula_16:\nla funzione di verosimiglianza associata \u00e8:\nNel caso in cui, come normalmente si ipotizza, gli formula_19 siano indipendenti e identicamente distribuiti, inoltre:\nPoich\u00e9 l'espressione sopra pu\u00f2 risultare scarsamente trattabile, specie nei problemi di massimizzazione collegati al metodo della massima verosimiglianza, spesso risulta preferibile lavorare sul logaritmo della funzione di verosimiglianza, in gergo chiamata \"log-verosimiglianza\":"], "concept_B": "Funzione di verosimiglianza", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_A": "Data mining", "wikipedia_passage_concept_B": ["1844568", "Analisi della regressione", "L'analisi della regressione \u00e8 una tecnica usata per analizzare una serie di dati che consistono in una variabile dipendente e una o pi\u00f9 variabili indipendenti. Lo scopo \u00e8 stimare un'eventuale relazione funzionale esistente tra la variabile dipendente e le variabili indipendenti. La variabile dipendente nell'\"equazione di regressione\" \u00e8 una funzione delle variabili indipendenti pi\u00f9 un \"termine d'errore\". Quest'ultimo \u00e8 una variabile casuale e rappresenta una variazione non controllabile e imprevedibile nella variabile dipendente. I parametri sono stimati in modo da descrivere al meglio i dati. Il metodo pi\u00f9 comunemente utilizzato per ottenere le migliori stime \u00e8 il metodo dei \"minimi quadrati\" (OLS), ma sono utilizzati anche altri metodi.\nIl \"data modeling\" pu\u00f2 essere usato senza alcuna conoscenza dei processi sottostanti che hanno generato i dati; in questo caso il modello \u00e8 un modello empirico. Inoltre, nella modellizzazione, non \u00e8 richiesta la conoscenza della distribuzione di probabilit\u00e0 degli errori. L'analisi della regressione richiede ipotesi riguardanti la distribuzione di probabilit\u00e0 degli errori. Test statistici vengono effettuati sulla base di tali ipotesi. Nell'analisi della regressione il termine \"modello\" comprende sia la funzione usata per modellare i dati che le assunzioni concernenti la distribuzione di probabilit\u00e0.\nL'analisi della regressione pu\u00f2 essere usata per effettuare previsioni (ad esempio per prevedere dati futuri di una serie temporale), inferenza statistica, per testare ipotesi o per modellare delle relazioni di dipendenza. Questi usi della regressione dipendono fortemente dal fatto che le assunzioni di partenza siano verificate. L'uso dell'analisi della regressione \u00e8 stato criticato in diversi casi in cui le ipotesi di partenza non possono essere verificate. Un fattore che contribuisce all'uso improprio della regressione \u00e8 che richiede pi\u00f9 competenze per criticare un modello che per adattarlo.\nLa prima forma di regressione fu il metodo dei minimi quadrati, pubblicato da Legendre nel 1805, e da Gauss nel 1809. Il termine \u201cminimi quadrati\u201d deriva da quello usato da Legendre: \"moindres carr\u00e9s\". Tuttavia, Gauss afferm\u00f2 di essere a conoscenza di questo metodo fin dal 1795.\nLegendre e Gauss applicarono entrambi il metodo al problema di determinare, a partire da osservazioni astronomiche, l'orbita dei pianeti attorno al Sole. Eulero aveva lavorato sullo stesso problema intorno al 1748, ma senza successo. Gauss pubblic\u00f2 un ulteriore sviluppo della teoria dei minimi quadrati nel 1821, includendo una versione del teorema di Gauss-Markov.\nIl termine \"regressione\" venne coniato nel diciannovesimo secolo per descrivere un fenomeno biologico, ovvero che la progenie di individui eccezionali tende in genere ad essere meno eccezionale dei propri genitori e pi\u00f9 simile ai loro avi pi\u00f9 distanti. Francis Galton, un cugino di Charles Darwin, studi\u00f2 questo fenomeno e applic\u00f2 il termine vagamente fuorviante di \"regressione verso il centro/regressione verso la media\". Per Galton, la regressione aveva solo questo significato biologico, ma il suo lavoro venne in seguito esteso da Udny Yule e Karl Pearson in un contesto statistico pi\u00f9 generale. Oggi il termine \"regressione\" \u00e8 spesso sinonimo di \"curva intercetta dei minimi quadrati\".\nQueste condizioni sono sufficienti (ma non tutte necessarie) perch\u00e9 lo stimatore dei minimi quadrati goda di buone propriet\u00e0. In particolare queste assunzioni implicano che lo stimatore sia non distorto, consistente ed efficiente nella classe degli stimatori lineari non distorti. Molte di queste assunzioni possono essere rilassate in analisi pi\u00f9 avanzate.\nNella regressione lineare, il modello assume che la variabile dipendente, formula_1 sia una combinazione lineare dei \"parametri\" (ma non \u00e8 necessario che sia lineare nella \"variabile indipendente\"). Ad esempio, nella regressione lineare semplice con formula_2 osservazioni ci sono una variabile indipendente: formula_3, e due parametri, formula_4 e formula_5:\nNella regressione lineare multipla, ci sono pi\u00f9 variabili indipendenti o funzioni di variabili indipendenti. Ad esempio, aggiungendo un termine in formula_7 alla regressione precedente si ottiene:\nSi tratta ancora di una regressione lineare: sebbene l'espressione sulla destra sia quadratica nella variabile indipendente formula_3, \u00e8 comunque lineare nei parametri formula_4, formula_5 e formula_12\nIn entrambi i casi, formula_13 \u00e8 un termine di errore e l'indice formula_14 identifica una particolare osservazione. Dato un campione casuale della popolazione, stimiamo i parametri della popolazione e otteniamo il modello di regressione lineare semplice:\nIl termine formula_16 \u00e8 il residuo, formula_17. Un metodo di stima \u00e8 quello dei minimi quadrati ordinari. Questo metodo ottiene le stime dei parametri che minimizzano la somma dei quadrati dei residui, SSE:\nLa minimizzazione di questa funzione risulta essere un sistema di equazioni normali, un insieme di equazioni lineari simultanee nei parametri, che vengono risolte per trovare le stime dei parametri, formula_19. Vedi coefficienti di regressione per informazioni sulle propriet\u00e0 statistiche di tali stimatori.\nNel caso della regressione semplice, le formule per le stime dei minimi quadrati sono \ndove formula_22 \u00e8 la media (media) dei valori formula_23 e formula_24 \u00e8 la media dei valori formula_25.\nSotto l'ipotesi che il termine di errore della popolazione abbia una varianza costante, la stima di quella varianza \u00e8 data da:\nformula_26\nQuesto \u00e8 la radice dell'errore quadratico medio (RMSE) della regressione. \nGli errori standard delle stime dei parametri sono dati da\nSotto l'ulteriore ipotesi che il termine di errore della popolazione abbia distribuzione normale, il ricercatore pu\u00f2 usare questi errori standard stimati per creare intervalli di confidenza e condurre test d'ipotesi sui parametri della popolazione.\nNel pi\u00f9 generale modello di regressione multipla, ci sono formula_29 variabili indipendenti:\nLe stime dei parametri dei minimi quadrati sono ottenute da formula_29 equazioni normali. Il residuo pu\u00f2 essere scritto come\nLe equazioni normali sono\nIn notazione matriciale, le equazioni normali sono scritte come\nUna volta costruito un modello di regressione, \u00e8 importante confermare la bont\u00e0 di adattamento del modello e la significativit\u00e0 statistica dei parametri stimati. I controlli della bont\u00e0 di adattamento comunemente usati includono l'indice R-quadro, analisi dei residui e test di ipotesi. La significativit\u00e0 statistica \u00e8 verificata con un test F dell'adattamento globale, seguito da t-test per ogni singolo parametro.\nL'interpretazione di questi test dipende fortemente dalle assunzioni sul modello. Nonostante l'analisi dei residui sia usata per determinare la bont\u00e0 di un modello, i risultati dei test-T e dei test-F sono difficili da interpretare nel caso in cui le assunzioni di partenza non siano soddisfatte. Ad esempio, se la distribuzione degli errori non \u00e8 normale, pu\u00f2 accadere che in campioni di numerosit\u00e0 ridotta le stime dei parametri non seguano una distribuzione normale, cosa che complica l'inferenza. Per grandi campioni, il teorema del limite centrale permette di effettuare i test usando un'approssimazione asintotica delle distribuzioni.\nLa variabile risposta pu\u00f2 essere non continua. Per le variabili binarie (zero/uno), si pu\u00f2 procedere con un particolare tipo di modello lineare linear probability model. Se si usa un modello non-lineare i modelli pi\u00f9 utilizzati sono il probit e il modello logit. Il modello probit multivariato rende possibile stimare congiuntamente la relazione tra pi\u00f9 variabili binarie dipendenti e alcune variabili indipendenti. Per variabili categoriche con pi\u00f9 di due valori si utilizza il modello logit multinomiale. Per variabili ordinali con pi\u00f9 di due valori, si utilizzano i modelli logit cumulativo e probit cumulativo. Un'alternativa a tali procedure \u00e8 la regressione lineare basata su polychoric o polyserial correlazioni tra le variabili categoriche. Tali procedure differiscono nelle ipotesi fatte sulla distribuzione delle variabili nella popolazione. Se la variabile rappresenta una ripetizione di un evento nel tempo, \u00e8 positiva e con poche realizzazioni (\"eventi rari\"), si possono utilizzare modelli di Poisson o binomiale negativa.\nI modelli di regressione predicono una variabile formula_25 partendo dai valori di altre variabili formula_23. Se i valori della previsione sono compresi nell'intervallo dei valori delle variabili formula_23 utilizzate per la costruzione del modello si parla di interpolazione. Se i valori escono dal range delle variabili esplicative si parla di estrapolazione. In questo caso la previsione diventa pi\u00f9 rischiosa.\nQuando la funzione del modello non \u00e8 lineare nei parametri la somma dei quadrati deve essere minimizzata da una procedura iterativa.\nSebbene i parametri di un modello di regressione siano di solito stimati usando il metodo dei minimi quadrati, altri metodi includono:\nTutti i principali pacchetti statistici eseguono i tipi comuni di analisi di regressione correttamente e in modo semplice. La regressione lineare semplice pu\u00f2 essere fatta in alcuni fogli elettronici. C'\u00e8 una quantit\u00e0 di programmi che esegue forme specializzate di regressione, e gli esperti possono scegliere di scrivere il loro proprio codice per usare o software per analisi numerica."], "concept_B": "Analisi della regressione", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_A": "Intervallo di confidenza", "wikipedia_passage_concept_B": ["847", "Campionamento statistico", "In statistica il campionamento statistico (che si appoggia alla teoria dei campioni o teoria del campionamento), sta alla base dell'inferenza statistica, la quale si divide in due grandi capitoli: la teoria della stima e la verifica d'ipotesi.\nIn particolare, una rilevazione si dice \"campionaria\" quando \u00e8 utile per fare inferenza ossia per desumere dal campione stesso un'informazione relativa all'intera popolazione.\nLe indagini censuarie riguardano l'intera popolazione e pur essendo pi\u00f9 affidabili riguardo al parametro oggetto d'indagine soffrono di:\nQuindi mentre l'indagine censuaria fornisce il valore vero dei parametri di interesse (proporzioni, percentuali, medie, totali...) quella campionaria restituisce una sua stima al quale \u00e8 associato un certo grado di fiducia (ovvero un'incertezza) quantificabile quando la formazione del campione risponde a determinati criteri di tipo probabilistico.\nIl campionamento si usa quando si vuole conoscere uno o pi\u00f9 parametri di una popolazione, senza doverne analizzare ogni elemento: questo per motivi di costi intesi in termini monetari, di tempo, di qualit\u00e0 o di disagio o perch\u00e9 analizzare un elemento lo distrugge rendendo inutilizzabile l'informazione ottenuta.\nModalit\u00e0 di selezione del campione sono:\nNella pratica quotidiana dei sondaggi di opinione e delle ricerche di mercato vengono usati tutti e quattro gli approcci.\nLa scelta di un tipo di campionamento avviene in base alle propriet\u00e0 degli stimatori di alcuni parametri oppure per tener conto di problemi di costo, mobilit\u00e0 o altro.\nConcetti chiave sono:\nBench\u00e9 gi\u00e0 nel Settecento si sia notato il vantaggio nell'esaminare un sottinsieme della popolazione per generalizzare i risultati alla popolazione complessiva, \u00e8 solo dalla fine dell'Ottocento che la discussione sulla \"scientificit\u00e0\" del campionamento viene posta in modo esplicito alla comunit\u00e0 statistica.\nGi\u00e0 agli inizi del Novecento si vanno delineando le caratteristiche che un campione deve avere, ovvero che deve essere scelto in maniera casuale, e nell'arco di pochi anni compaiono i primi studi che mettono in evidenza che il campione non deve essere necessariamente un campione semplice ma pu\u00f2 essere pi\u00f9 complesso, per esempio stratificando.\nImportanti autori che hanno fatto la storia della teoria dei campioni sono stati tra gli altri: \nNel 1925, durante il congresso di Roma, l'Istituto Internazionale di Statistica accetta definitivamente come scientifico il metodo campionario, distinguendo il campionamento casuale dal campionamento ragionato.\nAltri autori importanti nella ricerca teorica ed applicata sul campionamento furono George Gallup e William G. Cochran."], "concept_B": "Campionamento statistico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_A": "Test di verifica d'ipotesi", "wikipedia_passage_concept_B": ["847", "Campionamento statistico", "In statistica il campionamento statistico (che si appoggia alla teoria dei campioni o teoria del campionamento), sta alla base dell'inferenza statistica, la quale si divide in due grandi capitoli: la teoria della stima e la verifica d'ipotesi.\nIn particolare, una rilevazione si dice \"campionaria\" quando \u00e8 utile per fare inferenza ossia per desumere dal campione stesso un'informazione relativa all'intera popolazione.\nLe indagini censuarie riguardano l'intera popolazione e pur essendo pi\u00f9 affidabili riguardo al parametro oggetto d'indagine soffrono di:\nQuindi mentre l'indagine censuaria fornisce il valore vero dei parametri di interesse (proporzioni, percentuali, medie, totali...) quella campionaria restituisce una sua stima al quale \u00e8 associato un certo grado di fiducia (ovvero un'incertezza) quantificabile quando la formazione del campione risponde a determinati criteri di tipo probabilistico.\nIl campionamento si usa quando si vuole conoscere uno o pi\u00f9 parametri di una popolazione, senza doverne analizzare ogni elemento: questo per motivi di costi intesi in termini monetari, di tempo, di qualit\u00e0 o di disagio o perch\u00e9 analizzare un elemento lo distrugge rendendo inutilizzabile l'informazione ottenuta.\nModalit\u00e0 di selezione del campione sono:\nNella pratica quotidiana dei sondaggi di opinione e delle ricerche di mercato vengono usati tutti e quattro gli approcci.\nLa scelta di un tipo di campionamento avviene in base alle propriet\u00e0 degli stimatori di alcuni parametri oppure per tener conto di problemi di costo, mobilit\u00e0 o altro.\nConcetti chiave sono:\nBench\u00e9 gi\u00e0 nel Settecento si sia notato il vantaggio nell'esaminare un sottinsieme della popolazione per generalizzare i risultati alla popolazione complessiva, \u00e8 solo dalla fine dell'Ottocento che la discussione sulla \"scientificit\u00e0\" del campionamento viene posta in modo esplicito alla comunit\u00e0 statistica.\nGi\u00e0 agli inizi del Novecento si vanno delineando le caratteristiche che un campione deve avere, ovvero che deve essere scelto in maniera casuale, e nell'arco di pochi anni compaiono i primi studi che mettono in evidenza che il campione non deve essere necessariamente un campione semplice ma pu\u00f2 essere pi\u00f9 complesso, per esempio stratificando.\nImportanti autori che hanno fatto la storia della teoria dei campioni sono stati tra gli altri: \nNel 1925, durante il congresso di Roma, l'Istituto Internazionale di Statistica accetta definitivamente come scientifico il metodo campionario, distinguendo il campionamento casuale dal campionamento ragionato.\nAltri autori importanti nella ricerca teorica ed applicata sul campionamento furono George Gallup e William G. Cochran."], "concept_B": "Campionamento statistico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["5960762", "Retropropagazione dell'errore", "La retropropagazione dell'errore (in lingua inglese \"backward propagation of errors\", solitamente abbreviato in backpropagation), \u00e8 un algoritmo per l'allenamento delle reti neurali artificiali, usato in combinazione con un metodo di ottimizzazione come per esempio la discesa stocastica del gradiente.\nLa retropropagazione richiede un'uscita desiderata per ogni valore in ingresso per poter calcolare il gradiente della funzione di perdita (funzione di costo). Viene considerato quindi un metodo di apprendimento supervisionato, sebbene venga usato anche in reti non supervisionate come gli autocodificatori o Reti Diabolo.\n\u00c8 una generalizzazione della regola delta di reti feed-forward multistrato, resa possibile usando la regola di catena che iterativamente calcola i gradienti per ogni strato.\nLa retropropagazione richiede che la funzione d'attivazione usata dai neuroni artificiali (o \"nodi\") sia differenziabile.\nUna delle principali difficolt\u00e0 nell'uso della retropropagazione dell'errore \u00e8 il problema noto come scomparsa del gradiente, dovuto all'uso di funzioni di attivazione non lineari che causano una diminuzione esponenziale del valore del gradiente all'aumentare della profondit\u00e0 della rete neurale."], "concept_A": "Retropropagazione dell'errore", "wikipedia_passage_concept_B": ["605", "Apprendimento automatico", "L\u2019apprendimento automatico (noto anche come machine learning) \u00e8 una branca dell'intelligenza artificiale che raccoglie un insieme di metodi, sviluppati a partire dagli ultimi decenni del XX secolo in varie comunit\u00e0 scientifiche, sotto diversi nomi quali: statistica computazionale, riconoscimento di pattern, reti neurali artificiali, filtraggio adattivo, teoria dei sistemi dinamici, elaborazione delle immagini, data mining, algoritmi adattivi, ecc; che utilizza metodi statistici per migliorare progressivamente la performance di un algoritmo nell'identificare pattern nei dati. Nell'ambito dell'informatica, l'apprendimento automatico \u00e8 una variante alla programmazione tradizionale nella quale si predispone in una macchina l'abilit\u00e0 di apprendere qualcosa dai dati in maniera autonoma, senza ricevere istruzioni esplicite a riguardo.\nLo stesso Arthur Samuel che coni\u00f2 il termine nel 1959 in linea di principio identifica due approcci distinti. Il primo metodo, indicato come rete neurale, porta allo sviluppo di macchine ad apprendimento automatico per impiego generale in cui il comportamento \u00e8 appreso da una rete di commutazione connessa casualmente, a seguito di una routine di apprendimento basata su ricompensa e punizione (apprendimento per rinforzo). Il secondo metodo, pi\u00f9 specifico, consiste nel riprodurre l'equivalente di una rete altamente organizzata progettata per imparare solo alcune attivit\u00e0 specifiche. La seconda procedura, che necessita di supervisione, richiede la riprogrammazione per ogni nuova applicazione, ma risulta essere molto pi\u00f9 efficiente dal punto di vista computazionale.\nL'apprendimento automatico \u00e8 strettamente legato al riconoscimento di pattern e alla teoria computazionale dell'apprendimento ed esplora lo studio e la costruzione di algoritmi che possano apprendere da un insieme di dati e fare delle predizioni su questi, costruendo in modo induttivo un modello basato su dei campioni. L'apprendimento automatico viene impiegato in quei campi dell'informatica nei quali progettare e programmare algoritmi espliciti \u00e8 impraticabile; tra le possibili applicazioni citiamo il filtraggio delle email per evitare spam, l'individuazione di intrusioni in una rete o di intrusi che cercano di violare dati, il riconoscimento ottico dei caratteri, i motori di ricerca e la visione artificiale.\nL'apprendimento automatico \u00e8 strettamente collegato, e spesso si sovrappone con la statistica computazionale, che si occupa dell'elaborazione di predizioni tramite l'uso di computer. L'apprendimento automatico \u00e8 anche fortemente legato all'ottimizzazione matematica, che fornisce metodi, teorie e domini di applicazione a questo campo. Per usi commerciali, l'apprendimento automatico \u00e8 conosciuto come analisi predittiva.\nL'apprendimento automatico si sviluppa con lo studio dell'intelligenza artificiale, e vi \u00e8 strettamente collegato: infatti gi\u00e0 dai primi tentativi di definire l'intelligenza artificiale come disciplina accademica, alcuni ricercatori si erano mostrati interessati alla possibilit\u00e0 che le macchine imparassero dai dati. Questi ricercatori, in particolare Marvin Minsky, Arthur Samuel e Frank Rosenblatt, provarono ad avvicinarsi al problema sia attraverso vari metodi formali, sia con quelle che vengono definite reti neurali nei tardi anni '50. Le reti neurali erano allora costituite da singoli percettroni e da modelli matematici derivati dal modello lineare generalizzato della statistica, come l'ADALINE di Widrow. Si prov\u00f2 a sfruttare anche ragionamenti probabilistici, in particolare nelle diagnosi mediche automatiche.\nSempre negli anni '50, Alan Turing propose l'idea di una \"macchina che apprende\", ovvero in grado di imparare e dunque diventare intelligente. La proposta specifica di Turing anticipa gli algoritmi genetici.\nTuttavia gi\u00e0 dalla met\u00e0 degli anni '50 lo studio dell'intelligenza artificiale si stava concentrando su approcci logici di tipo \"knowledge-based\", nota oggi sotto il nome di GOFAI, causando un distacco tra lo studio dell'IA e quello dell'apprendimento automatico. Sistemi di tipo probabilistico erano invasi di problemi sia teoretici sia pratici in termini di acquisizione e rappresentazione dei dati. Negli anni Ottanta, i sistemi esperti dominavano il campo dell'IA, e i sistemi basati sulla statistica non venivano pi\u00f9 studiati.\nLo studio dell'apprendimento simbolico e \"knowledge-based\" continu\u00f2 nell'ambito dell'IA, portando a sviluppare la programmazione logica induttiva, ma ora la ricerca pi\u00f9 prettamente statistica si svolgeva al di fuori del campo vero e proprio dell'intelligenza artificiale, nel riconoscimento di pattern e nell'information retrieval.\nUn altro motivo per cui lo studio dell'apprendimento automatico fu abbandonato fu la pubblicazione del libro \"Perceptrons: an introduction to computational geometry\" di Marvin Minsky e Seymour Papert, che vi descrivevano alcune delle limitazioni dei percettroni e delle reti neurali. La ricerca sulle reti neurali sub\u00ec un significativo rallentamento a causa dell'interpretazione del libro, che le descriveva come intrinsecamente limitate. Anche la linea di ricerca sulle reti neurali continu\u00f2 al di fuori del campo dell'IA, portata avanti da ricercatori provenienti da altre discipline quali Hopfield, Rumelhart, Hinton e Fukushima. Il loro successo principale fu a met\u00e0 degli anni '80 con la riscoperta della \"backpropagation\" e della self-organization.\nL'apprendimento automatico, sviluppatosi come campo di studi separato dall'IA classica, cominci\u00f2 a rifiorire negli anni '90. Il suo obiettivo cambi\u00f2 dall'ottenere l'intelligenza artificiale ad affrontare problemi risolvibili di natura pratica. Distolse inoltre la propria attenzione dagli approcci simbolici che aveva ereditato dall'IA, e si diresse verso metodi e modelli presi in prestito dalla statistica e dalla teoria della probabilit\u00e0. L'apprendimento automatico ha inoltre beneficiato dalla nascita di Internet, che ha reso l'informazione digitale pi\u00f9 facilmente reperibile e distribuibile.\nTom M. Mitchell ha fornito la definizione pi\u00f9 citata di apprendimento automatico nel suo libro \"\"Machine Learning\"\": \"\"Si dice che un programma apprende dall'esperienza E con riferimento a alcune classi di compiti T e con misurazione della performance P, se le sue performance nel compito T, come misurato da P, migliorano con l'esperienza E.\"\" In poche parole, si potrebbe semplificare dicendo che un programma apprende se c'\u00e8 un miglioramento delle prestazioni dopo un compito svolto. Questa definizione di Mitchell \u00e8 rilevante poich\u00e9 fornisce una definizione operativa dell'apprendimento automatico, invece che in termini cognitivi. Fornendo questa definizione, Mitchell di fatto segue la proposta che Alan Turing fece nel suo articolo \"\"Computing Machinery and Intelligence\"\", sostituendo la domanda \"\"Le macchine possono pensare?\"\" con la domanda \"\"Le macchine possono fare quello che noi (in quanto entit\u00e0 pensanti) possiamo fare?\"\".\nL'obiettivo principe dell'apprendimento automatico \u00e8 che una macchina sia in grado di generalizzare dalla propria esperienza, ossia che sia in grado di svolgere ragionamenti induttivi. In questo contesto, per generalizzazione si intende l'abilit\u00e0 di una macchina di portare a termine in maniera accurata esempi o compiti nuovi, che non ha mai affrontato, dopo aver fatto esperienza su un insieme di dati di apprendimento. Gli esempi di addestramento (in inglese chiamati \"training examples\") si assume provengano da una qualche distribuzione di probabilit\u00e0, generalmente sconosciuta e considerata rappresentativa dello spazio delle occorrenze del fenomeno da apprendere; la macchina ha il compito di costruire un modello probabilistico generale dello spazio delle occorrenze, in maniera tale da essere in grado di produrre previsioni sufficientemente accurate quando sottoposta a nuovi casi.\nL'analisi computazionale degli algoritmi di apprendimento automatico e delle loro prestazioni \u00e8 una branca dell'Informatica teorica chiamata teoria dell'apprendimento. Dato che gli esempi di addestramento sono insiemi finiti di dati e non c'\u00e8 modo di sapere l'evoluzione futura di un modello, la teoria dell'apprendimento non offre alcuna garanzia sulle prestazioni degli algoritmi. D'altro canto, \u00e8 piuttosto comune che tali prestazioni siano vincolate da limiti probabilistici. Il bias-variance tradeoff \u00e8 uno dei modi di quantificare l'errore di generalizzazione.\nAffinch\u00e9 la generalizzazione offra le migliori prestazioni possibili, la complessit\u00e0 dell'ipotesi induttiva deve essere pari alla complessit\u00e0 della funzione sottostante i dati. Se l'ipotesi \u00e8 meno complessa della funzione, allora il modello manifesta \"underfitting\". Quando la complessit\u00e0 del modello viene aumentata in risposta, allora l'errore di apprendimento diminuisce. Al contrario invece se l'ipotesi \u00e8 troppo complessa, allora il modello manifesta overfitting e la generalizzazione sar\u00e0 pi\u00f9 scarsa.\nOltre ai limiti di prestazioni, i teorici dell'apprendimento studiano la complessit\u00e0 temporale e la fattibilit\u00e0 dell'apprendimento stesso. Una computazione \u00e8 considerata fattibile se pu\u00f2 essere svolta in tempo polinomiale.\nI compiti dell'apprendimento automatico vengono tipicamente classificati in tre ampie categorie, a seconda della natura del \"segnale\" utilizzato per l'apprendimento o del \"feedback\" disponibile al sistema di apprendimento. Queste categorie, anche dette paradigmi, sono:\nA met\u00e0 strada tra l'apprendimento supervisionato e quello non supervisionato c'\u00e8 l'apprendimento semi-supervisionato, nel quale l'insegnante fornisce un dataset incompleto per l'allenamento, cio\u00e8 un insieme di dati per l'allenamento tra i quali ci sono dati senza il rispettivo output desiderato. La trasduzione \u00e8 un caso speciale di questo principio, nel quale l'intero insieme delle istanze del problema \u00e8 noto durante l'apprendimento, eccetto la parte degli output desiderati che \u00e8 mancante.\nUn'altra categorizzazione dei compiti dell'apprendimento automatico si rileva quando si considera l'output desiderato del sistema di apprendimento automatico.\nL'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo Michael I. Jordan, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. Jordan ha anche suggerito il termine data science come nome con cui chiamare l'intero campo di studi.\nLeo Breiman ha distinto due paradigmi statistici di modellazione: modello basato sui dati e modello basato sugli algoritmi, dove \"modello basato sugli algoritmi\" indica approssimativamente algoritmi di apprendimento automatico come la foresta casuale.\nAlcuni statistici hanno adottato metodi provenienti dall'apprendimento automatico, il che ha portato alla creazione di una disciplina combinata chiamata \"apprendimento statistico\".\nL'apprendimento automatico viene a volte unito al data mining, che si focalizza maggiormente sull'analisi esplorativa dei dati ed utilizza principalmente il paradigma di apprendimento chiamato \"apprendimento non supervisionato\". Invece, l'apprendimento automatico pu\u00f2 essere anche supervisionato.\nL'apprendimento automatico e il \"data mining\" infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su propriet\u00e0 note apprese dai dati, il data mining si concentra sulla scoperta di propriet\u00e0 prima \"sconosciute\" nei dati. Il data mining sfrutta i metodi dell'apprendimento automatico, ma con obiettivi differenti; d'altro canto, l'apprendimento automatico utilizza i metodi di data mining come metodi di apprendimento non supervisionato o come passi di preprocessing per aumentare l'accuratezza dell'apprendimento. Gran parte della confusione tra le due comunit\u00e0 di ricerca scaturisce dall'assunzione di base del loro operato: nell'apprendimento automatico, le prestazioni sono generalmente valutate in base all'abilit\u00e0 di riprodurre conoscenza gi\u00e0 acquisita, mentre in data mining il compito chiave \u00e8 la scoperta di conoscenza che prima non si aveva.\nL'apprendimento automatico ha legami molto stretti con l'ottimizzazione: molti problemi di apprendimento sono formulati come la minimizzazione di una qualche funzione di costo su un insieme di esempi di apprendimento. La funzione di costo (o funzione di perdita) rappresenta la discrepanza tra le previsioni del modello che si sta addestrando e le istanze del problema reale. Le differenze tra i due campi (l'apprendimento automatico e l'ottimizzazione) sorgono dall'obiettivo della generalizzazione: mentre gli algoritmi di ottimizzazione possono minimizzare la perdita su un insieme di apprendimento, l'apprendimento automatico si preoccupa di minimizzare la perdita su campioni mai visti dalla macchina.\nLa risoluzione automatica di problemi avviene, nel campo dell'informatica, in due modi differenti: tramite paradigmi di \"hard computing\" o tramite paradigmi di \"soft computing\". Per \"hard computing\" si intende la risoluzione di un problema tramite l'esecuzione di un algoritmo ben definito e decidibile. La maggior parte dei paradigmi di \"hard computing\" sono metodi ormai consolidati, ma presentano alcuni lati negativi: infatti richiedono sempre un modello analitico preciso e definibile, e spesso un alto tempo di computazione. \nLe tecniche di \"soft computing\" d'altro canto antepongono il guadagno nella comprensione del comportamento di un sistema a scapito della precisione, spesso non necessaria. I paradigmi di \"soft computing\" si basano su due principi: \nL'apprendimento automatico si avvale delle tecniche di \"soft computing\".\nLa programmazione logica induttiva (anche ILP, dall'inglese \"inductive logic programming\") \u00e8 un approccio all'apprendimento di regole che usa la programmazione logica come rappresentazione uniforme per gli esempi di input, per la conoscenza di base della macchina, e per le ipotesi. Data una codifica della (nota) conoscenza di base e un insieme di esempi rappresentati come fatti in una base di dati logica, un sistema ILP deriva un programma logico ipotetico da cui conseguono tutti gli esempi positivi, e nessuno di quelli negativi. La programmazione induttiva \u00e8 un campo simile che considera ogni tipo di linguaggio di programmazione per rappresentare le ipotesi invece che soltanto la programmazione logica, come ad esempio programmi funzionali.\nL'albero di decisione \u00e8 un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende \u00e8 rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilit\u00e0 umana.\nL'apprendimento automatico basato su regole di associazione \u00e8 un metodo di apprendimento che identifica, apprende ed evolve delle \"regole\" con l'intento di immagazzinare, manipolare e applicare conoscenza. La caratteristica principale di questo tipo di apprendimento \u00e8 l'identificazione ed utilizzo di un insieme di regole relazionali che rappresenta nel suo insieme la conoscenza catturata dal sistema. Ci\u00f2 si pone in controtendenza con altri tipi di apprendimento automatico che normalmente identificano un singolo modello che pu\u00f2 essere applicato universalmente ad ogni istanza per riuscire a fare su di essa una previsione. Gli approcci dell'apprendimento basato su regole di associazione includono il sistema immunitario artificiale.\nUna rete neurale artificiale \u00e8 un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.\nGli algoritmi genetici forniscono un approccio all'apprendimento che \u00e8 liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi pi\u00f9 adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una variet\u00e0 di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.\nIl ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantit\u00e0 di interesse sono disciplinate da distribuzioni di probabilit\u00e0 e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilit\u00e0 insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana \u00e8 importante perch\u00e9 fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilit\u00e0.\nMacchine a vettori di supporto (\"Support Vector Machine\", SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.\nLa discesa dei prezzi per l'hardware e lo sviluppo di GPU per uso personale negli ultimi anni hanno contribuito allo sviluppo del concetto di apprendimento profondo, che consiste nello sviluppare livelli nascosti multipli nelle reti neurali artificiali. Questo approccio tenta di modellizzare il modo in cui il cervello umano processa luce e suoni e li interpreta in vista e udito. Alcune delle applicazioni pi\u00f9 affermate dell'apprendimento profondo sono la visione artificiale e il riconoscimento vocale.\nLa cluster analisi, o clustering, \u00e8 in grado di rilevare similarit\u00e0 strutturali tra le osservazioni di un dataset attraverso l'assegnazione di un insieme di osservazioni in sottogruppi (\"cluster\") di elementi tra loro omogenei. Il clustering \u00e8 un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.\nTutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.\nMetodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.\nMetodi di apprendimento automatico sono stati applicati ad una variet\u00e0 di database di grandi dimensioni per imparare regolarit\u00e0 generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema \u00e8 oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.\nI programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.\nL'apprendimento automatico solleva un numero di problematiche etiche. I sistemi addestrati con insiemi di dati faziosi o pregiudizievoli possono esibire questi pregiudizi quando vengono interpellati: in questo modo possono essere digitalizzati pregiudizi culturali quali il razzismo istituzionale e il classismo. Di conseguenza la raccolta responsabile dei dati pu\u00f2 diventare un aspetto critico dell'apprendimento automatico.\nIn ragione dell'innata ambiguit\u00e0 dei linguaggi naturali, le macchine addestrate su corpi linguistici necessariamente apprenderanno questa ambiguit\u00e0."], "concept_B": "Apprendimento automatico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_A": "Test di verifica d'ipotesi", "wikipedia_passage_concept_B": ["1199503", "Popolazione statistica", "In statistica per popolazione (o collettivo statistico o aggregato) si intende l'insieme degli elementi che sono oggetto di studio, ovvero l'insieme delle unit\u00e0 (dette \"unit\u00e0 statistiche\") sulle quali viene effettuata la rilevazione delle modalit\u00e0 con le quali il fenomeno studiato si presenta. Tali unit\u00e0 presentano tutte almeno una caratteristica comune, che viene accuratamente definita al fine di delimitare il loro insieme; ad esempio con \"italiani\" si pu\u00f2 intendere sia le persone di nazionalit\u00e0 italiana, anche se residenti all'estero, sia le persone residenti in Italia, indipendentemente da quale sia la loro nazionalit\u00e0.\nUna popolazione statistica va definita anche rispetto al tempo; ad esempio si possono considerare gli italiani che risultano residenti in Italia alle ore 12 di un dato giorno (popolazione definita secondo una caratteristica riferita ad un \"istante\" di tempo), oppure quelli nati dal 1\u00ba gennaio al 31 dicembre di un dato anno (popolazione definita secondo una caratteristica riferita ad un \"periodo\" di tempo).\nUna popolazione statistica, peraltro, non \u00e8 sempre un insieme biologico; costituisce una popolazione anche l'insieme delle lampadine prodotte da un'azienda in un dato periodo di tempo, l'insieme delle nazioni del continente europeo in un dato anno o l'insieme degli anni di un dato secolo.\nI collettivi statistici, o popolazioni, possono essere distinti in:\noppure in:\no ancora tra:"], "concept_B": "Popolazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1845509", "Significativit\u00e0", "In statistica la significativit\u00e0 \u00e8 la possibilit\u00e0 rilevante che compaia un determinato valore. Ci si riferisce anche come \"statisticamente differente da zero\"; ci\u00f2 non significa che la \"significativit\u00e0\" sia rilevante, o vasta, come indurrebbe a pensare la parola. Ma solo che \u00e8 diversa dal numero limite.\nIl livello di significativit\u00e0 di un test \u00e8 dato solitamente da una verifica del test d'ipotesi. Nel caso pi\u00f9 semplice \u00e8 definita come la probabilit\u00e0 di accettare o rigettare l'ipotesi nulla.\nI livelli di significativit\u00e0 sono solitamente rappresentati con la lettera greca \u03b1 (alfa). I livelli pi\u00f9 usati sono 5% (\u03b1=0,05) e 1% (\u03b1=0,01); nel caso di ipotesi a carattere prevalentemente esplorativo \u00e8 consuetudine adoperare un livello di significativit\u00e0 al 10% (\u03b1=0,1). Se il test di verifica d'ipotesi d\u00e0 un valore p minore del livello \u03b1, l'ipotesi nulla \u00e8 rifiutata.\nTali risultati sono informalmente riportati come 'statisticamente significativi'. Per esempio se si sostiene che \"c'\u00e8 solo una possibilit\u00e0 su mille che ci\u00f2 possa accadere per coincidenza,\" viene usato un livello di significativit\u00e0 dello 0,1%. Pi\u00f9 basso \u00e8 il livello di significativit\u00e0, maggiore \u00e8 l'evidenza. In alcune situazioni conviene esprimere la significativit\u00e0 statistica con 1\u00a0\u2212\u00a0\u03b1. In generale, quando si interpreta una significativit\u00e0 stabilita, bisogna stare attenti nell'indicare che cosa, precisamente \u00e8 stato testato statisticamente.\nDifferenti livelli di \u03b1 hanno differenti vantaggi e svantaggi. \u03b1-livelli pi\u00f9 bassi danno maggiore confidenza nella determinazione della significativit\u00e0, ma corrono maggiori rischi di errore nel respingere una falsa ipotesi nulla (un errore di tipo II, o \"falsa determinazione negativa\"), e cos\u00ec hanno maggiore potenza statistica. La selezione di un \u03b1-livello inevitabilmente implica un compromesso fra significativit\u00e0 e potenza, e di conseguenza, fra errore tipo I ed errore tipo II.\nIn alcuni campi, per esempio nella fisica nucleare ed in quella delle particelle, si usa esprimere la significativit\u00e0 statistica in unit\u00e0 di \"\u03c3\" (sigma), la deviazione standard di una distribuzione gaussiana. Una significativit\u00e0 statistica di \"formula_1\" pu\u00f2 essere convertita in un valore di \u03b1 usando la funzione errore:\nL'uso di \u03c3 \u00e8 motivato dalla onnipresenza della distribuzione gaussiana nella \nmisura delle incertezze. Per esempio se una teoria prevede che un parametro abbia un valore, ad esempio 100, e ad una misurazione indica che il parametro \u00e8 100 \u00b1 3, allora bisogna riportare la misura come una \"deviazione 3\u03c3\" dalla previsione teorica. in termini di \u03b1, questa situazione \u00e8 equivalente al dire che \"supponendo vera la teoria, la possibilit\u00e0 di ottenere che il risultato sperimentale coincida \u00e8 dello 0,27%\" (poich\u00e9 1 \u00a0\u2212\u00a0erf(3/\u221a2) = 0.0027).\nFissati i livelli di significativit\u00e0 come quelli menzionati in seguito possono essere considerati come utili nelle analisi di dati esploratorie. Comunque, la moderna statistica \u00e8 dell'avviso che, dove il risultato di un test \u00e8 essenzialmente il risultato finale di un esperimento o di altro studio, il p-valore deve essere considerato esplicitamente. Inoltre, ed \u00e8 importante, bisogna considerare se e come il p-valore \u00e8 significativo o meno. Questo consente di accedere al massimo delle informazioni che devono essere trasferiti da un riassunto degli studi nelle meta-analisi.\nUn errore comune \u00e8 ritenere che un risultato statisticamente significativo sia sempre di significativit\u00e0 pratica, o dimostri un largo effetto nella popolazione. Sfortunatamente, questo problema si incontra diffusamente negli scritti scientifici. Dato un campione sufficientemente grande, per esempio, si pu\u00f2 scoprire che differenze estremamente piccole e non visibili sono statisticamente significative, ma la significativit\u00e0 statistica non dice niente di una significativit\u00e0 pratica di una differenza.\nUno dei problemi pi\u00f9 comuni nel testare la significativit\u00e0 \u00e8 la tendenza delle comparazioni multiple a tendere a significative differenze spurie anche dove l'ipotesi nulla \u00e8 vera. Per esempio, in uno studio di venti comparazioni, usando un \n\u03b1-livello del 5%, una comparazione pu\u00f2 effettivamente riportare un risultato significativo nonostante sia vera l'ipotesi di nullit\u00e0. in questi casi i p-valori sono corretti al fine di controllare o il valore falso o l'errore familiare.\nUn problema addizionale \u00e8 che si ritiene che le analisi frequentiste dei p-valori esagerino la \"\"significativit\u00e0 statistica\"\". Si veda il fattore di Bayes per i dettagli.\nJ. Scott Armstrong, negli articoli \"Significance Tests Harm Progress in Forecasting,\" e \"Statistical Significance Tests are Unnecessary Even When Properly Done,\" espone la sua posizione secondo cui in alcuni casi, seppure eseguiti correttamente, i test di significativit\u00e0 statistica non sarebbero utili. A suo parere, un certo numero di tentativi ha fallito nel trovare prove empiriche che sostenessero l'uso di test di significativit\u00e0, ed i test di significativit\u00e0 statistica usati da soli potrebbero essere nocivi allo sviluppo della conoscenza scientifica perch\u00e9 distrarrebbero i ricercatori dall'uso di metodi statistici in alcuni casi pi\u00f9 adatti. \nArmstrong suggerisce quindi che secondo lui i ricercatori dovrebbero evitare i test di significativit\u00e0 statistica, e dovrebbero piuttosto fare uso di strumenti di area di effetto, intervalli di fiducia, ripetizioni/estensioni, e meta-analisi.\nLa significativit\u00e0 statistica pu\u00f2 essere considerata come la fiducia che si ha in un dato risultato. In uno studio di comparazione, essa dipende dalla differenza relativa tra i gruppi confrontati, la quantit\u00e0 delle misurazioni e il rumore associato alle misurazioni. In altre parole, la fiducia che si ha che un dato risultato sia non casuale (cio\u00e8 non una conseguenza di un caso) dipende dal rapporto segnale-rumore (SNR) e misura campione. Esprimendosi matematicamente, la fiducia che un risultato non sia casuale \u00e8 dato dalla seguente formula di Sackett:\nPer chiarezza, la succitata formula \u00e8 rappresentata tabularmente qui di seguito.\nDipendenza della fiducia con rumore, segnale e misura campione (forma tabulare)\nIn parole la dipendenza di una fiducia \u00e8 maggiore se il rumore \u00e8 basso o la misura campione \u00e8 estesa o l'ampiezza effettiva (del segnale) \u00e8 larga. La fiducia di un risultato (e l'associato intervallo di fiducia) \"non\" dipende dagli effetti della sola ampiezza effettiva del segnale. Se la misura campione \u00e8 grande e il rumore e piccolo un'ampiezza effettiva di segnale pu\u00f2 essere misurata con grande fiducia. Sebbene un'ampiezza effettiva viene considerata importante essa dipende nel contesto degli eventi comparati.\nIn medicina, piccole ampiezze effettive (riflesse da piccoli aumenti di rischio) sono spesso considerate clinicamente rilevanti e sono frequentemente usati per guidare decisioni di trattamento (se c'\u00e8 una grande fiducia in essi). Sebbene un dato trattamento \u00e8 considerato un giusto tentativo esso dipende dai rischi, dai benefici e dai costi."], "concept_A": "Significativit\u00e0", "wikipedia_passage_concept_B": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_B": "Intervallo di confidenza", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["3645149", "Regole di associazione", "Nel data mining, le regole di associazione sono uno dei metodi per estrarre relazioni nascoste tra i dati.\nAgrawal et al. introdussero le regole di associazione per la scoperta di regolarit\u00e0 all'interno delle transazioni registrate nelle vendite dei supermercati. Per esempio, la regola formula_1 individuata nell'analisi degli scontrini di un supermercato indica che il se il cliente compra insieme cipolle e patate \u00e8 probabile che acquisti anche della carne per hamburger. Tale informazione pu\u00f2 essere utilizzata come base per le decisioni riguardanti le attivit\u00e0 di marketing, come ad esempio le offerte promozionali o il posizionamento dei prodotti negli scaffali.\nLe regole di associazione sono anche usate in molte altre aree, quali il Web mining, la scoperta di anomalie e la bioinformatica.\nIl concetto di regola di associazione divenne popolare a causa di un articolo del 1993 di Agrawal et al.. Secondo Google Scholar esso possiede pi\u00f9 di 9500 citazioni (Settembre 2010) ed \u00e8 uno degli articoli pi\u00f9 citati nel campo del data mining. Tuttavia \u00e8 possibile che quella che viene chiamata come \"regola di associazione\" sia simile a un approccio di data mining presentato nel 1966 e sviluppato da H\u00e1jek et al..\nSeguendo la definizione originale di Agrawal et al. il problema della scoperta di regole di associazione \u00e8 rappresentato come segue.\nConsideriamo l'insieme di formula_2 attributi binari (\"oggetti\" o \"item\") formula_3 e l'insieme di transazioni (\"database\")formula_4. Ciascuna transazione appartenente a formula_5 possiede un codice identificativo (ID) e contiene un sottoinsieme degli oggetti contenuti in formula_6. Una \"regola\" \u00e8 definita come un'implicazione nella forma formula_7 dove formula_8\ne formula_9. L'insieme di oggetti (o \"itemsets\") formula_10 e formula_11 vengono chiamati rispettivamente \"antecendente\" e \"conseguente\" della regola.\nPer illustrare questo concetto, \u00e8 possibile usare un esempio giocattolo riguardante un supermercato.\nL'insieme di oggetti \u00e8 formula_12 e il database contenente gli oggetti \u00e8 rappresentato nella tabella a destra, dove 1 indica la presenza di un oggetto in una transazione e 0 l'assenza. Un esempio di regola di associazione potrebbe essere: formula_13. Essa indica che se il cliente acquista pane e burro, comprer\u00e0 anche il latte.\nAttenzione: questo esempio \u00e8 estremamente piccolo. In un'applicazione reale una regola necessita di un supporto di diverse centinaia di transazioni perch\u00e9 sia considerata statisticamente significativa e il database deve contenere migliaia (o milioni) di transazioni."], "concept_A": "Regole di associazione", "wikipedia_passage_concept_B": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_B": "Probabilit\u00e0 condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1716607", "Test t", "Il test t (o, dall'inglese, t-test) \u00e8 un test statistico di tipo parametrico con lo scopo di verificare se il valore medio di una distribuzione si discosta significativamente da un certo valore di riferimento. Differisce dal test z per il fatto che la varianza formula_1 \u00e8 sconosciuta.\nSe la varianza della popolazione non \u00e8 nota, la verifica d'ipotesi sulla media della popolazione si effettua sostituendo alla varianza di universo la sua stima ottenuta a partire dallo stimatore varianza corretta del campione:\nIn questo modo la statistica test \u00e8:\nla cui distribuzione \u00e8 quella della formula_4 di Student con formula_5 gradi di libert\u00e0. Ad ogni modo, all'aumentare dei gradi di libert\u00e0, per il teorema del limite centrale, la variabile casuale formula_4 tende alla distribuzione normale e quindi alla formula_4 si pu\u00f2 sostituire la formula_8 diciamo per una soglia campionaria formula_9 maggiore di 30. Se il test \u00e8 bidirezionale, si rifiuter\u00e0 l'ipotesi nulla se la formula_10 empirica \u00e8 maggiore della formula_10 teorica di formula_12 con formula_5 gradi di libert\u00e0 e si accetter\u00e0 l'ipotesi alternativa formula_14 con un errore formula_15 di I specie.\nIn econometria la statistica formula_10 ha la seguente forma:"], "concept_A": "Test t", "wikipedia_passage_concept_B": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_B": "Intervallo di confidenza", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["605046", "Campionamento casuale", "In statistica il campionamento casuale corrisponde ad un'estrazione da una popolazione distribuita secondo la sua legge (funzione di densit\u00e0) di un determinato numero di individui/oggetti.\nLa scelta del campione nel campionamento casuale \u00e8 affidata al caso e non deve essere influenzata, pi\u00f9 o meno consciamente, da chi compie l'indagine.\nLe caratteristiche essenziali di un campionamento casuale semplice sono:\na) tutte le unit\u00e0 della popolazione hanno eguale probabilit\u00e0 di fare parte del campione;\nb) ogni campione di ampiezza n ha la stessa probabilit\u00e0 di essere formato.\nUn modo semplice per operare tale campionamento consiste nel numerare tutte le unit\u00e0 della popolazione, mettere in un'urna tante palline numerate, tutte uguali fra loro, quante sono le unit\u00e0 della popolazione e quindi sorteggiare da tale urna le palline per formare il campione.\nInvece dell'urna si preferisce oggi ricorrere a una tavola di numeri casuali. Le tavole dei numeri casuali si costruivano, un tempo, con metodi empirici; attualmente si utilizzano gli elaboratori elettronici; per utilizzare le tavole dei numeri casuali, si parte da un punto qualunque, solitamente, estratto a sorte, e si procede in orizzontale, o in verticale, o in diagonale.\nIl campionamento casuale pu\u00f2 essere:\nNell'estrazione in blocco le n unit\u00e0 statistiche che compongono il campione vengono estratte contemporaneamente, e di conseguenza non si pu\u00f2 distinguere l'ordine con cui gli n elementi si presentano. Quindi ad esempio in questo caso il campione \"A B C D\" \u00e8 considerato uguale al campione \"A C B D\".\nmentre il campionamento senza riposizione consiste nell'estrazione di un elemento alla volta senza il reinserimento nella popolazione dello stesso. In questo caso l'ordine con cui vengono scelti gli elementi conta. il numero dei possibili campioni \u00e8:\nOgni unit\u00e0 statistica estratta viene rimessa nella popolazione e quindi la stessa unit\u00e0 pu\u00f2 essere\nnuovamente estratta\nSi potrebbe formare il campione anche estraendo successivamente le \"n\" unit\u00e0 senza reimmissione, ma tenendo conto dell'ordine in cui le singole unit\u00e0 sono estratte. In questo caso il numero dei campioni di \"n\" elementi che si possono estrarre dalla popolazione di N elementi \u00e8 dato dalle disposizioni semplici D(N,n) degli N elementi di classe \"n\", ma questo procedimento \u00e8 molto difficile da trovare.\nConoscendo la distribuzione della popolazione \u00e8 possibile:"], "concept_A": "Campionamento casuale", "wikipedia_passage_concept_B": ["1199503", "Popolazione statistica", "In statistica per popolazione (o collettivo statistico o aggregato) si intende l'insieme degli elementi che sono oggetto di studio, ovvero l'insieme delle unit\u00e0 (dette \"unit\u00e0 statistiche\") sulle quali viene effettuata la rilevazione delle modalit\u00e0 con le quali il fenomeno studiato si presenta. Tali unit\u00e0 presentano tutte almeno una caratteristica comune, che viene accuratamente definita al fine di delimitare il loro insieme; ad esempio con \"italiani\" si pu\u00f2 intendere sia le persone di nazionalit\u00e0 italiana, anche se residenti all'estero, sia le persone residenti in Italia, indipendentemente da quale sia la loro nazionalit\u00e0.\nUna popolazione statistica va definita anche rispetto al tempo; ad esempio si possono considerare gli italiani che risultano residenti in Italia alle ore 12 di un dato giorno (popolazione definita secondo una caratteristica riferita ad un \"istante\" di tempo), oppure quelli nati dal 1\u00ba gennaio al 31 dicembre di un dato anno (popolazione definita secondo una caratteristica riferita ad un \"periodo\" di tempo).\nUna popolazione statistica, peraltro, non \u00e8 sempre un insieme biologico; costituisce una popolazione anche l'insieme delle lampadine prodotte da un'azienda in un dato periodo di tempo, l'insieme delle nazioni del continente europeo in un dato anno o l'insieme degli anni di un dato secolo.\nI collettivi statistici, o popolazioni, possono essere distinti in:\noppure in:\no ancora tra:"], "concept_B": "Popolazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_A": "Boosting", "wikipedia_passage_concept_B": ["605", "Apprendimento automatico", "L\u2019apprendimento automatico (noto anche come machine learning) \u00e8 una branca dell'intelligenza artificiale che raccoglie un insieme di metodi, sviluppati a partire dagli ultimi decenni del XX secolo in varie comunit\u00e0 scientifiche, sotto diversi nomi quali: statistica computazionale, riconoscimento di pattern, reti neurali artificiali, filtraggio adattivo, teoria dei sistemi dinamici, elaborazione delle immagini, data mining, algoritmi adattivi, ecc; che utilizza metodi statistici per migliorare progressivamente la performance di un algoritmo nell'identificare pattern nei dati. Nell'ambito dell'informatica, l'apprendimento automatico \u00e8 una variante alla programmazione tradizionale nella quale si predispone in una macchina l'abilit\u00e0 di apprendere qualcosa dai dati in maniera autonoma, senza ricevere istruzioni esplicite a riguardo.\nLo stesso Arthur Samuel che coni\u00f2 il termine nel 1959 in linea di principio identifica due approcci distinti. Il primo metodo, indicato come rete neurale, porta allo sviluppo di macchine ad apprendimento automatico per impiego generale in cui il comportamento \u00e8 appreso da una rete di commutazione connessa casualmente, a seguito di una routine di apprendimento basata su ricompensa e punizione (apprendimento per rinforzo). Il secondo metodo, pi\u00f9 specifico, consiste nel riprodurre l'equivalente di una rete altamente organizzata progettata per imparare solo alcune attivit\u00e0 specifiche. La seconda procedura, che necessita di supervisione, richiede la riprogrammazione per ogni nuova applicazione, ma risulta essere molto pi\u00f9 efficiente dal punto di vista computazionale.\nL'apprendimento automatico \u00e8 strettamente legato al riconoscimento di pattern e alla teoria computazionale dell'apprendimento ed esplora lo studio e la costruzione di algoritmi che possano apprendere da un insieme di dati e fare delle predizioni su questi, costruendo in modo induttivo un modello basato su dei campioni. L'apprendimento automatico viene impiegato in quei campi dell'informatica nei quali progettare e programmare algoritmi espliciti \u00e8 impraticabile; tra le possibili applicazioni citiamo il filtraggio delle email per evitare spam, l'individuazione di intrusioni in una rete o di intrusi che cercano di violare dati, il riconoscimento ottico dei caratteri, i motori di ricerca e la visione artificiale.\nL'apprendimento automatico \u00e8 strettamente collegato, e spesso si sovrappone con la statistica computazionale, che si occupa dell'elaborazione di predizioni tramite l'uso di computer. L'apprendimento automatico \u00e8 anche fortemente legato all'ottimizzazione matematica, che fornisce metodi, teorie e domini di applicazione a questo campo. Per usi commerciali, l'apprendimento automatico \u00e8 conosciuto come analisi predittiva.\nL'apprendimento automatico si sviluppa con lo studio dell'intelligenza artificiale, e vi \u00e8 strettamente collegato: infatti gi\u00e0 dai primi tentativi di definire l'intelligenza artificiale come disciplina accademica, alcuni ricercatori si erano mostrati interessati alla possibilit\u00e0 che le macchine imparassero dai dati. Questi ricercatori, in particolare Marvin Minsky, Arthur Samuel e Frank Rosenblatt, provarono ad avvicinarsi al problema sia attraverso vari metodi formali, sia con quelle che vengono definite reti neurali nei tardi anni '50. Le reti neurali erano allora costituite da singoli percettroni e da modelli matematici derivati dal modello lineare generalizzato della statistica, come l'ADALINE di Widrow. Si prov\u00f2 a sfruttare anche ragionamenti probabilistici, in particolare nelle diagnosi mediche automatiche.\nSempre negli anni '50, Alan Turing propose l'idea di una \"macchina che apprende\", ovvero in grado di imparare e dunque diventare intelligente. La proposta specifica di Turing anticipa gli algoritmi genetici.\nTuttavia gi\u00e0 dalla met\u00e0 degli anni '50 lo studio dell'intelligenza artificiale si stava concentrando su approcci logici di tipo \"knowledge-based\", nota oggi sotto il nome di GOFAI, causando un distacco tra lo studio dell'IA e quello dell'apprendimento automatico. Sistemi di tipo probabilistico erano invasi di problemi sia teoretici sia pratici in termini di acquisizione e rappresentazione dei dati. Negli anni Ottanta, i sistemi esperti dominavano il campo dell'IA, e i sistemi basati sulla statistica non venivano pi\u00f9 studiati.\nLo studio dell'apprendimento simbolico e \"knowledge-based\" continu\u00f2 nell'ambito dell'IA, portando a sviluppare la programmazione logica induttiva, ma ora la ricerca pi\u00f9 prettamente statistica si svolgeva al di fuori del campo vero e proprio dell'intelligenza artificiale, nel riconoscimento di pattern e nell'information retrieval.\nUn altro motivo per cui lo studio dell'apprendimento automatico fu abbandonato fu la pubblicazione del libro \"Perceptrons: an introduction to computational geometry\" di Marvin Minsky e Seymour Papert, che vi descrivevano alcune delle limitazioni dei percettroni e delle reti neurali. La ricerca sulle reti neurali sub\u00ec un significativo rallentamento a causa dell'interpretazione del libro, che le descriveva come intrinsecamente limitate. Anche la linea di ricerca sulle reti neurali continu\u00f2 al di fuori del campo dell'IA, portata avanti da ricercatori provenienti da altre discipline quali Hopfield, Rumelhart, Hinton e Fukushima. Il loro successo principale fu a met\u00e0 degli anni '80 con la riscoperta della \"backpropagation\" e della self-organization.\nL'apprendimento automatico, sviluppatosi come campo di studi separato dall'IA classica, cominci\u00f2 a rifiorire negli anni '90. Il suo obiettivo cambi\u00f2 dall'ottenere l'intelligenza artificiale ad affrontare problemi risolvibili di natura pratica. Distolse inoltre la propria attenzione dagli approcci simbolici che aveva ereditato dall'IA, e si diresse verso metodi e modelli presi in prestito dalla statistica e dalla teoria della probabilit\u00e0. L'apprendimento automatico ha inoltre beneficiato dalla nascita di Internet, che ha reso l'informazione digitale pi\u00f9 facilmente reperibile e distribuibile.\nTom M. Mitchell ha fornito la definizione pi\u00f9 citata di apprendimento automatico nel suo libro \"\"Machine Learning\"\": \"\"Si dice che un programma apprende dall'esperienza E con riferimento a alcune classi di compiti T e con misurazione della performance P, se le sue performance nel compito T, come misurato da P, migliorano con l'esperienza E.\"\" In poche parole, si potrebbe semplificare dicendo che un programma apprende se c'\u00e8 un miglioramento delle prestazioni dopo un compito svolto. Questa definizione di Mitchell \u00e8 rilevante poich\u00e9 fornisce una definizione operativa dell'apprendimento automatico, invece che in termini cognitivi. Fornendo questa definizione, Mitchell di fatto segue la proposta che Alan Turing fece nel suo articolo \"\"Computing Machinery and Intelligence\"\", sostituendo la domanda \"\"Le macchine possono pensare?\"\" con la domanda \"\"Le macchine possono fare quello che noi (in quanto entit\u00e0 pensanti) possiamo fare?\"\".\nL'obiettivo principe dell'apprendimento automatico \u00e8 che una macchina sia in grado di generalizzare dalla propria esperienza, ossia che sia in grado di svolgere ragionamenti induttivi. In questo contesto, per generalizzazione si intende l'abilit\u00e0 di una macchina di portare a termine in maniera accurata esempi o compiti nuovi, che non ha mai affrontato, dopo aver fatto esperienza su un insieme di dati di apprendimento. Gli esempi di addestramento (in inglese chiamati \"training examples\") si assume provengano da una qualche distribuzione di probabilit\u00e0, generalmente sconosciuta e considerata rappresentativa dello spazio delle occorrenze del fenomeno da apprendere; la macchina ha il compito di costruire un modello probabilistico generale dello spazio delle occorrenze, in maniera tale da essere in grado di produrre previsioni sufficientemente accurate quando sottoposta a nuovi casi.\nL'analisi computazionale degli algoritmi di apprendimento automatico e delle loro prestazioni \u00e8 una branca dell'Informatica teorica chiamata teoria dell'apprendimento. Dato che gli esempi di addestramento sono insiemi finiti di dati e non c'\u00e8 modo di sapere l'evoluzione futura di un modello, la teoria dell'apprendimento non offre alcuna garanzia sulle prestazioni degli algoritmi. D'altro canto, \u00e8 piuttosto comune che tali prestazioni siano vincolate da limiti probabilistici. Il bias-variance tradeoff \u00e8 uno dei modi di quantificare l'errore di generalizzazione.\nAffinch\u00e9 la generalizzazione offra le migliori prestazioni possibili, la complessit\u00e0 dell'ipotesi induttiva deve essere pari alla complessit\u00e0 della funzione sottostante i dati. Se l'ipotesi \u00e8 meno complessa della funzione, allora il modello manifesta \"underfitting\". Quando la complessit\u00e0 del modello viene aumentata in risposta, allora l'errore di apprendimento diminuisce. Al contrario invece se l'ipotesi \u00e8 troppo complessa, allora il modello manifesta overfitting e la generalizzazione sar\u00e0 pi\u00f9 scarsa.\nOltre ai limiti di prestazioni, i teorici dell'apprendimento studiano la complessit\u00e0 temporale e la fattibilit\u00e0 dell'apprendimento stesso. Una computazione \u00e8 considerata fattibile se pu\u00f2 essere svolta in tempo polinomiale.\nI compiti dell'apprendimento automatico vengono tipicamente classificati in tre ampie categorie, a seconda della natura del \"segnale\" utilizzato per l'apprendimento o del \"feedback\" disponibile al sistema di apprendimento. Queste categorie, anche dette paradigmi, sono:\nA met\u00e0 strada tra l'apprendimento supervisionato e quello non supervisionato c'\u00e8 l'apprendimento semi-supervisionato, nel quale l'insegnante fornisce un dataset incompleto per l'allenamento, cio\u00e8 un insieme di dati per l'allenamento tra i quali ci sono dati senza il rispettivo output desiderato. La trasduzione \u00e8 un caso speciale di questo principio, nel quale l'intero insieme delle istanze del problema \u00e8 noto durante l'apprendimento, eccetto la parte degli output desiderati che \u00e8 mancante.\nUn'altra categorizzazione dei compiti dell'apprendimento automatico si rileva quando si considera l'output desiderato del sistema di apprendimento automatico.\nL'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo Michael I. Jordan, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. Jordan ha anche suggerito il termine data science come nome con cui chiamare l'intero campo di studi.\nLeo Breiman ha distinto due paradigmi statistici di modellazione: modello basato sui dati e modello basato sugli algoritmi, dove \"modello basato sugli algoritmi\" indica approssimativamente algoritmi di apprendimento automatico come la foresta casuale.\nAlcuni statistici hanno adottato metodi provenienti dall'apprendimento automatico, il che ha portato alla creazione di una disciplina combinata chiamata \"apprendimento statistico\".\nL'apprendimento automatico viene a volte unito al data mining, che si focalizza maggiormente sull'analisi esplorativa dei dati ed utilizza principalmente il paradigma di apprendimento chiamato \"apprendimento non supervisionato\". Invece, l'apprendimento automatico pu\u00f2 essere anche supervisionato.\nL'apprendimento automatico e il \"data mining\" infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su propriet\u00e0 note apprese dai dati, il data mining si concentra sulla scoperta di propriet\u00e0 prima \"sconosciute\" nei dati. Il data mining sfrutta i metodi dell'apprendimento automatico, ma con obiettivi differenti; d'altro canto, l'apprendimento automatico utilizza i metodi di data mining come metodi di apprendimento non supervisionato o come passi di preprocessing per aumentare l'accuratezza dell'apprendimento. Gran parte della confusione tra le due comunit\u00e0 di ricerca scaturisce dall'assunzione di base del loro operato: nell'apprendimento automatico, le prestazioni sono generalmente valutate in base all'abilit\u00e0 di riprodurre conoscenza gi\u00e0 acquisita, mentre in data mining il compito chiave \u00e8 la scoperta di conoscenza che prima non si aveva.\nL'apprendimento automatico ha legami molto stretti con l'ottimizzazione: molti problemi di apprendimento sono formulati come la minimizzazione di una qualche funzione di costo su un insieme di esempi di apprendimento. La funzione di costo (o funzione di perdita) rappresenta la discrepanza tra le previsioni del modello che si sta addestrando e le istanze del problema reale. Le differenze tra i due campi (l'apprendimento automatico e l'ottimizzazione) sorgono dall'obiettivo della generalizzazione: mentre gli algoritmi di ottimizzazione possono minimizzare la perdita su un insieme di apprendimento, l'apprendimento automatico si preoccupa di minimizzare la perdita su campioni mai visti dalla macchina.\nLa risoluzione automatica di problemi avviene, nel campo dell'informatica, in due modi differenti: tramite paradigmi di \"hard computing\" o tramite paradigmi di \"soft computing\". Per \"hard computing\" si intende la risoluzione di un problema tramite l'esecuzione di un algoritmo ben definito e decidibile. La maggior parte dei paradigmi di \"hard computing\" sono metodi ormai consolidati, ma presentano alcuni lati negativi: infatti richiedono sempre un modello analitico preciso e definibile, e spesso un alto tempo di computazione. \nLe tecniche di \"soft computing\" d'altro canto antepongono il guadagno nella comprensione del comportamento di un sistema a scapito della precisione, spesso non necessaria. I paradigmi di \"soft computing\" si basano su due principi: \nL'apprendimento automatico si avvale delle tecniche di \"soft computing\".\nLa programmazione logica induttiva (anche ILP, dall'inglese \"inductive logic programming\") \u00e8 un approccio all'apprendimento di regole che usa la programmazione logica come rappresentazione uniforme per gli esempi di input, per la conoscenza di base della macchina, e per le ipotesi. Data una codifica della (nota) conoscenza di base e un insieme di esempi rappresentati come fatti in una base di dati logica, un sistema ILP deriva un programma logico ipotetico da cui conseguono tutti gli esempi positivi, e nessuno di quelli negativi. La programmazione induttiva \u00e8 un campo simile che considera ogni tipo di linguaggio di programmazione per rappresentare le ipotesi invece che soltanto la programmazione logica, come ad esempio programmi funzionali.\nL'albero di decisione \u00e8 un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende \u00e8 rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilit\u00e0 umana.\nL'apprendimento automatico basato su regole di associazione \u00e8 un metodo di apprendimento che identifica, apprende ed evolve delle \"regole\" con l'intento di immagazzinare, manipolare e applicare conoscenza. La caratteristica principale di questo tipo di apprendimento \u00e8 l'identificazione ed utilizzo di un insieme di regole relazionali che rappresenta nel suo insieme la conoscenza catturata dal sistema. Ci\u00f2 si pone in controtendenza con altri tipi di apprendimento automatico che normalmente identificano un singolo modello che pu\u00f2 essere applicato universalmente ad ogni istanza per riuscire a fare su di essa una previsione. Gli approcci dell'apprendimento basato su regole di associazione includono il sistema immunitario artificiale.\nUna rete neurale artificiale \u00e8 un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.\nGli algoritmi genetici forniscono un approccio all'apprendimento che \u00e8 liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi pi\u00f9 adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una variet\u00e0 di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.\nIl ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantit\u00e0 di interesse sono disciplinate da distribuzioni di probabilit\u00e0 e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilit\u00e0 insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana \u00e8 importante perch\u00e9 fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilit\u00e0.\nMacchine a vettori di supporto (\"Support Vector Machine\", SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.\nLa discesa dei prezzi per l'hardware e lo sviluppo di GPU per uso personale negli ultimi anni hanno contribuito allo sviluppo del concetto di apprendimento profondo, che consiste nello sviluppare livelli nascosti multipli nelle reti neurali artificiali. Questo approccio tenta di modellizzare il modo in cui il cervello umano processa luce e suoni e li interpreta in vista e udito. Alcune delle applicazioni pi\u00f9 affermate dell'apprendimento profondo sono la visione artificiale e il riconoscimento vocale.\nLa cluster analisi, o clustering, \u00e8 in grado di rilevare similarit\u00e0 strutturali tra le osservazioni di un dataset attraverso l'assegnazione di un insieme di osservazioni in sottogruppi (\"cluster\") di elementi tra loro omogenei. Il clustering \u00e8 un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.\nTutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.\nMetodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.\nMetodi di apprendimento automatico sono stati applicati ad una variet\u00e0 di database di grandi dimensioni per imparare regolarit\u00e0 generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema \u00e8 oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.\nI programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.\nL'apprendimento automatico solleva un numero di problematiche etiche. I sistemi addestrati con insiemi di dati faziosi o pregiudizievoli possono esibire questi pregiudizi quando vengono interpellati: in questo modo possono essere digitalizzati pregiudizi culturali quali il razzismo istituzionale e il classismo. Di conseguenza la raccolta responsabile dei dati pu\u00f2 diventare un aspetto critico dell'apprendimento automatico.\nIn ragione dell'innata ambiguit\u00e0 dei linguaggi naturali, le macchine addestrate su corpi linguistici necessariamente apprenderanno questa ambiguit\u00e0."], "concept_B": "Apprendimento automatico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_A": "Macchine a vettori di supporto", "wikipedia_passage_concept_B": ["3612028", "Classificazione statistica", "La classificazione statistica \u00e8 quell'attivit\u00e0 che si serve di un algoritmo statistico al fine di individuare una rappresentazione di alcune caratteristiche di un'entit\u00e0 da classificare (oggetto o nozione), associandole una etichetta classificatoria. Tale attivit\u00e0 pu\u00f2 essere svolta mediante algoritmi di apprendimento automatico supervisionato o non supervisionato. Esempi di questi algoritmi sono:\nI programmi che effettuano l'attivit\u00e0 di classificazione sono detti classificatori. Talora si usa l'aggettivo \"statistica\" anche per classificazioni utilizzate per costruire indicazioni statistiche sulle entit\u00e0 assegnate ai diversi contenitori di una classificazione, soprattutto nel caso delle tassonomie, mentre nella definizione della classificazione non si sono utilizzati precisi metodi statistici."], "concept_B": "Classificazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["3216546", "Analisi dei dati", "Nell'ambito della scienza dei dati l'analisi dei dati \u00e8 un processo di ispezione, pulizia, trasformazione e modellazione di dati con il fine di evidenziare informazioni che suggeriscano conclusioni e supportino le decisioni strategiche aziendali. L'analisi di dati ha molti approcci e sfaccettature, il che comprende tecniche diversissime tra loro che si riconoscono con una serie di definizioni varie nel commercio, le scienze naturali e sociali.\nIl data mining \u00e8 una tecnica particolare di analisi dei dati che si focalizza nella modellazione e scoperta di conoscenza per scopi predittivi piuttosto che descrittivi. Il business intelligence identifica l'analisi di dati che si basa fondamentalmente sull'aggregazione, focalizzandosi sulle informazioni aziendali. Nell'ambito dei big data si parla di big data analytics. Nelle applicazioni statistiche, gli studiosi dividono l'analisi dei dati in statistica descrittiva, analisi dei dati esplorativa (ADE) e analisi dei dati di conferma (ADC). L'ADE si concentra sullo scoprire nuove caratteristiche presenti nei dati, mentre l'ADC nel confermare o falsificare le ipotesi esistenti. L'analisi predittiva si concentra sull'applicazione di modelli statistici o strutturali per classificazione o il forecasting predittivo, mentre l'analisi testuale applica tecniche statistiche, linguistiche e strutturali per estrarre e classificare informazioni da fonti testuali, una categoria di dati non-strutturati.\nL'integrazione di dati \u00e8 un precursore dell'analisi dei dati, la quale \u00e8 collegata alla visualizzazione di dati."], "concept_B": "Analisi dei dati", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["3854", "Scarto interquartile", "In statistica lo scarto interquartile (o differenza interquartile o ampiezza interquartile, in inglese \"interquartile range\" o \"IQR\") \u00e8 la differenza tra il terzo e il primo quartile, ovvero l'ampiezza della fascia di valori che contiene la met\u00e0 \"centrale\" dei valori osservati.\nLo scarto interquartile \u00e8 un indice di dispersione, cio\u00e8 una misura di quanto i valori si allontanino da un valore centrale. Viene utilizzato nel disegno del diagramma box-plot.\nLo scarto interquartile di una variabile aleatoria si ottiene tramite la funzione di ripartizione, come differenza formula_1\nPer una variabile casuale normale formula_2 lo scarto interquartile \u00e8 circa formula_3.\nPer una variabile casuale di Cauchy formula_4 lo scarto interquartile \u00e8 formula_5."], "concept_A": "Scarto interquartile", "wikipedia_passage_concept_B": ["840579", "Variabilit\u00e0", "Nella terminologia statistica, la variabilit\u00e0 di un carattere X, rilevato su n unit\u00e0 statistiche, \u00e8 l'attitudine di questo a manifestarsi in diversi modi, ossia con diverse modalit\u00e0.\nQuando il carattere \u00e8 \"quantitativo\", la variabilit\u00e0 pu\u00f2 essere misurata usando indici basati sulla distanza delle modalit\u00e0 rispetto ad un indice di posizione (generalmente rispetto alla media aritmetica o alla mediana); gli indici di variabilit\u00e0 pi\u00f9 utilizzati sono la varianza, lo scarto quadratico medio o deviazione standard, il coefficiente di variazione.\nSe invece il carattere \u00e8 \"qualitativo\", la variabilit\u00e0 pu\u00f2 essere misurata con indici di eterogeneit\u00e0.\nLe propriet\u00e0 della variabilit\u00e0 sono:\nEsempio 1: rileviamo il carattere reddito su 5 unit\u00e0 statistiche; supponiamo che il risultato della rilevazione sia 1.000 euro su ognuna delle 5 unit\u00e0: in tal caso la variabilit\u00e0 del carattere sar\u00e0 nulla perch\u00e9 il carattere reddito si \u00e8 manifestato sempre nello stesso modo (ossia con un'unica modalit\u00e0: 1.000).\nEsempio 2: supponiamo che, nel contesto dell'esempio precedente, il risultato della rilevazione sia 1.000 sulla prima unit\u00e0, 1.100 sulla seconda, 1.500 sulla terza, 5.000 sulla quarta e 8.500 sulla quinta; in tal caso, la variabilit\u00e0 del carattere risulta maggiore di zero, perch\u00e9 il carattere si \u00e8 manifestato sulle cinque unit\u00e0 statistiche con diverse modalit\u00e0.\nEsempio 3: supponiamo ora che il risultato della rilevazione sia 800 sulla prima unit\u00e0, 12.000 sulla seconda, 6.500 sulla terza, 9.000 sulla quarta e 2.500 sulla quinta; in tal caso la variabilit\u00e0 aumenta perch\u00e9 le modalit\u00e0 rilevate, oltre ad essere tutte diverse, risultano essere pi\u00f9 \"distanti\" tra loro.\nIn generale, la variabilit\u00e0 di un carattere quantitativo \u00e8 tanto maggiore quanto pi\u00f9 numerose sono le modalit\u00e0 con cui esso si manifesta sulle unit\u00e0 statistiche e quanto pi\u00f9 le modalit\u00e0 rilevate sono \"distanti\" tra loro."], "concept_B": "Variabilit\u00e0", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1238309", "Algoritmo apriori", "In informatica e in data mining, l'algoritmo Apriori \u00e8 un classico algoritmo di ricerca delle associazioni. \u00c8 utilizzato per la generazione degli itemset frequenti, per approssimazioni successive, a partire dagli itemset con un solo elemento. In sintesi, il presupposto teorico su cui si basa l'algoritmo parte dalla considerazione che se un insieme di oggetti (itemset) \u00e8 frequente, allora anche tutti i suoi sottoinsiemi sono frequenti, ma se un itemset non \u00e8 frequente, allora neanche gli insiemi che lo contengono sono frequenti (principio di anti-monotonicit\u00e0).\nUn ambito dove questo algoritmo trova grande applicabilit\u00e0 \u00e8 il \"market/basket problem\". Per ricavare le associazioni viene impiegato un approccio \"bottom up\", dove i sottoinsiemi frequenti sono costruiti aggiungendo un item per volta (generazione dei candidati); i gruppi di candidati sono successivamente verificati sui dati e l'algoritmo termina quando non ci sono ulteriori estensioni possibili. In questo processo, il numero delle iterazioni \u00e8 formula_1, dove formula_2 indica la cardinalit\u00e0 massima di un itemset frequente.\nVi sono altri algoritmi con finalit\u00e0 analoghe (Winepi e Minepi), e che tuttavia sono pi\u00f9 diffusi in ambiti dove i dati sono privi di timestamp (ad esempio le sequenze di DNA).\nApriori, anche se storicamente significativo, soffre di alcune inefficienze. In particolare, la generazione dei candidati crea molti sottoinsiemi. Nel processo vengono individuati i sottoinsiemi significativi solo dopo aver trovato tutti i formula_3 sottoinsiemi propri, dove S \u00e8 il gruppo di elementi specifico (Supporto) in cui un particolare sottoinsieme di oggetti compare.\nI passi dell'algoritmo per trovare gli insiemi frequenti formula_4 nel Database formula_5:\ndove formula_7 \u00e8 il candidato itemset di grandezza formula_12 e dove inoltre formula_13 \u00e8 l'itemset frequente di grandezza formula_12\nQuesto esempio mostra il processo di selezione ovvero generazione di una lista ordinata di itemset candidati.\nIl compito consiste nella costruzione di un insieme ordinato di formula_12 nodi, in modo seriale, a partire da itemset di grandezza formula_16.\nAd esempio, con formula_17, supponiamo che ci siano due di tali insiemi di grandezza formula_16\ne \nebbene i due itemset candidati generati saranno\ne \n\"Apriori\" formula_23"], "concept_A": "Algoritmo apriori", "wikipedia_passage_concept_B": ["3645149", "Regole di associazione", "Nel data mining, le regole di associazione sono uno dei metodi per estrarre relazioni nascoste tra i dati.\nAgrawal et al. introdussero le regole di associazione per la scoperta di regolarit\u00e0 all'interno delle transazioni registrate nelle vendite dei supermercati. Per esempio, la regola formula_1 individuata nell'analisi degli scontrini di un supermercato indica che il se il cliente compra insieme cipolle e patate \u00e8 probabile che acquisti anche della carne per hamburger. Tale informazione pu\u00f2 essere utilizzata come base per le decisioni riguardanti le attivit\u00e0 di marketing, come ad esempio le offerte promozionali o il posizionamento dei prodotti negli scaffali.\nLe regole di associazione sono anche usate in molte altre aree, quali il Web mining, la scoperta di anomalie e la bioinformatica.\nIl concetto di regola di associazione divenne popolare a causa di un articolo del 1993 di Agrawal et al.. Secondo Google Scholar esso possiede pi\u00f9 di 9500 citazioni (Settembre 2010) ed \u00e8 uno degli articoli pi\u00f9 citati nel campo del data mining. Tuttavia \u00e8 possibile che quella che viene chiamata come \"regola di associazione\" sia simile a un approccio di data mining presentato nel 1966 e sviluppato da H\u00e1jek et al..\nSeguendo la definizione originale di Agrawal et al. il problema della scoperta di regole di associazione \u00e8 rappresentato come segue.\nConsideriamo l'insieme di formula_2 attributi binari (\"oggetti\" o \"item\") formula_3 e l'insieme di transazioni (\"database\")formula_4. Ciascuna transazione appartenente a formula_5 possiede un codice identificativo (ID) e contiene un sottoinsieme degli oggetti contenuti in formula_6. Una \"regola\" \u00e8 definita come un'implicazione nella forma formula_7 dove formula_8\ne formula_9. L'insieme di oggetti (o \"itemsets\") formula_10 e formula_11 vengono chiamati rispettivamente \"antecendente\" e \"conseguente\" della regola.\nPer illustrare questo concetto, \u00e8 possibile usare un esempio giocattolo riguardante un supermercato.\nL'insieme di oggetti \u00e8 formula_12 e il database contenente gli oggetti \u00e8 rappresentato nella tabella a destra, dove 1 indica la presenza di un oggetto in una transazione e 0 l'assenza. Un esempio di regola di associazione potrebbe essere: formula_13. Essa indica che se il cliente acquista pane e burro, comprer\u00e0 anche il latte.\nAttenzione: questo esempio \u00e8 estremamente piccolo. In un'applicazione reale una regola necessita di un supporto di diverse centinaia di transazioni perch\u00e9 sia considerata statisticamente significativa e il database deve contenere migliaia (o milioni) di transazioni."], "concept_B": "Regole di associazione", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_A": "Rete bayesiana", "wikipedia_passage_concept_B": ["3678589", "Distribuzione condizionata", "variabili aleatorie \"X\" e \"Y\", la distribuzione condizionata di Y dato X \u00e8 la probabilit\u00e0 di Y quando \u00e8 conosciuto il valore assunto da X. A ogni distribuzione condizionata \u00e8 associato un valore atteso condizionato e una varianza condizionata.\nNel caso di variabili aletorie discrete, la distribuzione condizionata di \"Y\" dato \"X=x\", \u00e8 data da:\n\u00c8 necessario quindi che \"P(X=x)>0\".\nNel caso di variabili aleatorie continue, la densit\u00e0 condizionata di \"Y\" dato \"X=x\" \u00e8 data da\nAnche in questo caso, si deve avere che formula_3.\nSe per due variabili aleatorie \"X\" e \"Y\" si ha che \"P\"(\"Y\" = \"y\" | \"X\" = \"x\") = \"P\"(\"Y\" = \"y\") per ogni \"x\" e \"y\" o, nel caso continuo, \"f\"(\"y\" | \"X=x\") = \"f\"(\"y\") per ogni \"x\" e \"y\", allora le due variabili sono dette indipendenti"], "concept_B": "Distribuzione condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_A": "Data mining", "wikipedia_passage_concept_B": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_B": "Test di verifica d'ipotesi", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_A": "K-means", "wikipedia_passage_concept_B": ["3216546", "Analisi dei dati", "Nell'ambito della scienza dei dati l'analisi dei dati \u00e8 un processo di ispezione, pulizia, trasformazione e modellazione di dati con il fine di evidenziare informazioni che suggeriscano conclusioni e supportino le decisioni strategiche aziendali. L'analisi di dati ha molti approcci e sfaccettature, il che comprende tecniche diversissime tra loro che si riconoscono con una serie di definizioni varie nel commercio, le scienze naturali e sociali.\nIl data mining \u00e8 una tecnica particolare di analisi dei dati che si focalizza nella modellazione e scoperta di conoscenza per scopi predittivi piuttosto che descrittivi. Il business intelligence identifica l'analisi di dati che si basa fondamentalmente sull'aggregazione, focalizzandosi sulle informazioni aziendali. Nell'ambito dei big data si parla di big data analytics. Nelle applicazioni statistiche, gli studiosi dividono l'analisi dei dati in statistica descrittiva, analisi dei dati esplorativa (ADE) e analisi dei dati di conferma (ADC). L'ADE si concentra sullo scoprire nuove caratteristiche presenti nei dati, mentre l'ADC nel confermare o falsificare le ipotesi esistenti. L'analisi predittiva si concentra sull'applicazione di modelli statistici o strutturali per classificazione o il forecasting predittivo, mentre l'analisi testuale applica tecniche statistiche, linguistiche e strutturali per estrarre e classificare informazioni da fonti testuali, una categoria di dati non-strutturati.\nL'integrazione di dati \u00e8 un precursore dell'analisi dei dati, la quale \u00e8 collegata alla visualizzazione di dati."], "concept_B": "Analisi dei dati", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["8208004", "Bagging", "Il bagging \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel bagging pi\u00f9 modelli dello stesso tipo vengono addestrati su dataset diversi, ciascuno ottenuto dal dataset iniziale tramite campionamento casuale con rimpiazzo (bootstrap). Il nome \"bagging\" deriva dalla combinazione delle parole inglesi \"bootstrap\" (ovvero il campionamento casuale con rimpiazzo) e \"aggregation\" (in riferimento all'aggregazione di pi\u00f9 modelli, tipico dell'Apprendimento ensemble)."], "concept_B": "Bagging", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_A": "Macchine a vettori di supporto", "wikipedia_passage_concept_B": ["605", "Apprendimento automatico", "L\u2019apprendimento automatico (noto anche come machine learning) \u00e8 una branca dell'intelligenza artificiale che raccoglie un insieme di metodi, sviluppati a partire dagli ultimi decenni del XX secolo in varie comunit\u00e0 scientifiche, sotto diversi nomi quali: statistica computazionale, riconoscimento di pattern, reti neurali artificiali, filtraggio adattivo, teoria dei sistemi dinamici, elaborazione delle immagini, data mining, algoritmi adattivi, ecc; che utilizza metodi statistici per migliorare progressivamente la performance di un algoritmo nell'identificare pattern nei dati. Nell'ambito dell'informatica, l'apprendimento automatico \u00e8 una variante alla programmazione tradizionale nella quale si predispone in una macchina l'abilit\u00e0 di apprendere qualcosa dai dati in maniera autonoma, senza ricevere istruzioni esplicite a riguardo.\nLo stesso Arthur Samuel che coni\u00f2 il termine nel 1959 in linea di principio identifica due approcci distinti. Il primo metodo, indicato come rete neurale, porta allo sviluppo di macchine ad apprendimento automatico per impiego generale in cui il comportamento \u00e8 appreso da una rete di commutazione connessa casualmente, a seguito di una routine di apprendimento basata su ricompensa e punizione (apprendimento per rinforzo). Il secondo metodo, pi\u00f9 specifico, consiste nel riprodurre l'equivalente di una rete altamente organizzata progettata per imparare solo alcune attivit\u00e0 specifiche. La seconda procedura, che necessita di supervisione, richiede la riprogrammazione per ogni nuova applicazione, ma risulta essere molto pi\u00f9 efficiente dal punto di vista computazionale.\nL'apprendimento automatico \u00e8 strettamente legato al riconoscimento di pattern e alla teoria computazionale dell'apprendimento ed esplora lo studio e la costruzione di algoritmi che possano apprendere da un insieme di dati e fare delle predizioni su questi, costruendo in modo induttivo un modello basato su dei campioni. L'apprendimento automatico viene impiegato in quei campi dell'informatica nei quali progettare e programmare algoritmi espliciti \u00e8 impraticabile; tra le possibili applicazioni citiamo il filtraggio delle email per evitare spam, l'individuazione di intrusioni in una rete o di intrusi che cercano di violare dati, il riconoscimento ottico dei caratteri, i motori di ricerca e la visione artificiale.\nL'apprendimento automatico \u00e8 strettamente collegato, e spesso si sovrappone con la statistica computazionale, che si occupa dell'elaborazione di predizioni tramite l'uso di computer. L'apprendimento automatico \u00e8 anche fortemente legato all'ottimizzazione matematica, che fornisce metodi, teorie e domini di applicazione a questo campo. Per usi commerciali, l'apprendimento automatico \u00e8 conosciuto come analisi predittiva.\nL'apprendimento automatico si sviluppa con lo studio dell'intelligenza artificiale, e vi \u00e8 strettamente collegato: infatti gi\u00e0 dai primi tentativi di definire l'intelligenza artificiale come disciplina accademica, alcuni ricercatori si erano mostrati interessati alla possibilit\u00e0 che le macchine imparassero dai dati. Questi ricercatori, in particolare Marvin Minsky, Arthur Samuel e Frank Rosenblatt, provarono ad avvicinarsi al problema sia attraverso vari metodi formali, sia con quelle che vengono definite reti neurali nei tardi anni '50. Le reti neurali erano allora costituite da singoli percettroni e da modelli matematici derivati dal modello lineare generalizzato della statistica, come l'ADALINE di Widrow. Si prov\u00f2 a sfruttare anche ragionamenti probabilistici, in particolare nelle diagnosi mediche automatiche.\nSempre negli anni '50, Alan Turing propose l'idea di una \"macchina che apprende\", ovvero in grado di imparare e dunque diventare intelligente. La proposta specifica di Turing anticipa gli algoritmi genetici.\nTuttavia gi\u00e0 dalla met\u00e0 degli anni '50 lo studio dell'intelligenza artificiale si stava concentrando su approcci logici di tipo \"knowledge-based\", nota oggi sotto il nome di GOFAI, causando un distacco tra lo studio dell'IA e quello dell'apprendimento automatico. Sistemi di tipo probabilistico erano invasi di problemi sia teoretici sia pratici in termini di acquisizione e rappresentazione dei dati. Negli anni Ottanta, i sistemi esperti dominavano il campo dell'IA, e i sistemi basati sulla statistica non venivano pi\u00f9 studiati.\nLo studio dell'apprendimento simbolico e \"knowledge-based\" continu\u00f2 nell'ambito dell'IA, portando a sviluppare la programmazione logica induttiva, ma ora la ricerca pi\u00f9 prettamente statistica si svolgeva al di fuori del campo vero e proprio dell'intelligenza artificiale, nel riconoscimento di pattern e nell'information retrieval.\nUn altro motivo per cui lo studio dell'apprendimento automatico fu abbandonato fu la pubblicazione del libro \"Perceptrons: an introduction to computational geometry\" di Marvin Minsky e Seymour Papert, che vi descrivevano alcune delle limitazioni dei percettroni e delle reti neurali. La ricerca sulle reti neurali sub\u00ec un significativo rallentamento a causa dell'interpretazione del libro, che le descriveva come intrinsecamente limitate. Anche la linea di ricerca sulle reti neurali continu\u00f2 al di fuori del campo dell'IA, portata avanti da ricercatori provenienti da altre discipline quali Hopfield, Rumelhart, Hinton e Fukushima. Il loro successo principale fu a met\u00e0 degli anni '80 con la riscoperta della \"backpropagation\" e della self-organization.\nL'apprendimento automatico, sviluppatosi come campo di studi separato dall'IA classica, cominci\u00f2 a rifiorire negli anni '90. Il suo obiettivo cambi\u00f2 dall'ottenere l'intelligenza artificiale ad affrontare problemi risolvibili di natura pratica. Distolse inoltre la propria attenzione dagli approcci simbolici che aveva ereditato dall'IA, e si diresse verso metodi e modelli presi in prestito dalla statistica e dalla teoria della probabilit\u00e0. L'apprendimento automatico ha inoltre beneficiato dalla nascita di Internet, che ha reso l'informazione digitale pi\u00f9 facilmente reperibile e distribuibile.\nTom M. Mitchell ha fornito la definizione pi\u00f9 citata di apprendimento automatico nel suo libro \"\"Machine Learning\"\": \"\"Si dice che un programma apprende dall'esperienza E con riferimento a alcune classi di compiti T e con misurazione della performance P, se le sue performance nel compito T, come misurato da P, migliorano con l'esperienza E.\"\" In poche parole, si potrebbe semplificare dicendo che un programma apprende se c'\u00e8 un miglioramento delle prestazioni dopo un compito svolto. Questa definizione di Mitchell \u00e8 rilevante poich\u00e9 fornisce una definizione operativa dell'apprendimento automatico, invece che in termini cognitivi. Fornendo questa definizione, Mitchell di fatto segue la proposta che Alan Turing fece nel suo articolo \"\"Computing Machinery and Intelligence\"\", sostituendo la domanda \"\"Le macchine possono pensare?\"\" con la domanda \"\"Le macchine possono fare quello che noi (in quanto entit\u00e0 pensanti) possiamo fare?\"\".\nL'obiettivo principe dell'apprendimento automatico \u00e8 che una macchina sia in grado di generalizzare dalla propria esperienza, ossia che sia in grado di svolgere ragionamenti induttivi. In questo contesto, per generalizzazione si intende l'abilit\u00e0 di una macchina di portare a termine in maniera accurata esempi o compiti nuovi, che non ha mai affrontato, dopo aver fatto esperienza su un insieme di dati di apprendimento. Gli esempi di addestramento (in inglese chiamati \"training examples\") si assume provengano da una qualche distribuzione di probabilit\u00e0, generalmente sconosciuta e considerata rappresentativa dello spazio delle occorrenze del fenomeno da apprendere; la macchina ha il compito di costruire un modello probabilistico generale dello spazio delle occorrenze, in maniera tale da essere in grado di produrre previsioni sufficientemente accurate quando sottoposta a nuovi casi.\nL'analisi computazionale degli algoritmi di apprendimento automatico e delle loro prestazioni \u00e8 una branca dell'Informatica teorica chiamata teoria dell'apprendimento. Dato che gli esempi di addestramento sono insiemi finiti di dati e non c'\u00e8 modo di sapere l'evoluzione futura di un modello, la teoria dell'apprendimento non offre alcuna garanzia sulle prestazioni degli algoritmi. D'altro canto, \u00e8 piuttosto comune che tali prestazioni siano vincolate da limiti probabilistici. Il bias-variance tradeoff \u00e8 uno dei modi di quantificare l'errore di generalizzazione.\nAffinch\u00e9 la generalizzazione offra le migliori prestazioni possibili, la complessit\u00e0 dell'ipotesi induttiva deve essere pari alla complessit\u00e0 della funzione sottostante i dati. Se l'ipotesi \u00e8 meno complessa della funzione, allora il modello manifesta \"underfitting\". Quando la complessit\u00e0 del modello viene aumentata in risposta, allora l'errore di apprendimento diminuisce. Al contrario invece se l'ipotesi \u00e8 troppo complessa, allora il modello manifesta overfitting e la generalizzazione sar\u00e0 pi\u00f9 scarsa.\nOltre ai limiti di prestazioni, i teorici dell'apprendimento studiano la complessit\u00e0 temporale e la fattibilit\u00e0 dell'apprendimento stesso. Una computazione \u00e8 considerata fattibile se pu\u00f2 essere svolta in tempo polinomiale.\nI compiti dell'apprendimento automatico vengono tipicamente classificati in tre ampie categorie, a seconda della natura del \"segnale\" utilizzato per l'apprendimento o del \"feedback\" disponibile al sistema di apprendimento. Queste categorie, anche dette paradigmi, sono:\nA met\u00e0 strada tra l'apprendimento supervisionato e quello non supervisionato c'\u00e8 l'apprendimento semi-supervisionato, nel quale l'insegnante fornisce un dataset incompleto per l'allenamento, cio\u00e8 un insieme di dati per l'allenamento tra i quali ci sono dati senza il rispettivo output desiderato. La trasduzione \u00e8 un caso speciale di questo principio, nel quale l'intero insieme delle istanze del problema \u00e8 noto durante l'apprendimento, eccetto la parte degli output desiderati che \u00e8 mancante.\nUn'altra categorizzazione dei compiti dell'apprendimento automatico si rileva quando si considera l'output desiderato del sistema di apprendimento automatico.\nL'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo Michael I. Jordan, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. Jordan ha anche suggerito il termine data science come nome con cui chiamare l'intero campo di studi.\nLeo Breiman ha distinto due paradigmi statistici di modellazione: modello basato sui dati e modello basato sugli algoritmi, dove \"modello basato sugli algoritmi\" indica approssimativamente algoritmi di apprendimento automatico come la foresta casuale.\nAlcuni statistici hanno adottato metodi provenienti dall'apprendimento automatico, il che ha portato alla creazione di una disciplina combinata chiamata \"apprendimento statistico\".\nL'apprendimento automatico viene a volte unito al data mining, che si focalizza maggiormente sull'analisi esplorativa dei dati ed utilizza principalmente il paradigma di apprendimento chiamato \"apprendimento non supervisionato\". Invece, l'apprendimento automatico pu\u00f2 essere anche supervisionato.\nL'apprendimento automatico e il \"data mining\" infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su propriet\u00e0 note apprese dai dati, il data mining si concentra sulla scoperta di propriet\u00e0 prima \"sconosciute\" nei dati. Il data mining sfrutta i metodi dell'apprendimento automatico, ma con obiettivi differenti; d'altro canto, l'apprendimento automatico utilizza i metodi di data mining come metodi di apprendimento non supervisionato o come passi di preprocessing per aumentare l'accuratezza dell'apprendimento. Gran parte della confusione tra le due comunit\u00e0 di ricerca scaturisce dall'assunzione di base del loro operato: nell'apprendimento automatico, le prestazioni sono generalmente valutate in base all'abilit\u00e0 di riprodurre conoscenza gi\u00e0 acquisita, mentre in data mining il compito chiave \u00e8 la scoperta di conoscenza che prima non si aveva.\nL'apprendimento automatico ha legami molto stretti con l'ottimizzazione: molti problemi di apprendimento sono formulati come la minimizzazione di una qualche funzione di costo su un insieme di esempi di apprendimento. La funzione di costo (o funzione di perdita) rappresenta la discrepanza tra le previsioni del modello che si sta addestrando e le istanze del problema reale. Le differenze tra i due campi (l'apprendimento automatico e l'ottimizzazione) sorgono dall'obiettivo della generalizzazione: mentre gli algoritmi di ottimizzazione possono minimizzare la perdita su un insieme di apprendimento, l'apprendimento automatico si preoccupa di minimizzare la perdita su campioni mai visti dalla macchina.\nLa risoluzione automatica di problemi avviene, nel campo dell'informatica, in due modi differenti: tramite paradigmi di \"hard computing\" o tramite paradigmi di \"soft computing\". Per \"hard computing\" si intende la risoluzione di un problema tramite l'esecuzione di un algoritmo ben definito e decidibile. La maggior parte dei paradigmi di \"hard computing\" sono metodi ormai consolidati, ma presentano alcuni lati negativi: infatti richiedono sempre un modello analitico preciso e definibile, e spesso un alto tempo di computazione. \nLe tecniche di \"soft computing\" d'altro canto antepongono il guadagno nella comprensione del comportamento di un sistema a scapito della precisione, spesso non necessaria. I paradigmi di \"soft computing\" si basano su due principi: \nL'apprendimento automatico si avvale delle tecniche di \"soft computing\".\nLa programmazione logica induttiva (anche ILP, dall'inglese \"inductive logic programming\") \u00e8 un approccio all'apprendimento di regole che usa la programmazione logica come rappresentazione uniforme per gli esempi di input, per la conoscenza di base della macchina, e per le ipotesi. Data una codifica della (nota) conoscenza di base e un insieme di esempi rappresentati come fatti in una base di dati logica, un sistema ILP deriva un programma logico ipotetico da cui conseguono tutti gli esempi positivi, e nessuno di quelli negativi. La programmazione induttiva \u00e8 un campo simile che considera ogni tipo di linguaggio di programmazione per rappresentare le ipotesi invece che soltanto la programmazione logica, come ad esempio programmi funzionali.\nL'albero di decisione \u00e8 un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende \u00e8 rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilit\u00e0 umana.\nL'apprendimento automatico basato su regole di associazione \u00e8 un metodo di apprendimento che identifica, apprende ed evolve delle \"regole\" con l'intento di immagazzinare, manipolare e applicare conoscenza. La caratteristica principale di questo tipo di apprendimento \u00e8 l'identificazione ed utilizzo di un insieme di regole relazionali che rappresenta nel suo insieme la conoscenza catturata dal sistema. Ci\u00f2 si pone in controtendenza con altri tipi di apprendimento automatico che normalmente identificano un singolo modello che pu\u00f2 essere applicato universalmente ad ogni istanza per riuscire a fare su di essa una previsione. Gli approcci dell'apprendimento basato su regole di associazione includono il sistema immunitario artificiale.\nUna rete neurale artificiale \u00e8 un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.\nGli algoritmi genetici forniscono un approccio all'apprendimento che \u00e8 liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi pi\u00f9 adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una variet\u00e0 di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.\nIl ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantit\u00e0 di interesse sono disciplinate da distribuzioni di probabilit\u00e0 e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilit\u00e0 insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana \u00e8 importante perch\u00e9 fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilit\u00e0.\nMacchine a vettori di supporto (\"Support Vector Machine\", SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.\nLa discesa dei prezzi per l'hardware e lo sviluppo di GPU per uso personale negli ultimi anni hanno contribuito allo sviluppo del concetto di apprendimento profondo, che consiste nello sviluppare livelli nascosti multipli nelle reti neurali artificiali. Questo approccio tenta di modellizzare il modo in cui il cervello umano processa luce e suoni e li interpreta in vista e udito. Alcune delle applicazioni pi\u00f9 affermate dell'apprendimento profondo sono la visione artificiale e il riconoscimento vocale.\nLa cluster analisi, o clustering, \u00e8 in grado di rilevare similarit\u00e0 strutturali tra le osservazioni di un dataset attraverso l'assegnazione di un insieme di osservazioni in sottogruppi (\"cluster\") di elementi tra loro omogenei. Il clustering \u00e8 un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.\nTutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.\nMetodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.\nMetodi di apprendimento automatico sono stati applicati ad una variet\u00e0 di database di grandi dimensioni per imparare regolarit\u00e0 generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema \u00e8 oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.\nI programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.\nL'apprendimento automatico solleva un numero di problematiche etiche. I sistemi addestrati con insiemi di dati faziosi o pregiudizievoli possono esibire questi pregiudizi quando vengono interpellati: in questo modo possono essere digitalizzati pregiudizi culturali quali il razzismo istituzionale e il classismo. Di conseguenza la raccolta responsabile dei dati pu\u00f2 diventare un aspetto critico dell'apprendimento automatico.\nIn ragione dell'innata ambiguit\u00e0 dei linguaggi naturali, le macchine addestrate su corpi linguistici necessariamente apprenderanno questa ambiguit\u00e0."], "concept_B": "Apprendimento automatico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_A": "Test di verifica d'ipotesi", "wikipedia_passage_concept_B": ["2292", "Ipotesi nulla", "Un'ipotesi nulla (in inglese \"null hypothesis,\" che significa letteralmente ipotesi zero) \u00e8 un'affermazione sulla distribuzione di probabilit\u00e0 di una o pi\u00f9 variabili casuali. Si intende per ipotesi nulla l'affermazione secondo la quale non ci sia differenza oppure non vi sia relazione tra due fenomeni misurati, o associazione tra due gruppi. Solitamente viene assunta vera finch\u00e9 non si trova evidenza che la confuti.\nNel test statistico viene verificata in termini probabilistici la validit\u00e0 di un'ipotesi statistica, detta appunto ipotesi nulla, di solito indicata con \"H\".\nAttraverso una funzione dei dati campionari si decide se accettare l'ipotesi nulla o meno. Nel caso l'ipotesi nulla venga rifiutata si accetter\u00e0 l'ipotesi alternativa, indicata con \"H\".\nSe si rifiuta un'ipotesi nulla che nella realt\u00e0 \u00e8 vera allora si dice che si \u00e8 commesso un errore di prima specie (o falso positivo). Accettando invece un'ipotesi nulla falsa si commette un errore di seconda specie (o falso negativo).\nL'ipotesi pu\u00f2 essere di tipo funzionale se riferita alla forma della f (x;\u03b8) con f funzione di densit\u00e0 o di probabilit\u00e0, o parametrica se riferita al vettore incognito \u03b8.\nL'ipotesi \u00e8 semplice quando specifica completamente la f (x;\u03b8). Nel caso un'ipotesi non sia semplice si dir\u00e0 composta.\nQuando si considera un solo parametro l'ipotesi semplice \u00e8 del tipo \u03b8=\u03b8, dove \u03b8 \u00e8 un valore particolare. Un'ipotesi \u00e8 unilaterale se \u00e8 del tipo \u03b8 > \u03b8 oppure del tipo \u03b8 < \u03b8.\nUn'ipotesi \u00e8 bilaterale se \u00e8 del tipo \u03b8 \u2260 \u03b8 oppure del tipo \u03b8 < \u03b8 e \u03b8 > \u03b8."], "concept_B": "Ipotesi nulla", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["2244534", "Receiver operating characteristic", "Nella teoria delle decisioni, le curve ROC (Receiver Operating Characteristic, anche note come Relative Operating Characteristic) sono degli schemi grafici per un classificatore binario. Lungo i due assi si possono rappresentare la sensibilit\u00e0 e (1-specificit\u00e0), rispettivamente rappresentati da \"True Positive Rate\" (TPR, frazione di veri positivi) e \"False Positive Rate\" (FPR, frazione di falsi positivi). In altre parole, si studiano i rapporti fra allarmi veri (\"hit rate\") e falsi allarmi.\nLa curva ROC viene creata tracciando il valore del \"True Positive Rate\" (TPR, frazione di veri positivi) rispetto al \"False Positive Rate\" (FPR, frazione di falsi positivi) a varie impostazioni di soglia. Il tasso di veri positivi \u00e8 anche noto come sensibilit\u00e0, richiamo o probabilit\u00e0 di rilevazione. Il tasso di falsi positivi \u00e8 anche noto come fall-out o probabilit\u00e0 di falsi allarmi e pu\u00f2 essere calcolato come (1 - specificit\u00e0). Pu\u00f2 anche essere pensato come un diagramma della potenza in funzione dell'errore di tipo I :quando la prestazione viene calcolata da un solo campione della popolazione, pu\u00f2 essere considerata come una stima di queste quantit\u00e0. La curva ROC \u00e8 quindi il tasso dei veri positivi in funzione del tasso dei falsi positivi. In generale, se sono note le distribuzioni di sensibilit\u00e0 e 1-specificit\u00e0, la curva ROC pu\u00f2 essere generata tracciando la funzione di distribuzione cumulativa (area sotto la distribuzione di probabilit\u00e0 da formula_1 alla soglia di discriminazione) della probabilit\u00e0 di rilevamento nell'asse y rispetto alla funzione di distribuzione cumulativa della probabilit\u00e0 di falso allarme sull'asse x.\nIl ROC \u00e8 anche noto come curva Receiver Operating Characteristic, poich\u00e9 \u00e8 un confronto tra due caratteristiche operative (TPR e FPR) al cambiare del criterio.\nLe curve ROC furono utilizzate per la prima volta durante la seconda guerra mondiale, da alcuni ingegneri elettrotecnici che volevano individuare i nemici utilizzando il radar durante le battaglie aeree. Recentemente le curve ROC sono utilizzate in medicina, radiologia, psicologia, meteorologia, veterinaria, fisica e altri ambiti, come il machine learning ed il data mining.\nSe si considera un problema di predizione a 2 classi (classificatore binario come da figura: distribuzione rossa e azzurra), scelto un valore di soglia (\"threshold\" o \"cut-off\"), rispetto a cui decidere il risultato, ovvero se appartenente alla classe positiva (\"p\") o negativa (\"n\"), dato che le due curve di distribuzione di probabilit\u00e0 risultano in parte sovrapposte, sono possibili quattro risultati a seconda della posizione del valore di cut-off:\n\u00c8 inoltre possibile rappresentare questo tipo di situazione utilizzando una tabella di contingenza di tipo 2\u00d72, dove le colonne rappresentano la distinzione tra soggetti sani e malati; le righe invece rappresentano il risultato del test sui pazienti. Un risultato qualitativo del test potrebbe essere quello di andare a valutare il numero di falsi positivi e negativi; meno ve ne saranno e maggiormente il test sar\u00e0 valido.\nUna curva ROC \u00e8 il grafico dell'insieme delle coppie (FP, TP) al variare di un parametro del classificatore. Per esempio, in un classificatore a soglia, si calcola la frazione di veri positivi e quella di falsi positivi per ogni possibile valore della soglia; tutti i punti cos\u00ec ottenuti nello spazio FP-TP descrivono la curva ROC.\nAttraverso l'analisi delle curve ROC si valuta la capacit\u00e0 del classificatore di discernere, ad esempio, tra un insieme di popolazione \"sana\" e \"malata\", calcolando l'area sottesa alla curva ROC (\"Area Under Curve\", AUC). Il valore di AUC, compreso tra 0 e 1, equivale infatti alla probabilit\u00e0 che il risultato del classificatore applicato ad un individuo estratto a caso dal gruppo dei malati sia superiore a quello ottenuto applicandolo ad un individuo estratto a caso dal gruppo dei sani.\nLe curve ROC passano per i punti (0,0) e (1,1), avendo inoltre due condizioni che rappresentano due curve limite:"], "concept_A": "Receiver operating characteristic", "wikipedia_passage_concept_B": ["3612028", "Classificazione statistica", "La classificazione statistica \u00e8 quell'attivit\u00e0 che si serve di un algoritmo statistico al fine di individuare una rappresentazione di alcune caratteristiche di un'entit\u00e0 da classificare (oggetto o nozione), associandole una etichetta classificatoria. Tale attivit\u00e0 pu\u00f2 essere svolta mediante algoritmi di apprendimento automatico supervisionato o non supervisionato. Esempi di questi algoritmi sono:\nI programmi che effettuano l'attivit\u00e0 di classificazione sono detti classificatori. Talora si usa l'aggettivo \"statistica\" anche per classificazioni utilizzate per costruire indicazioni statistiche sulle entit\u00e0 assegnate ai diversi contenitori di una classificazione, soprattutto nel caso delle tassonomie, mentre nella definizione della classificazione non si sono utilizzati precisi metodi statistici."], "concept_B": "Classificazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1105351", "Dbscan", "Il DBSCAN (\"Density-Based Spatial Clustering of Applications with Noise\") \u00e8 un metodo di clustering proposto nel 1996 da Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander and Xiaowei Xu. \u00c8 basato sulla densit\u00e0 perch\u00e9 connette regioni di punti con densit\u00e0 sufficientemente alta. DBSCAN \u00e8 l'algoritmo pi\u00f9 comunemente usato ed \u00e8 anche il pi\u00f9 citato nella letteratura scientifica.\nDBSCAN usa una definizione di cluster basata sulla nozione di \"density-reachability\". Un punto formula_1 \u00e8 direttamente raggiungibile da un punto formula_2 se la loro distanza \u00e8 minore di un assegnato formula_3 (cio\u00e8, \u00e8 parte del suo formula_3-vicinato) e se formula_2 \u00e8 circondato da un sufficiente numero di punti, allora formula_2 e formula_1 possono essere considerati parti di un cluster. Il punto formula_1 \u00e8 \"density-reachable\" da formula_2 se c'\u00e8 una sequenza formula_10 di punti con formula_11 e formula_12 dove ogni formula_13 \u00e8 density-reachable direttamente da formula_14. Si osservi che la relazione density-reachable non \u00e8 simmetrica dato che formula_1 potrebbe situarsi su una periferia del cluster, avendo un numero insufficiente di vicini per considerarlo un elemento genuino del cluster. Di conseguenza la nozione \"density-connected\" diventa: due punti formula_2 e formula_1 sono density-connected se c'\u00e8 un punto formula_18 tale che sia formula_18 e formula_2 sia formula_18 e formula_1 sono density-reachable.\nUn cluster, che \u00e8 un sotto-insieme dei punti del database, soddisfa due propriet\u00e0:\nDBSCAN necessita di due parametri: formula_3 (eps) e del numero minimo di punti richiesti per formare un cluster (minPts). Si comincia con un punto casuale che non \u00e8 stato ancora visitato. Viene calcolato il suo formula_3-vicinato e se contiene un numero sufficiente di punti viene creato un nuovo cluster. Se ci\u00f2 non avviene il punto viene etichettato come rumore e successivamente potrebbe essere ritrovato in un formula_3-vicinato sufficientemente grande riconducibile ad un punto differente entrando a far parte di un cluster.\nSe un punto \u00e8 associato ad un cluster anche i punti del suo formula_3-vicinato sono parte del cluster. Conseguentemente tutti i punti trovati all'interno del suo formula_3-vicinato sono aggiunti al cluster, cos\u00ec come i loro formula_3-vicinati. Questo processo continua fino a quando il cluster viene completato. Il processo continua fino a quando non sono stati visitati tutti i punti.\n DBSCAN(D, eps, MinPts)\nDBSCAN visita ogni punto del database, anche pi\u00f9 volte nel caso di punti candidati a cluster differenti. Tuttavia per considerazioni pratiche la complessit\u00e0 temporale \u00e8 per lo pi\u00f9 governata dal numero di invocazioni a getVicini, in riferimento allo pseudo codice di cui sopra. DBSCAN esegue esattamente una invocazione per ogni punto e se viene utilizzata una struttura indicizzata che esegue un'interrogazione del vicinato in formula_29, si ottiene un tempo globale di esecuzione pari a formula_30. Senza l'uso di strutture indicizzate, il tempo di esecuzione \u00e8 pari a formula_31. Spesso la matrice delle distanze di dimensione formula_32 viene creata per evitare appunto il ricalcolo delle distanze riducendo il tempo di elaborazione a spese della memoria utilizzata pari a formula_31.\nDBSCAN presenta i seguenti vantaggi:\nIl rilevamento del vicinato pi\u00f9 vicino avviene nella funzione getVicini(P,epsilon). Per ogni punto P vengono determinati tutti gli altri punti che sono all'interno dell'intervallo epsilon, basandosi sulla funzione della distanza usata nell'algoritmo. L'analisi richiede che sia calcolata una matrice delle distanze per l'intero data set. La generazione della matrice delle distanze ha una complessit\u00e0 di formula_34dato che \u00e8 necessaria solo una matrice triangolare superiore. All'interno della matrice delle distanze il vicinato pi\u00f9 vicino pu\u00f2 essere calcolato selezionando la tupla che ha come valori il minimo delle funzioni su riga e colonna. La ricerca ha spinto il rilevamento del vicinato, nei database tradizionali, per migliorare la velocit\u00e0. Questi ultimi risolvono il problema utilizzando indici specificamente progettati per questo tipo di applicazioni.\nOgni processo di data mining ha il problema dei parametri. Ogni parametro influenza l'algoritmo in modo specifico. Per il DBSCAN i parametri epsilon e MinPnts sono necessari. I parametri devono essere specificati dall'utente dato che ogni data set richiede parametri differenti. Un valore iniziale per formula_3 pu\u00f2 essere determinato come un k-distance graph. Come per le regole del pollice, formula_36 pu\u00f2 essere derivato dal numero di dimensioni nel data set formula_37 come formula_38. Tuttavia valori maggiori sono usualmente migliori per data set con rumore.\nAnche se questa stima dei parametri restituisce un insieme sufficiente di parametri, la classificazione risultante pu\u00f2 rivelarsi diversa da ci\u00f2 che si aspetta, pertanto la ricerca ha realizzato un'incrementale ottimizzazione dei parametri su particolari valori.\nPer ogni oggetto vengono trovati i vicini che ricadono in un raggio dato come parametro in ingresso; se il numero di questi vicini \u00e8 superiore ad un fattore di soglia, anch'esso fornito in input all'algoritmo, allora questi punti fanno parte del medesimo cluster di quello dell'oggetto che si sta osservando e in questo caso il punto \u00e8 denominato core point.\nAl termine dell'algoritmo ci potrebbero essere alcuni punti non appartenenti a cluster catalogati come \"rumore\".\nSe c'\u00e8 una catena di oggetti da attraversare (con i consueti vincoli) per raggiungere un punto \"q\" da uno \"p\", allora \"q\" sar\u00e0 detto semplicemente rintracciabile.\nUltimo caso \u00e8 quello in cui due oggetti \"p\" e \"q\" sono detti connessi: per essere definiti in tal modo, deve esistere un terzo punto \"o\", per cui \"p\" e \"q\" sono entrambi rintracciabili."], "concept_A": "Dbscan", "wikipedia_passage_concept_B": ["896", "Correlazione (statistica)", "In statistica, una correlazione \u00e8 una relazione tra due variabili tale che a ciascun valore della prima corrisponda un valore della seconda, seguendo una certa regolarit\u00e0 .\nIl termine apparve per la prima volta in un'opera di Francis Galton, \"Hereditary Genius\" (1869). Non fu definita in modo pi\u00f9 approfondito (la moralit\u00e0 di un individuo e la sua instabilit\u00e0 morale sono non correlate).\nOtto anni dopo, nel 1877, lo stesso Galton scopr\u00ec che i coefficienti di regressione lineare tra X e Y sono gli stessi se - ad entrambe le variabili - viene applicata la deviazione standard \u03c3 e \u03c3: Galton utilizz\u00f2 in realt\u00e0 lo scarto interquartile, definendo il parametro \"coefficiente di co-relazione\" e abbreviando \"regressione\" in \"r\".\nIn base alle caratteristiche presentate, la correlazione pu\u00f2 definirsi:\nInoltre, le correlazioni possono essere:\nIl grado di correlazione tra due variabili viene espresso tramite l'indice di correlazione. Il valore che esso assume \u00e8 compreso tra \u22121 (correlazione inversa) e 1 (correlazione diretta e assoluta), con un indice pari a 0 che comporta l'assenza di correlazione; il valore nullo dell'indice non implica, tuttavia, che le variabili siano indipendenti.\nI coefficienti di correlazione sono derivati dagli indici, tenendo presenti le grandezze degli scostamenti dalla media. In particolare, l'indice di correlazione di Pearson \u00e8 calcolato come rapporto tra la covarianza delle due variabili e il prodotto delle loro deviazioni standard.:\nVa comunque notato che gli indici e i coefficienti di correlazione siano da ritenersi sempre approssimativi, a causa dell'arbitrariet\u00e0 con cui sono scelti gli elementi: ci\u00f2 \u00e8 vero, in particolare, nei casi di correlazioni multiple.\nContrariamente a quanto si potrebbe intuire, la correlazione non dipende da un rapporto di causa-effetto quanto dalla tendenza di una variabile a cambiare in funzione di un'altra. Le variabili possono essere tra loro dipendenti (per esempio la relazione tra stature dei padri e dei figli) oppure comuni (relazione tra altezza e peso di una persona). \nNel cercare una correlazione statistica tra due grandezze, per determinare un possibile rapporto di causa-effetto, essa non deve risultare una correlazione spuria."], "concept_B": "Correlazione (statistica)", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["71808", "Funzione di verosimiglianza", "In statistica, la funzione di verosimiglianza (o funzione di likelihood) \u00e8 una funzione di probabilit\u00e0 condizionata, considerata come funzione del suo \"secondo\" argomento, mantenendo fissato il primo argomento.\nIn gergo colloquiale spesso \"verosimiglianza\" \u00e8 usato come sinonimo di \"probabilit\u00e0\", ma in campo statistico vi \u00e8 una distinzione tecnica precisa. Questo esempio chiarisce la differenza tra i due concetti: una persona potrebbe chiedere \"Se lanciassi una moneta non truccata 100 volte, qual \u00e8 la probabilit\u00e0 che esca testa tutte le volte?\" oppure \"Dato che ho lanciato una moneta 100 volte ed \u00e8 uscita testa 100 volte, qual \u00e8 la verosimiglianza che la moneta sia truccata?\". Scambiare tra loro, nelle due frasi, i termini \"verosimiglianza\" e \"probabilit\u00e0\" sarebbe errato.\nUna distribuzione di probabilit\u00e0 che dipende da un parametro pu\u00f2 essere considerata in due modi differenti:\nFormalmente la funzione di verosimiglianza \u00e8 una funzione:\nSi definisce ancora funzione di verosimiglianza ogni funzione proporzionale a tale probabilit\u00e0. Dunque, la funzione di verosimiglianza per formula_2 \u00e8 la classe delle funzioni:\nper ogni costante formula_4. A causa di ci\u00f2, l'esatto valore di formula_5 non \u00e8 in generale rilevante; ci\u00f2 che \u00e8 importante sono rapporti nella forma: formula_6, invarianti rispetto alla costante di proporzionalit\u00e0.\nA livello interpretativo, l'uso di una funzione di verosimiglianza trae giustificazione dal teorema di Bayes, in base al quale, per due qualsiasi eventi formula_7 e formula_2:\ndove sia formula_10 che formula_11 sono funzioni di verosimiglianza. L'uso di funzioni di verosimiglianza ai fini dell'inferenza statistica costituisce un tratto distintivo dell'inferenza classica, o \"frequentista\"; esso rappresenta inoltre una fondamentale differenza rispetto alla scuola dell'inferenza bayesiana, in quanto lo statistico bayesiano conduce inferenza tramite la probabilit\u00e0 formula_12 nell'espressione sopra.\nAlcune idee relative alla funzione di verosimiglianza sembrano essere state introdotte da T. N. Thiele in un lavoro del 1889. Il primo contributo in cui il concetto di funzione di verosimiglianza \u00e8 esplicitamente formulato \u00e8 tuttavia dovuto a Ronald Fisher in un suo lavoro del 1922. In tale lavoro, Fisher usa inoltre l'espressione metodo della massima verosimiglianza; argomenta inoltre contro il ricorso alla condizionata nella forma formula_13 nell'espressione sopra, da lui ritenuta ingiustificabile a causa dell'elemento di soggettivit\u00e0 introdotto tramite la probabilit\u00e0 \"a priori\" (nel linguaggio che ora \u00e8 proprio della statistica bayesiana) formula_14. \nIl metodo della massima verosimiglianza ha le sue applicazioni pi\u00f9 rilevanti nella prassi come metodo di stima di modelli parametrici. Considerando un insieme di osservazioni formula_15, e una famiglia di funzioni di densit\u00e0 (o di massa, nel caso di distribuzioni discrete), parametrizzate tramite il vettore formula_16:\nla funzione di verosimiglianza associata \u00e8:\nNel caso in cui, come normalmente si ipotizza, gli formula_19 siano indipendenti e identicamente distribuiti, inoltre:\nPoich\u00e9 l'espressione sopra pu\u00f2 risultare scarsamente trattabile, specie nei problemi di massimizzazione collegati al metodo della massima verosimiglianza, spesso risulta preferibile lavorare sul logaritmo della funzione di verosimiglianza, in gergo chiamata \"log-verosimiglianza\":"], "concept_A": "Funzione di verosimiglianza", "wikipedia_passage_concept_B": ["3678589", "Distribuzione condizionata", "variabili aleatorie \"X\" e \"Y\", la distribuzione condizionata di Y dato X \u00e8 la probabilit\u00e0 di Y quando \u00e8 conosciuto il valore assunto da X. A ogni distribuzione condizionata \u00e8 associato un valore atteso condizionato e una varianza condizionata.\nNel caso di variabili aletorie discrete, la distribuzione condizionata di \"Y\" dato \"X=x\", \u00e8 data da:\n\u00c8 necessario quindi che \"P(X=x)>0\".\nNel caso di variabili aleatorie continue, la densit\u00e0 condizionata di \"Y\" dato \"X=x\" \u00e8 data da\nAnche in questo caso, si deve avere che formula_3.\nSe per due variabili aleatorie \"X\" e \"Y\" si ha che \"P\"(\"Y\" = \"y\" | \"X\" = \"x\") = \"P\"(\"Y\" = \"y\") per ogni \"x\" e \"y\" o, nel caso continuo, \"f\"(\"y\" | \"X=x\") = \"f\"(\"y\") per ogni \"x\" e \"y\", allora le due variabili sono dette indipendenti"], "concept_B": "Distribuzione condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["3678589", "Distribuzione condizionata", "variabili aleatorie \"X\" e \"Y\", la distribuzione condizionata di Y dato X \u00e8 la probabilit\u00e0 di Y quando \u00e8 conosciuto il valore assunto da X. A ogni distribuzione condizionata \u00e8 associato un valore atteso condizionato e una varianza condizionata.\nNel caso di variabili aletorie discrete, la distribuzione condizionata di \"Y\" dato \"X=x\", \u00e8 data da:\n\u00c8 necessario quindi che \"P(X=x)>0\".\nNel caso di variabili aleatorie continue, la densit\u00e0 condizionata di \"Y\" dato \"X=x\" \u00e8 data da\nAnche in questo caso, si deve avere che formula_3.\nSe per due variabili aleatorie \"X\" e \"Y\" si ha che \"P\"(\"Y\" = \"y\" | \"X\" = \"x\") = \"P\"(\"Y\" = \"y\") per ogni \"x\" e \"y\" o, nel caso continuo, \"f\"(\"y\" | \"X=x\") = \"f\"(\"y\") per ogni \"x\" e \"y\", allora le due variabili sono dette indipendenti"], "concept_A": "Distribuzione condizionata", "wikipedia_passage_concept_B": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_B": "Probabilit\u00e0 condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_A": "Test di verifica d'ipotesi", "wikipedia_passage_concept_B": ["1555", "Scarto quadratico medio", "Lo scarto quadratico medio (o deviazione standard o scarto tipo) \u00e8 un indice di dispersione statistico, vale a dire una stima della variabilit\u00e0 di una popolazione di dati o di una variabile casuale.\n\u00c8 uno dei modi per esprimere la dispersione dei dati intorno ad un indice di posizione, quale pu\u00f2 essere, ad esempio, la media aritmetica o una sua stima. Ha pertanto la stessa unit\u00e0 di misura dei valori osservati (al contrario della varianza che ha come unit\u00e0 di misura il quadrato dell'unit\u00e0 di misura dei valori di riferimento). In statistica la precisione si pu\u00f2 esprimere come lo scarto quadratico medio.\nIl termine \"\"standard deviation\"\" \u00e8 stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca formula_1 (sigma) che lo rappresenta. Il termine italiano \"deviazione standard\" ne \u00e8 la traduzione pi\u00f9 utilizzata nel linguaggio comune; il termine dell'Ente Nazionale Italiano di Unificazione \u00e8 tuttavia \"scarto tipo\", definito come la radice quadrata positiva della varianza per lo meno fin dal 1984.\nSe non indicato diversamente, lo scarto quadratico medio \u00e8 la radice quadrata della varianza, la quale viene coerentemente rappresentata con il quadrato di sigma (formula_2).\nIn statistica lo scarto quadratico medio di un carattere rilevato su una popolazione di formula_3 unit\u00e0 statistiche si definisce esplicitamente come:\ndove formula_5 \u00e8 la media aritmetica di formula_6.\nFormalmente lo scarto quadratico medio di una variabile pu\u00f2 essere calcolata a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato.\nA partire dallo scarto quadratico medio si definisce anche il coefficiente di variazione o la \"deviazione standard relativa\" come il rapporto tra lo scarto tipo formula_7 e il valore assoluto della media aritmetica della variabile in esame:\nQuesto indice relativo (che viene spesso espresso in termini percentuali) consente di effettuare confronti tra dispersioni di dati di tipo diverso, indipendentemente dalle loro quantit\u00e0 assolute.\nNell'ambito della statistica inferenziale (dove \u00e8 noto solo un campione della popolazione), soprattutto nell'ambito della teoria della stima, a volte si rimpiazza il denominatore formula_3 con formula_10 ottenendo:\nSostanzialmente, poich\u00e9 non \u00e8 nota la media dell'intera popolazione, ma solo una sua stima (la media del campione), bisogna utilizzare formula_10 per ottenere uno stimatore corretto formula_13 della varianza incognita formula_7 di formula_6 sull'intera popolazione a partire dai dati del campione. La sua radice quadrata diviene lo scarto quadratico medio \"corretto\".\nQuesta correzione al denominatore fa s\u00ec che la nuova definizione sia un po' pi\u00f9 grande della precedente, correggendo cos\u00ec la tendenza della precedente a sottostimare le incertezze soprattutto nel caso in cui si lavori con pochi dati (formula_3 piccolo).\nOsserviamo il caso limite di formula_17, cio\u00e8 quando si ha un campione di un solo elemento: la prima definizione d\u00e0 il risultato formula_18, che ovviamente non \u00e8 molto ragionevole nell'ambito della statistica inferenziale, mentre quella \"corretta\" d\u00e0 un risultato non definito del tipo formula_19, rispecchiando cos\u00ec la totale ignoranza inerente all'incertezza su una singola misura. In questo senso, si dice che la statistica non dice nulla sul singolo caso.\nOsserviamo che la differenza tra le due definizioni per campioni molto estesi \u00e8 spesso numericamente insignificante.\nIl calcolo pu\u00f2 essere semplificato come segue:\ncio\u00e8, applicando il tutto alla formula originale:\nSia formula_6 una variabile aleatoria, lo scarto quadratico medio \u00e8 definito come la radice quadrata della varianza di formula_6\nFormalmente lo scarto quadratico medio di una variabile aleatoria pu\u00f2 essere calcolato a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato, cio\u00e8\ndove formula_26 \u00e8 il valore atteso di formula_6.\nIn ambito finanziario, lo scarto quadratico medio viene usato per indicare la variabilit\u00e0 di un'attivit\u00e0 finanziaria e dei suoi payoff (rendimenti). Esso fornisce quindi, implicitamente, una misura della volatilit\u00e0 dell'attivit\u00e0, quindi del suo rischio.\nIn fisica, \u00e8 un ottimo indice dell'errore casuale della misurazione di una grandezza fisica.\nIn ambito sportivo \u00e8 utilizzato per valutare la prestazione di un giocatore di bowling in riferimento ad un certo numero di partite. Il valore trovato non incide sul punteggio ma sintetizza le capacit\u00e0 e i miglioramenti del giocatore.\nIn ingegneria, \u00e8 uno dei parametri da considerare per valutare la capacit\u00e0 di un processo produttivo.\nNelle applicazioni informatiche, \u00e8 a volte conveniente utilizzare la formula\nche consente, con sole tre variabili formula_29, di calcolare lo scarto quadratico medio, oltre che la media, di un flusso di numeri di lunghezza formula_3 senza dover ricorrere ad una memorizzazione degli stessi."], "concept_B": "Scarto quadratico medio", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["5960762", "Retropropagazione dell'errore", "La retropropagazione dell'errore (in lingua inglese \"backward propagation of errors\", solitamente abbreviato in backpropagation), \u00e8 un algoritmo per l'allenamento delle reti neurali artificiali, usato in combinazione con un metodo di ottimizzazione come per esempio la discesa stocastica del gradiente.\nLa retropropagazione richiede un'uscita desiderata per ogni valore in ingresso per poter calcolare il gradiente della funzione di perdita (funzione di costo). Viene considerato quindi un metodo di apprendimento supervisionato, sebbene venga usato anche in reti non supervisionate come gli autocodificatori o Reti Diabolo.\n\u00c8 una generalizzazione della regola delta di reti feed-forward multistrato, resa possibile usando la regola di catena che iterativamente calcola i gradienti per ogni strato.\nLa retropropagazione richiede che la funzione d'attivazione usata dai neuroni artificiali (o \"nodi\") sia differenziabile.\nUna delle principali difficolt\u00e0 nell'uso della retropropagazione dell'errore \u00e8 il problema noto come scomparsa del gradiente, dovuto all'uso di funzioni di attivazione non lineari che causano una diminuzione esponenziale del valore del gradiente all'aumentare della profondit\u00e0 della rete neurale."], "concept_A": "Retropropagazione dell'errore", "wikipedia_passage_concept_B": ["4100372", "Rete neurale artificiale", "Nel campo dell'apprendimento automatico, una rete neurale artificiale (in inglese \"artificial neural network\", abbreviato in ANN o anche come NN) \u00e8 un modello computazionale composto di \"neuroni\" artificiali, ispirato vagamente dalla semplificazione di una rete neurale biologica.\nQuesti modelli matematici sono troppo semplici per ottenere una comprensione delle reti neurali biologiche, ma sono utilizzati per tentare di risolvere problemi ingegneristici di intelligenza artificiale come quelli che si pongono in diversi ambiti tecnologici (in elettronica, informatica, simulazione, e altre discipline).\nUna rete neurale artificiale pu\u00f2 essere realizzata sia da programmi software che da hardware dedicato (DSP, \"Digital Signal Processing\"). Questa branca pu\u00f2 essere utilizzata in congiunzione alla logica fuzzy.\nL'ampia variet\u00e0 di modelli non pu\u00f2 prescindere dal costituente di base, il neurone artificiale proposto da W.S. McCulloch e Walter Pitts in un famoso lavoro del 1943: \"\"A logical calculus of the ideas immanent in nervous activity\"\", il quale schematizza un combinatore lineare a soglia, con dati binari multipli in entrata e un singolo dato binario in uscita: un numero opportuno di tali elementi, connessi in modo da formare una rete, \u00e8 in grado di calcolare semplici funzioni booleane.\nLe prime ipotesi di apprendimento furono introdotte da D. O. Hebb nel libro del 1949: \"\"The organization of behavior\"\", nel quale vengono proposti collegamenti con i modelli complessi del cervello.\nNel 1958, J. Von Neumann nella sua opera \"\"The computer and the brain\"\" esamina le soluzioni proposte dai precedenti autori sottolineando la scarsa precisione che queste strutture possedevano per potere svolgere operazioni complesse.\nNello stesso anno, Frank Rosenblatt nel libro \"Psychological review\" introduce il primo schema di rete neurale, detto \"Perceptron\" (percettrone), antesignano delle attuali reti neurali, per il riconoscimento e la classificazione di forme, allo scopo di fornire un'interpretazione dell'organizzazione generale dei sistemi biologici. Il modello probabilistico di Rosenblatt \u00e8 quindi mirato all'analisi, in forma matematica, di funzioni quali l'immagazzinamento delle informazioni, e della loro influenza sul riconoscimento dei pattern; esso costituisce un progresso decisivo rispetto al modello binario di McCulloch e Pitts, perch\u00e9 i suoi pesi sinaptici sono variabili e quindi il percettrone \u00e8 in grado di apprendere.\nL'opera di Rosenblatt stimola una quantit\u00e0 di studi e ricerche che dura per un decennio, e suscita un vivo interesse e notevoli aspettative nella comunit\u00e0 scientifica, destinate tuttavia ad essere notevolmente ridimensionate allorch\u00e9 nel 1969 Marvin Minsky e Seymour A. Papert, nell'opera \"\"An introduction to computational geometry\"\", mostrano i limiti operativi delle semplici reti a due strati basate sul percettrone, e dimostrano l'impossibilit\u00e0 di risolvere per questa via molte classi di problemi, ossia tutti quelli non caratterizzati da separabilit\u00e0 lineare delle soluzioni: questo tipo di rete neurale non \u00e8 abbastanza potente: non \u00e8 infatti neanche in grado di calcolare la funzione \"or esclusivo\" (XOR). A causa di queste limitazioni, al periodo di euforia dovuto ai primi risultati della cibernetica (come veniva chiamata negli anni sessanta) segue un periodo di diffidenza durante il quale tutte le ricerche in questo campo non ricevono pi\u00f9 alcun finanziamento dal governo degli Stati Uniti d'America; le ricerche sulle reti tendono, di fatto, a ristagnare per oltre un decennio, e l'entusiasmo iniziale risulta fortemente ridimensionato.\nIl contesto matematico per addestrare le reti MLP (\"Multi-Layers Perceptron\", ossia percettrone multistrato) fu stabilito dal matematico americano Paul Werbos nella sua tesi di dottorato (Ph.D.) del 1974. Non fu dato molto peso al suo lavoro tanto fu forte la confutazione dimostrata da Minsky e Papert anni prima, e solo l'intervento di J. J. Hopfield, nel 1982, che in un suo lavoro studia dei modelli di riconoscimento di pattern molto generali, si oppose in modo diretto alla confutazione di Minsky riaprendo cos\u00ec degli spiragli per la ricerca in questo campo.\nUno dei metodi pi\u00f9 noti ed efficaci per l'addestramento di tale classe di reti neurali \u00e8 il cosiddetto algoritmo di retropropagazione dell'errore (error backpropagation), proposto nel 1986 da David E. Rumelhart, G. Hinton e R. J. Williams, il quale modifica sistematicamente i pesi delle connessioni tra i nodi, cos\u00ec che la risposta della rete si avvicini sempre di pi\u00f9 a quella desiderata. Tale lavoro fu prodotto riprendendo il modello creato da Werbos. L'algoritmo di retropropagazione (\"backpropagation\" o BP) \u00e8 una tecnica d'apprendimento tramite esempi, costituente una generalizzazione dell'algoritmo d'apprendimento per il percettrone sviluppato da Rosenblatt nei primi anni '60. Mediante questa tecnica era possibile, come detto, trattare unicamente applicazioni caratterizzabili come funzioni booleane linearmente separabili.\nL'algoritmo di apprendimento si basa sul metodo della discesa del gradiente che permette di trovare un minimo locale di una funzione in uno spazio a N dimensioni. I pesi associati ai collegamenti tra gli strati di neuroni si inizializzano a valori piccoli (ovvero molto inferiori ai valori reali che poi assumeranno) e casuali e poi si applica la regola di apprendimento presentando alla rete dei pattern di esempio. Queste reti neurali sono poi capaci di generalizzare in modo appropriato, cio\u00e8 di dare risposte plausibili per input che non hanno mai visto.\nL'addestramento di une rete neurale di tipo BP avviene in due diversi stadi: \"forward-pass\" e \"backward-pass\". Nella prima fase i vettori in input sono applicati ai nodi in ingresso con una propagazione in avanti dei segnali attraverso ciascun livello della rete (\"forward-pass\"). Durante questa fase i valori dei pesi sinaptici sono tutti fissati. Nella seconda fase la risposta della rete viene confrontata con l'uscita desiderata ottenendo il segnale d'errore. L'errore calcolato \u00e8 propagato nella direzione inversa rispetto a quella delle connessioni sinaptiche. I pesi sinaptici infine sono modificati in modo da minimizzare la differenza tra l'uscita attuale e l'uscita desiderata (\"backward-pass\").\nTale algoritmo consente di superare le limitazioni del percettrone e di risolvere il problema della separabilit\u00e0 non lineare (e quindi di calcolare la funzione XOR), segnando il definitivo rilancio delle reti neurali, come testimoniato anche dall'ampia variet\u00e0 d'applicazioni commerciali: attualmente la BP rappresenta un algoritmo di largo uso in molti campi applicativi.\nUna rete neurale artificiale (ANN \"\"Artificial Neural Network\"\" in inglese), normalmente chiamata solo \"rete neurale\" (NN \"\"Neural Network\"\" in inglese), \u00e8 un modello matematico/informatico di calcolo basato sulle reti neurali biologiche. Tale modello \u00e8 costituito da un gruppo di interconnessioni di informazioni costituite da neuroni artificiali e processi che utilizzano un approccio di connessionismo di calcolo. Nella maggior parte dei casi una rete neurale artificiale \u00e8 un sistema adattivo che cambia la propria struttura in base a informazioni esterne o interne che scorrono attraverso la rete stessa durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare.\nUna rete neurale artificiale riceve segnali esterni su uno strato di nodi (unit\u00e0 di elaborazione) d'ingresso, ciascuno dei quali \u00e8 collegato con numerosi nodi interni, organizzati in pi\u00f9 livelli. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\nIl concetto di rete neurale si pone perch\u00e9 una funzione formula_1 \u00e8 definita come una composizione di altre funzioni formula_2, che possono a loro volta essere ulteriormente definite come composizione di altre funzioni. Questo pu\u00f2 essere comodamente rappresentato come una struttura di reti, con le frecce raffiguranti le dipendenze tra variabili. Una rappresentazione ampiamente utilizzata \u00e8 la somma ponderata non lineare, dove formula_3, dove formula_4 \u00e8 una funzione predefinita, come ad esempio la tangente iperbolica. Sar\u00e0 conveniente per le seguenti far riferimento ad un insieme di funzioni come un vettore formula_5.\nLa Figura 1 esemplifica una decomposizione della funzione formula_6, con dipendenze tra le variabili indicate dalle frecce. Queste possono essere interpretate in due modi:\nI due punti di vista sono in gran parte equivalenti. In entrambi i casi, per questa particolare architettura di rete, i componenti dei singoli strati sono indipendenti l'uno dall'altro (ad esempio, le componenti di formula_8 sono indipendenti l'una dall'altra, dato il loro ingresso formula_15). Questo, naturalmente, permette un certo grado di parallelismo nella costruzione del sistema.\nReti, come ad esempio quelle precedenti vengono comunemente chiamate \"\"feedforward\"\", perch\u00e9 il loro \u00e8 un grafico aciclico diretto. Reti con cicli al loro interno sono comunemente chiamati reti ricorrenti. Tali reti sono comunemente raffigurate nel modo indicato nella parte superiore della Figura 2, dove la funzione formula_6 \u00e8 mostrata come dipendente su se stessa. Tuttavia, vi \u00e8 una dipendenza temporale implicita che non \u00e8 possibile dimostrare. Questo significa in pratica che il valore di formula_6 ad un certo punto nel tempo formula_18 dipende dai valori di formula_6 al tempo zero o su uno o pi\u00f9 altri punti temporali. Il modello del grafico nella parte inferiore della Figura 2 illustra il caso in cui il valore di formula_6 al tempo formula_18 dipende solo dal suo valore finale.\nTuttavia la funzionalit\u00e0 pi\u00f9 interessante di queste funzioni, ci\u00f2 che ha attirato l'interesse e lo studio per la maggior parte delle reti neurali, \u00e8 la possibilit\u00e0 di apprendimento, che in pratica significa la seguente:\nCi\u00f2 comporta la definizione di una funzione di costo formula_24 tale che, per la soluzione ottimale formula_25 formula_26 nessuna soluzione ha un costo inferiore al costo della soluzione ottimale.\nLa funzione di costo formula_27 \u00e8 un concetto importante nell'apprendimento, poich\u00e9 si tratta di una misura di quanto \u00e8 lontana da noi la soluzione ottimale del problema che vogliamo risolvere. Quindi vi sono una serie di algoritmi di apprendimento che cercano nello spazio delle soluzioni al fine di trovare una funzione che abbia il minor costo possibile.\nPer applicazioni in cui la soluzione dipende da alcuni dati, il costo deve essere necessariamente funzione delle osservazioni.\nMentre \u00e8 possibile definire per alcune reti una funzione di costo ad hoc, spesso si pu\u00f2 utilizzare una particolare funzione di costo poich\u00e9 gode delle propriet\u00e0 desiderate (ad esempio, la convessit\u00e0), o perch\u00e9 proviene da una particolare formulazione del problema (vale a dire, in una formulazione probabilistica, la probabilit\u00e0 a posteriori del modello pu\u00f2 essere utilizzata come l'inverso del costo). In ultima analisi, la funzione di costo dipender\u00e0 dal compito.\nVi sono tre grandi paradigmi di apprendimento, ciascuno corrispondente ad un particolare compito astratto di apprendimento. Si tratta dell'apprendimento supervisionato, apprendimento non supervisionato e l'apprendimento per rinforzo. Di solito un tipo di architettura di rete pu\u00f2 essere impiegato in qualsiasi di tali compiti.\nL'algoritmo di apprendimento hebbiano (1984) si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata.\nformula_28 dove formula_29,\ndove formula_30 \u00e8 l'formula_31 ingresso e formula_32 \u00e8 il tasso di apprendimento formula_33.\nLa regola di Hebb \u00e8 la seguente: l'efficacia di una particolare sinapsi cambia se e solo se c'\u00e8 un'intensa attivit\u00e0 simultanea dei due neuroni, con un'alta trasmissione di input nella sinapsi in questione.\nEsempio di procedura:\nIn questo modo le connessioni possono solo irrobustirsi.\nLe connessioni si considerano irrobustite quando le unit\u00e0 presinaptica e postsinaptica sono d'accordo, altrimenti si indeboliscono.\nSi considerano funzioni bipolari (-1,1) invece che booleane (0,1).\nLe reti neurali si basano principalmente sulla simulazione di neuroni artificiali opportunamente collegati. Il modello rappresentato in figura \u00e8 quello proposto da McCulloch e Pitts.\nI suddetti neuroni ricevono in ingresso degli stimoli e li elaborano. L'elaborazione pu\u00f2 essere anche molto sofisticata ma in un caso semplice si pu\u00f2 pensare che i singoli ingressi vengano moltiplicati per un opportuno valore detto peso, il risultato delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone si attiva attivando la sua uscita. Il peso indica l'efficacia sinaptica della linea di ingresso e serve a quantificarne l'importanza, un ingresso molto importante avr\u00e0 un peso elevato, mentre un ingresso poco utile all'elaborazione avr\u00e0 un peso inferiore. Si pu\u00f2 pensare che se due neuroni comunicano fra loro utilizzando maggiormente alcune connessioni allora tali connessioni avranno un peso maggiore, fino a che non si creeranno delle connessioni tra l'ingresso e l'uscita della rete che sfruttano \"percorsi preferenziali\". Tuttavia \u00e8 sbagliato pensare che la rete finisca col produrre un unico percorso di connessione: tutte le combinazioni infatti avranno un certo peso, e quindi contribuiscono al collegamento ingresso/uscita.\nIl modello in figura rappresenta una classica rete neurale pienamente connessa.\nI singoli neuroni vengono collegati alla schiera di neuroni successivi, in modo da formare una rete di neuroni. Normalmente una rete \u00e8 formata da tre strati. Nel primo abbiamo gli ingressi (I), questo strato si preoccupa di trattare gli ingressi in modo da adeguarli alle richieste dei neuroni. Se i segnali in ingresso sono gi\u00e0 trattati pu\u00f2 anche non esserci. Il secondo strato \u00e8 quello nascosto (H, \"hidden\"), si preoccupa dell'elaborazione vera e propria e pu\u00f2 essere composto anche da pi\u00f9 colonne di neuroni. Il terzo strato \u00e8 quello di uscita (O) e si preoccupa di raccogliere i risultati ed adattarli alle richieste del blocco successivo della rete neurale. Queste reti possono essere anche molto complesse e coinvolgere migliaia di neuroni e decine di migliaia di connessioni.\nPer costruire la struttura di una rete neurale multistrato si possono inserire formula_38 strati \"hidden.\" L'efficacia di generalizzare di una rete neurale multistrato dipende ovviamente dall'addestramento che ha ricevuto e dal fatto di essere riuscita o meno ad entrare in un minimo locale buono.\nL'algoritmo di retropropagazione dell'errore (\"backpropagation\") \u00e8 utilizzato nell'apprendimento con supervisione. Esso permette di modificare i pesi delle connessioni in modo tale che si minimizzi una certa funzione errore E. Tale funzione dipende dal vettore h-esimo di output formula_39 restituito dalla rete, dato il vettore h-esimo di ingresso formula_40 e dal vettore h-esimo di output formula_41che noi desideriamo (che fa parte del training set). Il training set \u00e8 dunque un insieme di N coppie di vettori formula_42, con formula_43. La funzione errore che si deve minimizzare si pu\u00f2 scrivere come:\nformula_44\ndove l'indice k rappresenta il valore corrispondente al k-esimo neurone di output. E(w) \u00e8 una funzione dipendente dai pesi (che in generale variano nel tempo), per minimizzarla si pu\u00f2 usare l'algoritmo della discesa del gradiente (\"gradient descent\"). L'algoritmo parte da un punto generico formula_45 e calcola il gradiente formula_46. Il gradiente d\u00e0 la direzione verso cui muoversi lungo la quale si ha il massimo incremento (o decremento se considero formula_47). Definita la direzione ci si muove di una distanza formula_32 predefinita a priori e si trova un nuovo punto formula_49 sul quale \u00e8 calcolato nuovamente il gradiente. Si continua iterativamente finch\u00e9 il gradiente non \u00e8 nullo.\nL'algoritmo di backpropagation pu\u00f2 essere diviso in due passi:\nI passi logici per addestrare una rete neurale con apprendimento supervisionato sono i seguenti:\nPer l'addestramento di reti neurali profonde, impiegando dataset molto vasti, la discesa del gradiente classica risulta computazionalmente proibitiva, per cui nell'ottimizzare i parametri del modello si fa tipicamente uso dell'algoritmo di discesa stocastica del gradiente.\nNel 1982, il fisico John J. Hopfield pubblica un articolo fondamentale in cui presenta un modello matematico comunemente noto appunto come rete di Hopfield: tale rete si distingue per \"l'emergere spontaneo di nuove capacit\u00e0 computazionali dal comportamento collettivo di un gran numero di semplici elementi d'elaborazione\". Le propriet\u00e0 collettive del modello producono una memoria associativa per il riconoscimento di configurazioni corrotte e il recupero di informazioni mancanti.\nInoltre, Hopfield ritiene che ogni sistema fisico possa essere considerato come un potenziale dispositivo di memoria, qualora esso disponga di un certo numero di stati stabili, i quali fungano da attrattore per il sistema stesso. Sulla base di tale considerazione, egli si spinge a formulare la tesi secondo cui la stabilit\u00e0 e la collocazione di tali attrattori sono propriet\u00e0 spontanee di sistemi costituiti, come accennato, da considerevoli quantit\u00e0 di neuroni reciprocamente interagenti.\nLe applicazioni delle reti di Hopfield riguardano principalmente la realizzazione di memorie associative, resistenti all'alterazione delle condizioni operative, e la soluzione di problemi d'ottimizzazione combinatoriale.\nDa un punto di vista strutturale, la rete di Hopfield costituisce una rete neurale ricorrente simmetrica, di cui \u00e8 garantita la convergenza.\nUna rete ricorrente \u00e8 un modello neurale in cui \u00e8 presente un flusso bidirezionale d'informazioni; in altri termini, mentre nelle reti di tipo feedforward la propagazione dei segnali avviene unicamente, in maniera continua, nella direzione che conduce dagli ingressi alle uscite, nelle reti ricorrenti tale propagazione pu\u00f2 anche manifestarsi da uno strato neurale successivo ad uno precedente, oppure tra neuroni appartenenti ad uno stesso strato, e persino tra un neurone e s\u00e9 stesso.\nUn significativo e noto esempio di semplice rete ricorrente \u00e8 dovuto a Jeffrey L. Elman (1990). Essa costituisce una variazione sul tema del percettrone multistrato, con esattamente tre strati e l'aggiunta di un insieme di neuroni \"contestuali\" nello strato d'ingresso. Le connessioni retroattive si propagano dallo strato intermedio (e nascosto) a tali unit\u00e0 contestuali, alle quali si assegna peso costante e pari all'unit\u00e0.\nIn ciascun istante, gli ingressi si propagano nel modo tradizionale e tipico delle reti feedforward, compresa l'applicazione dell'algoritmo d'apprendimento (solitamente la \"backpropagation\"). Le connessioni retroattive fisse hanno come effetto quello di mantenere una copia dei precedenti valori dei neuroni intermedi, dal momento che tale flusso avviene sempre prima della fase d'apprendimento.\nIn questo modo la rete di Elman tiene conto del suo stato precedente, cosa che le consente di svolgere compiti di previsione di sequenze temporali che sono difficilmente alla portata dei percettroni multistrato convenzionali.\nInfine, un ultimo interessante tipo di rete \u00e8 costituita dalla cosiddetta mappa auto-organizzante o rete SOM (\"Self-Organizing Map\"). Tale innovativo tipo di rete neurale \u00e8 stata elaborata da Teuvo Kohonen dell'Universit\u00e0 Tecnologica di Helsinki; il suo algoritmo d'apprendimento \u00e8 senza dubbio una brillante formulazione di apprendimento non supervisionato, e ha dato luogo a un gran numero di applicazioni nell'ambito dei problemi di classificazione. Una mappa o rete SOM \u00e8 basata essenzialmente su un reticolo o griglia di neuroni artificiali i cui pesi sono continuamente adattati ai vettori presentati in ingresso nel relativo insieme di addestramento. Tali vettori possono essere di dimensione generica, anche se nella maggior parte delle applicazioni essa \u00e8 piuttosto alta. Per ci\u00f2 che riguarda le uscite della rete, al contrario, ci si limita di solito ad una dimensione massima pari a tre, il che consente di dare luogo a mappe 2D o 3D.\nIn termini pi\u00f9 analitici, l'algoritmo pu\u00f2 essere agevolmente descritto, come accennato, nei termini di un insieme di neuroni artificiali, ciascuno con una precisa collocazione sulla mappa rappresentativa degli \"output\", che prendono parte ad un processo noto come \"winner takes all\" (\"Il vincitore piglia tutto\"), al termine del quale il nodo avente un vettore di pesi pi\u00f9 vicino ad un certo \"input\" \u00e8 dichiarato vincitore, mentre i pesi stessi sono aggiornati in modo da avvicinarli al vettore in ingresso. Ciascun nodo ha un certo numero di nodi adiacenti. Quando un nodo vince una competizione, anche i pesi dei nodi adiacenti sono modificati, secondo la regola generale che pi\u00f9 un nodo \u00e8 lontano dal nodo vincitore, meno marcata deve essere la variazione dei suoi pesi. Il processo \u00e8 quindi ripetuto per ogni vettore dell'insieme di \"training\", per un certo numero, solitamente grande, di cicli. Va da s\u00e9 che ingressi diversi producono vincitori diversi.\nOperando in tal modo, la mappa riesce alfine ad associare i nodi d'uscita con i gruppi o schemi ricorrenti nell'insieme dei dati in ingresso. Se questi schemi sono riconoscibili, essi possono essere associati ai corrispondenti nodi della rete addestrata. In maniera analoga a quella della maggioranza delle reti neurali artificiali, anche la mappa o rete SOM pu\u00f2 operare in due distinte modalit\u00e0:\nIn generale una ANN (\"Attractor Neural Network\") \u00e8 una rete di nodi (es: biologicamente ispirati), spesso interconnessi in modo ricorsivo, la cui dinamica nel tempo stabilisce un assestamento in un particolare modo di oscillazione. Questo modo di oscillazione pu\u00f2 essere stazionario, variante nel tempo o di tipo stocastico ed \u00e8 chiamato il suo 'attrattore'. In neuroscienza teorica diversi tipi di reti ad attrattori sono state associate a differenti funzioni, come: memoria, attenzione, condotta del moto e classificazione.\nPi\u00f9 precisamente, una rete ad attrattori \u00e8 una rete di N nodi connessi in modo che la loro intera dinamica diventi stabile in uno spazio D dimensionale, dove solitamente N\u00bbD. Ci\u00f2 assume che non vi sia pi\u00f9 input dall'esterno del sistema. La stabilit\u00e0 nello stato ad attrattore indica l'esistenza di uno stato stabile in una qualche variet\u00e0 algebrica (es: linea, cerchio, piano, toroide).\nL'utilit\u00e0 dei modelli di rete neurale sta nel fatto che queste possono essere usate per comprendere una funzione utilizzando solo le osservazioni sui dati. Ci\u00f2 \u00e8 particolarmente utile nelle applicazioni in cui la complessit\u00e0 dei dati o la difficolt\u00e0 di elaborazione rende la progettazione di una tale funzione impraticabile con i normali procedimenti di analisi manuale.\nI compiti a cui le reti neurali sono applicate possono essere classificate nelle seguenti grandi categorie di applicazioni:\nLe aree di applicazione includono i sistemi di controllo (controllo di veicoli, controllo di processi), simulatori di giochi e processi decisionali (backgammon, scacchi), riconoscimento di pattern (sistemi radar, identificazione di volti, riconoscimento di oggetti, ecc), riconoscimenti di sequenze (riconoscimento di gesti, riconoscimento vocale, OCR), diagnosi medica, applicazioni finanziarie, data mining, filtri spam per e-mail.\nLe reti neurali per come sono costruite lavorano in parallelo e sono quindi in grado di trattare molti dati. Si tratta in sostanza di un sofisticato sistema di tipo statistico dotato di una buona immunit\u00e0 al rumore; se alcune unit\u00e0 del sistema dovessero funzionare male, la rete nel suo complesso avrebbe delle riduzioni di prestazioni ma difficilmente andrebbe incontro ad un blocco del sistema. I software di ultima generazione dedicati alle reti neurali richiedono comunque buone conoscenze statistiche; il grado di apparente utilizzabilit\u00e0 immediata non deve trarre in inganno, pur permettendo all'utente di effettuare subito previsioni o classificazioni, seppure con i limiti del caso.\nDa un punto di vista industriale, risultano efficaci quando si dispone di dati storici che possono essere trattati con gli algoritmi neurali. Ci\u00f2 \u00e8 di interesse per la produzione perch\u00e9 permette di estrarre dati e modelli senza effettuare ulteriori prove e sperimentazioni.\nI modelli prodotti dalle reti neurali, anche se molto efficienti, non sono spiegabili in linguaggio simbolico umano: i risultati vanno accettati \"cos\u00ec come sono\", da cui anche la definizione inglese delle reti neurali come \"black box\": in altre parole, a differenza di un sistema algoritmico, dove si pu\u00f2 esaminare passo-passo il percorso che dall'input genera l'output, una rete neurale \u00e8 in grado di generare un risultato valido, o comunque con una alta probabilit\u00e0 di essere accettabile, ma non \u00e8 possibile spiegare come e perch\u00e9 tale risultato sia stato generato.\nCome per qualsiasi algoritmo di modellazione, anche le reti neurali sono efficienti solo se le variabili predittive sono scelte con cura.\nNon sono in grado di trattare in modo efficiente variabili di tipo categorico (per esempio, il nome della citt\u00e0) con molti valori diversi. Necessitano di una fase di addestramento del sistema che fissi i pesi dei singoli neuroni e questa fase pu\u00f2 richiedere molto tempo, se il numero dei record e delle variabili analizzate \u00e8 molto grande. Non esistono teoremi o modelli che permettano di definire la rete ottima, quindi la riuscita di una rete dipende molto dall'esperienza del creatore.\nLe reti neurali vengono solitamente usate in contesti dove i dati possono essere parzialmente errati oppure dove non esistano modelli analitici in grado di affrontare il problema. Un loro tipico utilizzo \u00e8 nei software di OCR, nei sistemi di riconoscimento facciale e pi\u00f9 in generale nei sistemi che si occupano di trattare dati soggetti a errori o rumore. Esse sono anche uno degli strumenti maggiormente utilizzati nelle analisi di Data mining.\nLe reti neurali vengono anche utilizzate come mezzo per previsioni nell'analisi finanziaria o meteorologica. Negli ultimi anni \u00e8 aumentata notevolmente la loro importanza anche nel campo della bioinformatica nel quale vengono utilizzate per la ricerca di pattern funzionali e/o strutturali in proteine e acidi nucleici. Mostrando opportunamente una lunga serie di input (fase di training o apprendimento), la rete \u00e8 in grado di fornire l'output pi\u00f9 probabile. Negli ultimi anni inoltre sono in corso studi per il loro utilizzo nella previsione degli attacchi Epilettici (Analisi dei Dati provenienti dall' EEG).\nRecenti studi hanno dimostrato buone potenzialit\u00e0 delle reti neurali in sismologia per la localizzazione di epicentri di terremoti e predizione della loro intensit\u00e0."], "concept_B": "Rete neurale artificiale", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["896", "Correlazione (statistica)", "In statistica, una correlazione \u00e8 una relazione tra due variabili tale che a ciascun valore della prima corrisponda un valore della seconda, seguendo una certa regolarit\u00e0 .\nIl termine apparve per la prima volta in un'opera di Francis Galton, \"Hereditary Genius\" (1869). Non fu definita in modo pi\u00f9 approfondito (la moralit\u00e0 di un individuo e la sua instabilit\u00e0 morale sono non correlate).\nOtto anni dopo, nel 1877, lo stesso Galton scopr\u00ec che i coefficienti di regressione lineare tra X e Y sono gli stessi se - ad entrambe le variabili - viene applicata la deviazione standard \u03c3 e \u03c3: Galton utilizz\u00f2 in realt\u00e0 lo scarto interquartile, definendo il parametro \"coefficiente di co-relazione\" e abbreviando \"regressione\" in \"r\".\nIn base alle caratteristiche presentate, la correlazione pu\u00f2 definirsi:\nInoltre, le correlazioni possono essere:\nIl grado di correlazione tra due variabili viene espresso tramite l'indice di correlazione. Il valore che esso assume \u00e8 compreso tra \u22121 (correlazione inversa) e 1 (correlazione diretta e assoluta), con un indice pari a 0 che comporta l'assenza di correlazione; il valore nullo dell'indice non implica, tuttavia, che le variabili siano indipendenti.\nI coefficienti di correlazione sono derivati dagli indici, tenendo presenti le grandezze degli scostamenti dalla media. In particolare, l'indice di correlazione di Pearson \u00e8 calcolato come rapporto tra la covarianza delle due variabili e il prodotto delle loro deviazioni standard.:\nVa comunque notato che gli indici e i coefficienti di correlazione siano da ritenersi sempre approssimativi, a causa dell'arbitrariet\u00e0 con cui sono scelti gli elementi: ci\u00f2 \u00e8 vero, in particolare, nei casi di correlazioni multiple.\nContrariamente a quanto si potrebbe intuire, la correlazione non dipende da un rapporto di causa-effetto quanto dalla tendenza di una variabile a cambiare in funzione di un'altra. Le variabili possono essere tra loro dipendenti (per esempio la relazione tra stature dei padri e dei figli) oppure comuni (relazione tra altezza e peso di una persona). \nNel cercare una correlazione statistica tra due grandezze, per determinare un possibile rapporto di causa-effetto, essa non deve risultare una correlazione spuria."], "concept_A": "Correlazione (statistica)", "wikipedia_passage_concept_B": ["1555", "Scarto quadratico medio", "Lo scarto quadratico medio (o deviazione standard o scarto tipo) \u00e8 un indice di dispersione statistico, vale a dire una stima della variabilit\u00e0 di una popolazione di dati o di una variabile casuale.\n\u00c8 uno dei modi per esprimere la dispersione dei dati intorno ad un indice di posizione, quale pu\u00f2 essere, ad esempio, la media aritmetica o una sua stima. Ha pertanto la stessa unit\u00e0 di misura dei valori osservati (al contrario della varianza che ha come unit\u00e0 di misura il quadrato dell'unit\u00e0 di misura dei valori di riferimento). In statistica la precisione si pu\u00f2 esprimere come lo scarto quadratico medio.\nIl termine \"\"standard deviation\"\" \u00e8 stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca formula_1 (sigma) che lo rappresenta. Il termine italiano \"deviazione standard\" ne \u00e8 la traduzione pi\u00f9 utilizzata nel linguaggio comune; il termine dell'Ente Nazionale Italiano di Unificazione \u00e8 tuttavia \"scarto tipo\", definito come la radice quadrata positiva della varianza per lo meno fin dal 1984.\nSe non indicato diversamente, lo scarto quadratico medio \u00e8 la radice quadrata della varianza, la quale viene coerentemente rappresentata con il quadrato di sigma (formula_2).\nIn statistica lo scarto quadratico medio di un carattere rilevato su una popolazione di formula_3 unit\u00e0 statistiche si definisce esplicitamente come:\ndove formula_5 \u00e8 la media aritmetica di formula_6.\nFormalmente lo scarto quadratico medio di una variabile pu\u00f2 essere calcolata a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato.\nA partire dallo scarto quadratico medio si definisce anche il coefficiente di variazione o la \"deviazione standard relativa\" come il rapporto tra lo scarto tipo formula_7 e il valore assoluto della media aritmetica della variabile in esame:\nQuesto indice relativo (che viene spesso espresso in termini percentuali) consente di effettuare confronti tra dispersioni di dati di tipo diverso, indipendentemente dalle loro quantit\u00e0 assolute.\nNell'ambito della statistica inferenziale (dove \u00e8 noto solo un campione della popolazione), soprattutto nell'ambito della teoria della stima, a volte si rimpiazza il denominatore formula_3 con formula_10 ottenendo:\nSostanzialmente, poich\u00e9 non \u00e8 nota la media dell'intera popolazione, ma solo una sua stima (la media del campione), bisogna utilizzare formula_10 per ottenere uno stimatore corretto formula_13 della varianza incognita formula_7 di formula_6 sull'intera popolazione a partire dai dati del campione. La sua radice quadrata diviene lo scarto quadratico medio \"corretto\".\nQuesta correzione al denominatore fa s\u00ec che la nuova definizione sia un po' pi\u00f9 grande della precedente, correggendo cos\u00ec la tendenza della precedente a sottostimare le incertezze soprattutto nel caso in cui si lavori con pochi dati (formula_3 piccolo).\nOsserviamo il caso limite di formula_17, cio\u00e8 quando si ha un campione di un solo elemento: la prima definizione d\u00e0 il risultato formula_18, che ovviamente non \u00e8 molto ragionevole nell'ambito della statistica inferenziale, mentre quella \"corretta\" d\u00e0 un risultato non definito del tipo formula_19, rispecchiando cos\u00ec la totale ignoranza inerente all'incertezza su una singola misura. In questo senso, si dice che la statistica non dice nulla sul singolo caso.\nOsserviamo che la differenza tra le due definizioni per campioni molto estesi \u00e8 spesso numericamente insignificante.\nIl calcolo pu\u00f2 essere semplificato come segue:\ncio\u00e8, applicando il tutto alla formula originale:\nSia formula_6 una variabile aleatoria, lo scarto quadratico medio \u00e8 definito come la radice quadrata della varianza di formula_6\nFormalmente lo scarto quadratico medio di una variabile aleatoria pu\u00f2 essere calcolato a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato, cio\u00e8\ndove formula_26 \u00e8 il valore atteso di formula_6.\nIn ambito finanziario, lo scarto quadratico medio viene usato per indicare la variabilit\u00e0 di un'attivit\u00e0 finanziaria e dei suoi payoff (rendimenti). Esso fornisce quindi, implicitamente, una misura della volatilit\u00e0 dell'attivit\u00e0, quindi del suo rischio.\nIn fisica, \u00e8 un ottimo indice dell'errore casuale della misurazione di una grandezza fisica.\nIn ambito sportivo \u00e8 utilizzato per valutare la prestazione di un giocatore di bowling in riferimento ad un certo numero di partite. Il valore trovato non incide sul punteggio ma sintetizza le capacit\u00e0 e i miglioramenti del giocatore.\nIn ingegneria, \u00e8 uno dei parametri da considerare per valutare la capacit\u00e0 di un processo produttivo.\nNelle applicazioni informatiche, \u00e8 a volte conveniente utilizzare la formula\nche consente, con sole tre variabili formula_29, di calcolare lo scarto quadratico medio, oltre che la media, di un flusso di numeri di lunghezza formula_3 senza dover ricorrere ad una memorizzazione degli stessi."], "concept_B": "Scarto quadratico medio", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_A": "Rete bayesiana", "wikipedia_passage_concept_B": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_B": "Probabilit\u00e0 condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1845509", "Significativit\u00e0", "In statistica la significativit\u00e0 \u00e8 la possibilit\u00e0 rilevante che compaia un determinato valore. Ci si riferisce anche come \"statisticamente differente da zero\"; ci\u00f2 non significa che la \"significativit\u00e0\" sia rilevante, o vasta, come indurrebbe a pensare la parola. Ma solo che \u00e8 diversa dal numero limite.\nIl livello di significativit\u00e0 di un test \u00e8 dato solitamente da una verifica del test d'ipotesi. Nel caso pi\u00f9 semplice \u00e8 definita come la probabilit\u00e0 di accettare o rigettare l'ipotesi nulla.\nI livelli di significativit\u00e0 sono solitamente rappresentati con la lettera greca \u03b1 (alfa). I livelli pi\u00f9 usati sono 5% (\u03b1=0,05) e 1% (\u03b1=0,01); nel caso di ipotesi a carattere prevalentemente esplorativo \u00e8 consuetudine adoperare un livello di significativit\u00e0 al 10% (\u03b1=0,1). Se il test di verifica d'ipotesi d\u00e0 un valore p minore del livello \u03b1, l'ipotesi nulla \u00e8 rifiutata.\nTali risultati sono informalmente riportati come 'statisticamente significativi'. Per esempio se si sostiene che \"c'\u00e8 solo una possibilit\u00e0 su mille che ci\u00f2 possa accadere per coincidenza,\" viene usato un livello di significativit\u00e0 dello 0,1%. Pi\u00f9 basso \u00e8 il livello di significativit\u00e0, maggiore \u00e8 l'evidenza. In alcune situazioni conviene esprimere la significativit\u00e0 statistica con 1\u00a0\u2212\u00a0\u03b1. In generale, quando si interpreta una significativit\u00e0 stabilita, bisogna stare attenti nell'indicare che cosa, precisamente \u00e8 stato testato statisticamente.\nDifferenti livelli di \u03b1 hanno differenti vantaggi e svantaggi. \u03b1-livelli pi\u00f9 bassi danno maggiore confidenza nella determinazione della significativit\u00e0, ma corrono maggiori rischi di errore nel respingere una falsa ipotesi nulla (un errore di tipo II, o \"falsa determinazione negativa\"), e cos\u00ec hanno maggiore potenza statistica. La selezione di un \u03b1-livello inevitabilmente implica un compromesso fra significativit\u00e0 e potenza, e di conseguenza, fra errore tipo I ed errore tipo II.\nIn alcuni campi, per esempio nella fisica nucleare ed in quella delle particelle, si usa esprimere la significativit\u00e0 statistica in unit\u00e0 di \"\u03c3\" (sigma), la deviazione standard di una distribuzione gaussiana. Una significativit\u00e0 statistica di \"formula_1\" pu\u00f2 essere convertita in un valore di \u03b1 usando la funzione errore:\nL'uso di \u03c3 \u00e8 motivato dalla onnipresenza della distribuzione gaussiana nella \nmisura delle incertezze. Per esempio se una teoria prevede che un parametro abbia un valore, ad esempio 100, e ad una misurazione indica che il parametro \u00e8 100 \u00b1 3, allora bisogna riportare la misura come una \"deviazione 3\u03c3\" dalla previsione teorica. in termini di \u03b1, questa situazione \u00e8 equivalente al dire che \"supponendo vera la teoria, la possibilit\u00e0 di ottenere che il risultato sperimentale coincida \u00e8 dello 0,27%\" (poich\u00e9 1 \u00a0\u2212\u00a0erf(3/\u221a2) = 0.0027).\nFissati i livelli di significativit\u00e0 come quelli menzionati in seguito possono essere considerati come utili nelle analisi di dati esploratorie. Comunque, la moderna statistica \u00e8 dell'avviso che, dove il risultato di un test \u00e8 essenzialmente il risultato finale di un esperimento o di altro studio, il p-valore deve essere considerato esplicitamente. Inoltre, ed \u00e8 importante, bisogna considerare se e come il p-valore \u00e8 significativo o meno. Questo consente di accedere al massimo delle informazioni che devono essere trasferiti da un riassunto degli studi nelle meta-analisi.\nUn errore comune \u00e8 ritenere che un risultato statisticamente significativo sia sempre di significativit\u00e0 pratica, o dimostri un largo effetto nella popolazione. Sfortunatamente, questo problema si incontra diffusamente negli scritti scientifici. Dato un campione sufficientemente grande, per esempio, si pu\u00f2 scoprire che differenze estremamente piccole e non visibili sono statisticamente significative, ma la significativit\u00e0 statistica non dice niente di una significativit\u00e0 pratica di una differenza.\nUno dei problemi pi\u00f9 comuni nel testare la significativit\u00e0 \u00e8 la tendenza delle comparazioni multiple a tendere a significative differenze spurie anche dove l'ipotesi nulla \u00e8 vera. Per esempio, in uno studio di venti comparazioni, usando un \n\u03b1-livello del 5%, una comparazione pu\u00f2 effettivamente riportare un risultato significativo nonostante sia vera l'ipotesi di nullit\u00e0. in questi casi i p-valori sono corretti al fine di controllare o il valore falso o l'errore familiare.\nUn problema addizionale \u00e8 che si ritiene che le analisi frequentiste dei p-valori esagerino la \"\"significativit\u00e0 statistica\"\". Si veda il fattore di Bayes per i dettagli.\nJ. Scott Armstrong, negli articoli \"Significance Tests Harm Progress in Forecasting,\" e \"Statistical Significance Tests are Unnecessary Even When Properly Done,\" espone la sua posizione secondo cui in alcuni casi, seppure eseguiti correttamente, i test di significativit\u00e0 statistica non sarebbero utili. A suo parere, un certo numero di tentativi ha fallito nel trovare prove empiriche che sostenessero l'uso di test di significativit\u00e0, ed i test di significativit\u00e0 statistica usati da soli potrebbero essere nocivi allo sviluppo della conoscenza scientifica perch\u00e9 distrarrebbero i ricercatori dall'uso di metodi statistici in alcuni casi pi\u00f9 adatti. \nArmstrong suggerisce quindi che secondo lui i ricercatori dovrebbero evitare i test di significativit\u00e0 statistica, e dovrebbero piuttosto fare uso di strumenti di area di effetto, intervalli di fiducia, ripetizioni/estensioni, e meta-analisi.\nLa significativit\u00e0 statistica pu\u00f2 essere considerata come la fiducia che si ha in un dato risultato. In uno studio di comparazione, essa dipende dalla differenza relativa tra i gruppi confrontati, la quantit\u00e0 delle misurazioni e il rumore associato alle misurazioni. In altre parole, la fiducia che si ha che un dato risultato sia non casuale (cio\u00e8 non una conseguenza di un caso) dipende dal rapporto segnale-rumore (SNR) e misura campione. Esprimendosi matematicamente, la fiducia che un risultato non sia casuale \u00e8 dato dalla seguente formula di Sackett:\nPer chiarezza, la succitata formula \u00e8 rappresentata tabularmente qui di seguito.\nDipendenza della fiducia con rumore, segnale e misura campione (forma tabulare)\nIn parole la dipendenza di una fiducia \u00e8 maggiore se il rumore \u00e8 basso o la misura campione \u00e8 estesa o l'ampiezza effettiva (del segnale) \u00e8 larga. La fiducia di un risultato (e l'associato intervallo di fiducia) \"non\" dipende dagli effetti della sola ampiezza effettiva del segnale. Se la misura campione \u00e8 grande e il rumore e piccolo un'ampiezza effettiva di segnale pu\u00f2 essere misurata con grande fiducia. Sebbene un'ampiezza effettiva viene considerata importante essa dipende nel contesto degli eventi comparati.\nIn medicina, piccole ampiezze effettive (riflesse da piccoli aumenti di rischio) sono spesso considerate clinicamente rilevanti e sono frequentemente usati per guidare decisioni di trattamento (se c'\u00e8 una grande fiducia in essi). Sebbene un dato trattamento \u00e8 considerato un giusto tentativo esso dipende dai rischi, dai benefici e dai costi."], "concept_A": "Significativit\u00e0", "wikipedia_passage_concept_B": ["1199503", "Popolazione statistica", "In statistica per popolazione (o collettivo statistico o aggregato) si intende l'insieme degli elementi che sono oggetto di studio, ovvero l'insieme delle unit\u00e0 (dette \"unit\u00e0 statistiche\") sulle quali viene effettuata la rilevazione delle modalit\u00e0 con le quali il fenomeno studiato si presenta. Tali unit\u00e0 presentano tutte almeno una caratteristica comune, che viene accuratamente definita al fine di delimitare il loro insieme; ad esempio con \"italiani\" si pu\u00f2 intendere sia le persone di nazionalit\u00e0 italiana, anche se residenti all'estero, sia le persone residenti in Italia, indipendentemente da quale sia la loro nazionalit\u00e0.\nUna popolazione statistica va definita anche rispetto al tempo; ad esempio si possono considerare gli italiani che risultano residenti in Italia alle ore 12 di un dato giorno (popolazione definita secondo una caratteristica riferita ad un \"istante\" di tempo), oppure quelli nati dal 1\u00ba gennaio al 31 dicembre di un dato anno (popolazione definita secondo una caratteristica riferita ad un \"periodo\" di tempo).\nUna popolazione statistica, peraltro, non \u00e8 sempre un insieme biologico; costituisce una popolazione anche l'insieme delle lampadine prodotte da un'azienda in un dato periodo di tempo, l'insieme delle nazioni del continente europeo in un dato anno o l'insieme degli anni di un dato secolo.\nI collettivi statistici, o popolazioni, possono essere distinti in:\noppure in:\no ancora tra:"], "concept_B": "Popolazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["1716607", "Test t", "Il test t (o, dall'inglese, t-test) \u00e8 un test statistico di tipo parametrico con lo scopo di verificare se il valore medio di una distribuzione si discosta significativamente da un certo valore di riferimento. Differisce dal test z per il fatto che la varianza formula_1 \u00e8 sconosciuta.\nSe la varianza della popolazione non \u00e8 nota, la verifica d'ipotesi sulla media della popolazione si effettua sostituendo alla varianza di universo la sua stima ottenuta a partire dallo stimatore varianza corretta del campione:\nIn questo modo la statistica test \u00e8:\nla cui distribuzione \u00e8 quella della formula_4 di Student con formula_5 gradi di libert\u00e0. Ad ogni modo, all'aumentare dei gradi di libert\u00e0, per il teorema del limite centrale, la variabile casuale formula_4 tende alla distribuzione normale e quindi alla formula_4 si pu\u00f2 sostituire la formula_8 diciamo per una soglia campionaria formula_9 maggiore di 30. Se il test \u00e8 bidirezionale, si rifiuter\u00e0 l'ipotesi nulla se la formula_10 empirica \u00e8 maggiore della formula_10 teorica di formula_12 con formula_5 gradi di libert\u00e0 e si accetter\u00e0 l'ipotesi alternativa formula_14 con un errore formula_15 di I specie.\nIn econometria la statistica formula_10 ha la seguente forma:"], "concept_A": "Test t", "wikipedia_passage_concept_B": ["847", "Campionamento statistico", "In statistica il campionamento statistico (che si appoggia alla teoria dei campioni o teoria del campionamento), sta alla base dell'inferenza statistica, la quale si divide in due grandi capitoli: la teoria della stima e la verifica d'ipotesi.\nIn particolare, una rilevazione si dice \"campionaria\" quando \u00e8 utile per fare inferenza ossia per desumere dal campione stesso un'informazione relativa all'intera popolazione.\nLe indagini censuarie riguardano l'intera popolazione e pur essendo pi\u00f9 affidabili riguardo al parametro oggetto d'indagine soffrono di:\nQuindi mentre l'indagine censuaria fornisce il valore vero dei parametri di interesse (proporzioni, percentuali, medie, totali...) quella campionaria restituisce una sua stima al quale \u00e8 associato un certo grado di fiducia (ovvero un'incertezza) quantificabile quando la formazione del campione risponde a determinati criteri di tipo probabilistico.\nIl campionamento si usa quando si vuole conoscere uno o pi\u00f9 parametri di una popolazione, senza doverne analizzare ogni elemento: questo per motivi di costi intesi in termini monetari, di tempo, di qualit\u00e0 o di disagio o perch\u00e9 analizzare un elemento lo distrugge rendendo inutilizzabile l'informazione ottenuta.\nModalit\u00e0 di selezione del campione sono:\nNella pratica quotidiana dei sondaggi di opinione e delle ricerche di mercato vengono usati tutti e quattro gli approcci.\nLa scelta di un tipo di campionamento avviene in base alle propriet\u00e0 degli stimatori di alcuni parametri oppure per tener conto di problemi di costo, mobilit\u00e0 o altro.\nConcetti chiave sono:\nBench\u00e9 gi\u00e0 nel Settecento si sia notato il vantaggio nell'esaminare un sottinsieme della popolazione per generalizzare i risultati alla popolazione complessiva, \u00e8 solo dalla fine dell'Ottocento che la discussione sulla \"scientificit\u00e0\" del campionamento viene posta in modo esplicito alla comunit\u00e0 statistica.\nGi\u00e0 agli inizi del Novecento si vanno delineando le caratteristiche che un campione deve avere, ovvero che deve essere scelto in maniera casuale, e nell'arco di pochi anni compaiono i primi studi che mettono in evidenza che il campione non deve essere necessariamente un campione semplice ma pu\u00f2 essere pi\u00f9 complesso, per esempio stratificando.\nImportanti autori che hanno fatto la storia della teoria dei campioni sono stati tra gli altri: \nNel 1925, durante il congresso di Roma, l'Istituto Internazionale di Statistica accetta definitivamente come scientifico il metodo campionario, distinguendo il campionamento casuale dal campionamento ragionato.\nAltri autori importanti nella ricerca teorica ed applicata sul campionamento furono George Gallup e William G. Cochran."], "concept_B": "Campionamento statistico", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_B": "Probabilit\u00e0 condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["4100372", "Rete neurale artificiale", "Nel campo dell'apprendimento automatico, una rete neurale artificiale (in inglese \"artificial neural network\", abbreviato in ANN o anche come NN) \u00e8 un modello computazionale composto di \"neuroni\" artificiali, ispirato vagamente dalla semplificazione di una rete neurale biologica.\nQuesti modelli matematici sono troppo semplici per ottenere una comprensione delle reti neurali biologiche, ma sono utilizzati per tentare di risolvere problemi ingegneristici di intelligenza artificiale come quelli che si pongono in diversi ambiti tecnologici (in elettronica, informatica, simulazione, e altre discipline).\nUna rete neurale artificiale pu\u00f2 essere realizzata sia da programmi software che da hardware dedicato (DSP, \"Digital Signal Processing\"). Questa branca pu\u00f2 essere utilizzata in congiunzione alla logica fuzzy.\nL'ampia variet\u00e0 di modelli non pu\u00f2 prescindere dal costituente di base, il neurone artificiale proposto da W.S. McCulloch e Walter Pitts in un famoso lavoro del 1943: \"\"A logical calculus of the ideas immanent in nervous activity\"\", il quale schematizza un combinatore lineare a soglia, con dati binari multipli in entrata e un singolo dato binario in uscita: un numero opportuno di tali elementi, connessi in modo da formare una rete, \u00e8 in grado di calcolare semplici funzioni booleane.\nLe prime ipotesi di apprendimento furono introdotte da D. O. Hebb nel libro del 1949: \"\"The organization of behavior\"\", nel quale vengono proposti collegamenti con i modelli complessi del cervello.\nNel 1958, J. Von Neumann nella sua opera \"\"The computer and the brain\"\" esamina le soluzioni proposte dai precedenti autori sottolineando la scarsa precisione che queste strutture possedevano per potere svolgere operazioni complesse.\nNello stesso anno, Frank Rosenblatt nel libro \"Psychological review\" introduce il primo schema di rete neurale, detto \"Perceptron\" (percettrone), antesignano delle attuali reti neurali, per il riconoscimento e la classificazione di forme, allo scopo di fornire un'interpretazione dell'organizzazione generale dei sistemi biologici. Il modello probabilistico di Rosenblatt \u00e8 quindi mirato all'analisi, in forma matematica, di funzioni quali l'immagazzinamento delle informazioni, e della loro influenza sul riconoscimento dei pattern; esso costituisce un progresso decisivo rispetto al modello binario di McCulloch e Pitts, perch\u00e9 i suoi pesi sinaptici sono variabili e quindi il percettrone \u00e8 in grado di apprendere.\nL'opera di Rosenblatt stimola una quantit\u00e0 di studi e ricerche che dura per un decennio, e suscita un vivo interesse e notevoli aspettative nella comunit\u00e0 scientifica, destinate tuttavia ad essere notevolmente ridimensionate allorch\u00e9 nel 1969 Marvin Minsky e Seymour A. Papert, nell'opera \"\"An introduction to computational geometry\"\", mostrano i limiti operativi delle semplici reti a due strati basate sul percettrone, e dimostrano l'impossibilit\u00e0 di risolvere per questa via molte classi di problemi, ossia tutti quelli non caratterizzati da separabilit\u00e0 lineare delle soluzioni: questo tipo di rete neurale non \u00e8 abbastanza potente: non \u00e8 infatti neanche in grado di calcolare la funzione \"or esclusivo\" (XOR). A causa di queste limitazioni, al periodo di euforia dovuto ai primi risultati della cibernetica (come veniva chiamata negli anni sessanta) segue un periodo di diffidenza durante il quale tutte le ricerche in questo campo non ricevono pi\u00f9 alcun finanziamento dal governo degli Stati Uniti d'America; le ricerche sulle reti tendono, di fatto, a ristagnare per oltre un decennio, e l'entusiasmo iniziale risulta fortemente ridimensionato.\nIl contesto matematico per addestrare le reti MLP (\"Multi-Layers Perceptron\", ossia percettrone multistrato) fu stabilito dal matematico americano Paul Werbos nella sua tesi di dottorato (Ph.D.) del 1974. Non fu dato molto peso al suo lavoro tanto fu forte la confutazione dimostrata da Minsky e Papert anni prima, e solo l'intervento di J. J. Hopfield, nel 1982, che in un suo lavoro studia dei modelli di riconoscimento di pattern molto generali, si oppose in modo diretto alla confutazione di Minsky riaprendo cos\u00ec degli spiragli per la ricerca in questo campo.\nUno dei metodi pi\u00f9 noti ed efficaci per l'addestramento di tale classe di reti neurali \u00e8 il cosiddetto algoritmo di retropropagazione dell'errore (error backpropagation), proposto nel 1986 da David E. Rumelhart, G. Hinton e R. J. Williams, il quale modifica sistematicamente i pesi delle connessioni tra i nodi, cos\u00ec che la risposta della rete si avvicini sempre di pi\u00f9 a quella desiderata. Tale lavoro fu prodotto riprendendo il modello creato da Werbos. L'algoritmo di retropropagazione (\"backpropagation\" o BP) \u00e8 una tecnica d'apprendimento tramite esempi, costituente una generalizzazione dell'algoritmo d'apprendimento per il percettrone sviluppato da Rosenblatt nei primi anni '60. Mediante questa tecnica era possibile, come detto, trattare unicamente applicazioni caratterizzabili come funzioni booleane linearmente separabili.\nL'algoritmo di apprendimento si basa sul metodo della discesa del gradiente che permette di trovare un minimo locale di una funzione in uno spazio a N dimensioni. I pesi associati ai collegamenti tra gli strati di neuroni si inizializzano a valori piccoli (ovvero molto inferiori ai valori reali che poi assumeranno) e casuali e poi si applica la regola di apprendimento presentando alla rete dei pattern di esempio. Queste reti neurali sono poi capaci di generalizzare in modo appropriato, cio\u00e8 di dare risposte plausibili per input che non hanno mai visto.\nL'addestramento di une rete neurale di tipo BP avviene in due diversi stadi: \"forward-pass\" e \"backward-pass\". Nella prima fase i vettori in input sono applicati ai nodi in ingresso con una propagazione in avanti dei segnali attraverso ciascun livello della rete (\"forward-pass\"). Durante questa fase i valori dei pesi sinaptici sono tutti fissati. Nella seconda fase la risposta della rete viene confrontata con l'uscita desiderata ottenendo il segnale d'errore. L'errore calcolato \u00e8 propagato nella direzione inversa rispetto a quella delle connessioni sinaptiche. I pesi sinaptici infine sono modificati in modo da minimizzare la differenza tra l'uscita attuale e l'uscita desiderata (\"backward-pass\").\nTale algoritmo consente di superare le limitazioni del percettrone e di risolvere il problema della separabilit\u00e0 non lineare (e quindi di calcolare la funzione XOR), segnando il definitivo rilancio delle reti neurali, come testimoniato anche dall'ampia variet\u00e0 d'applicazioni commerciali: attualmente la BP rappresenta un algoritmo di largo uso in molti campi applicativi.\nUna rete neurale artificiale (ANN \"\"Artificial Neural Network\"\" in inglese), normalmente chiamata solo \"rete neurale\" (NN \"\"Neural Network\"\" in inglese), \u00e8 un modello matematico/informatico di calcolo basato sulle reti neurali biologiche. Tale modello \u00e8 costituito da un gruppo di interconnessioni di informazioni costituite da neuroni artificiali e processi che utilizzano un approccio di connessionismo di calcolo. Nella maggior parte dei casi una rete neurale artificiale \u00e8 un sistema adattivo che cambia la propria struttura in base a informazioni esterne o interne che scorrono attraverso la rete stessa durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare.\nUna rete neurale artificiale riceve segnali esterni su uno strato di nodi (unit\u00e0 di elaborazione) d'ingresso, ciascuno dei quali \u00e8 collegato con numerosi nodi interni, organizzati in pi\u00f9 livelli. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\nIl concetto di rete neurale si pone perch\u00e9 una funzione formula_1 \u00e8 definita come una composizione di altre funzioni formula_2, che possono a loro volta essere ulteriormente definite come composizione di altre funzioni. Questo pu\u00f2 essere comodamente rappresentato come una struttura di reti, con le frecce raffiguranti le dipendenze tra variabili. Una rappresentazione ampiamente utilizzata \u00e8 la somma ponderata non lineare, dove formula_3, dove formula_4 \u00e8 una funzione predefinita, come ad esempio la tangente iperbolica. Sar\u00e0 conveniente per le seguenti far riferimento ad un insieme di funzioni come un vettore formula_5.\nLa Figura 1 esemplifica una decomposizione della funzione formula_6, con dipendenze tra le variabili indicate dalle frecce. Queste possono essere interpretate in due modi:\nI due punti di vista sono in gran parte equivalenti. In entrambi i casi, per questa particolare architettura di rete, i componenti dei singoli strati sono indipendenti l'uno dall'altro (ad esempio, le componenti di formula_8 sono indipendenti l'una dall'altra, dato il loro ingresso formula_15). Questo, naturalmente, permette un certo grado di parallelismo nella costruzione del sistema.\nReti, come ad esempio quelle precedenti vengono comunemente chiamate \"\"feedforward\"\", perch\u00e9 il loro \u00e8 un grafico aciclico diretto. Reti con cicli al loro interno sono comunemente chiamati reti ricorrenti. Tali reti sono comunemente raffigurate nel modo indicato nella parte superiore della Figura 2, dove la funzione formula_6 \u00e8 mostrata come dipendente su se stessa. Tuttavia, vi \u00e8 una dipendenza temporale implicita che non \u00e8 possibile dimostrare. Questo significa in pratica che il valore di formula_6 ad un certo punto nel tempo formula_18 dipende dai valori di formula_6 al tempo zero o su uno o pi\u00f9 altri punti temporali. Il modello del grafico nella parte inferiore della Figura 2 illustra il caso in cui il valore di formula_6 al tempo formula_18 dipende solo dal suo valore finale.\nTuttavia la funzionalit\u00e0 pi\u00f9 interessante di queste funzioni, ci\u00f2 che ha attirato l'interesse e lo studio per la maggior parte delle reti neurali, \u00e8 la possibilit\u00e0 di apprendimento, che in pratica significa la seguente:\nCi\u00f2 comporta la definizione di una funzione di costo formula_24 tale che, per la soluzione ottimale formula_25 formula_26 nessuna soluzione ha un costo inferiore al costo della soluzione ottimale.\nLa funzione di costo formula_27 \u00e8 un concetto importante nell'apprendimento, poich\u00e9 si tratta di una misura di quanto \u00e8 lontana da noi la soluzione ottimale del problema che vogliamo risolvere. Quindi vi sono una serie di algoritmi di apprendimento che cercano nello spazio delle soluzioni al fine di trovare una funzione che abbia il minor costo possibile.\nPer applicazioni in cui la soluzione dipende da alcuni dati, il costo deve essere necessariamente funzione delle osservazioni.\nMentre \u00e8 possibile definire per alcune reti una funzione di costo ad hoc, spesso si pu\u00f2 utilizzare una particolare funzione di costo poich\u00e9 gode delle propriet\u00e0 desiderate (ad esempio, la convessit\u00e0), o perch\u00e9 proviene da una particolare formulazione del problema (vale a dire, in una formulazione probabilistica, la probabilit\u00e0 a posteriori del modello pu\u00f2 essere utilizzata come l'inverso del costo). In ultima analisi, la funzione di costo dipender\u00e0 dal compito.\nVi sono tre grandi paradigmi di apprendimento, ciascuno corrispondente ad un particolare compito astratto di apprendimento. Si tratta dell'apprendimento supervisionato, apprendimento non supervisionato e l'apprendimento per rinforzo. Di solito un tipo di architettura di rete pu\u00f2 essere impiegato in qualsiasi di tali compiti.\nL'algoritmo di apprendimento hebbiano (1984) si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata.\nformula_28 dove formula_29,\ndove formula_30 \u00e8 l'formula_31 ingresso e formula_32 \u00e8 il tasso di apprendimento formula_33.\nLa regola di Hebb \u00e8 la seguente: l'efficacia di una particolare sinapsi cambia se e solo se c'\u00e8 un'intensa attivit\u00e0 simultanea dei due neuroni, con un'alta trasmissione di input nella sinapsi in questione.\nEsempio di procedura:\nIn questo modo le connessioni possono solo irrobustirsi.\nLe connessioni si considerano irrobustite quando le unit\u00e0 presinaptica e postsinaptica sono d'accordo, altrimenti si indeboliscono.\nSi considerano funzioni bipolari (-1,1) invece che booleane (0,1).\nLe reti neurali si basano principalmente sulla simulazione di neuroni artificiali opportunamente collegati. Il modello rappresentato in figura \u00e8 quello proposto da McCulloch e Pitts.\nI suddetti neuroni ricevono in ingresso degli stimoli e li elaborano. L'elaborazione pu\u00f2 essere anche molto sofisticata ma in un caso semplice si pu\u00f2 pensare che i singoli ingressi vengano moltiplicati per un opportuno valore detto peso, il risultato delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone si attiva attivando la sua uscita. Il peso indica l'efficacia sinaptica della linea di ingresso e serve a quantificarne l'importanza, un ingresso molto importante avr\u00e0 un peso elevato, mentre un ingresso poco utile all'elaborazione avr\u00e0 un peso inferiore. Si pu\u00f2 pensare che se due neuroni comunicano fra loro utilizzando maggiormente alcune connessioni allora tali connessioni avranno un peso maggiore, fino a che non si creeranno delle connessioni tra l'ingresso e l'uscita della rete che sfruttano \"percorsi preferenziali\". Tuttavia \u00e8 sbagliato pensare che la rete finisca col produrre un unico percorso di connessione: tutte le combinazioni infatti avranno un certo peso, e quindi contribuiscono al collegamento ingresso/uscita.\nIl modello in figura rappresenta una classica rete neurale pienamente connessa.\nI singoli neuroni vengono collegati alla schiera di neuroni successivi, in modo da formare una rete di neuroni. Normalmente una rete \u00e8 formata da tre strati. Nel primo abbiamo gli ingressi (I), questo strato si preoccupa di trattare gli ingressi in modo da adeguarli alle richieste dei neuroni. Se i segnali in ingresso sono gi\u00e0 trattati pu\u00f2 anche non esserci. Il secondo strato \u00e8 quello nascosto (H, \"hidden\"), si preoccupa dell'elaborazione vera e propria e pu\u00f2 essere composto anche da pi\u00f9 colonne di neuroni. Il terzo strato \u00e8 quello di uscita (O) e si preoccupa di raccogliere i risultati ed adattarli alle richieste del blocco successivo della rete neurale. Queste reti possono essere anche molto complesse e coinvolgere migliaia di neuroni e decine di migliaia di connessioni.\nPer costruire la struttura di una rete neurale multistrato si possono inserire formula_38 strati \"hidden.\" L'efficacia di generalizzare di una rete neurale multistrato dipende ovviamente dall'addestramento che ha ricevuto e dal fatto di essere riuscita o meno ad entrare in un minimo locale buono.\nL'algoritmo di retropropagazione dell'errore (\"backpropagation\") \u00e8 utilizzato nell'apprendimento con supervisione. Esso permette di modificare i pesi delle connessioni in modo tale che si minimizzi una certa funzione errore E. Tale funzione dipende dal vettore h-esimo di output formula_39 restituito dalla rete, dato il vettore h-esimo di ingresso formula_40 e dal vettore h-esimo di output formula_41che noi desideriamo (che fa parte del training set). Il training set \u00e8 dunque un insieme di N coppie di vettori formula_42, con formula_43. La funzione errore che si deve minimizzare si pu\u00f2 scrivere come:\nformula_44\ndove l'indice k rappresenta il valore corrispondente al k-esimo neurone di output. E(w) \u00e8 una funzione dipendente dai pesi (che in generale variano nel tempo), per minimizzarla si pu\u00f2 usare l'algoritmo della discesa del gradiente (\"gradient descent\"). L'algoritmo parte da un punto generico formula_45 e calcola il gradiente formula_46. Il gradiente d\u00e0 la direzione verso cui muoversi lungo la quale si ha il massimo incremento (o decremento se considero formula_47). Definita la direzione ci si muove di una distanza formula_32 predefinita a priori e si trova un nuovo punto formula_49 sul quale \u00e8 calcolato nuovamente il gradiente. Si continua iterativamente finch\u00e9 il gradiente non \u00e8 nullo.\nL'algoritmo di backpropagation pu\u00f2 essere diviso in due passi:\nI passi logici per addestrare una rete neurale con apprendimento supervisionato sono i seguenti:\nPer l'addestramento di reti neurali profonde, impiegando dataset molto vasti, la discesa del gradiente classica risulta computazionalmente proibitiva, per cui nell'ottimizzare i parametri del modello si fa tipicamente uso dell'algoritmo di discesa stocastica del gradiente.\nNel 1982, il fisico John J. Hopfield pubblica un articolo fondamentale in cui presenta un modello matematico comunemente noto appunto come rete di Hopfield: tale rete si distingue per \"l'emergere spontaneo di nuove capacit\u00e0 computazionali dal comportamento collettivo di un gran numero di semplici elementi d'elaborazione\". Le propriet\u00e0 collettive del modello producono una memoria associativa per il riconoscimento di configurazioni corrotte e il recupero di informazioni mancanti.\nInoltre, Hopfield ritiene che ogni sistema fisico possa essere considerato come un potenziale dispositivo di memoria, qualora esso disponga di un certo numero di stati stabili, i quali fungano da attrattore per il sistema stesso. Sulla base di tale considerazione, egli si spinge a formulare la tesi secondo cui la stabilit\u00e0 e la collocazione di tali attrattori sono propriet\u00e0 spontanee di sistemi costituiti, come accennato, da considerevoli quantit\u00e0 di neuroni reciprocamente interagenti.\nLe applicazioni delle reti di Hopfield riguardano principalmente la realizzazione di memorie associative, resistenti all'alterazione delle condizioni operative, e la soluzione di problemi d'ottimizzazione combinatoriale.\nDa un punto di vista strutturale, la rete di Hopfield costituisce una rete neurale ricorrente simmetrica, di cui \u00e8 garantita la convergenza.\nUna rete ricorrente \u00e8 un modello neurale in cui \u00e8 presente un flusso bidirezionale d'informazioni; in altri termini, mentre nelle reti di tipo feedforward la propagazione dei segnali avviene unicamente, in maniera continua, nella direzione che conduce dagli ingressi alle uscite, nelle reti ricorrenti tale propagazione pu\u00f2 anche manifestarsi da uno strato neurale successivo ad uno precedente, oppure tra neuroni appartenenti ad uno stesso strato, e persino tra un neurone e s\u00e9 stesso.\nUn significativo e noto esempio di semplice rete ricorrente \u00e8 dovuto a Jeffrey L. Elman (1990). Essa costituisce una variazione sul tema del percettrone multistrato, con esattamente tre strati e l'aggiunta di un insieme di neuroni \"contestuali\" nello strato d'ingresso. Le connessioni retroattive si propagano dallo strato intermedio (e nascosto) a tali unit\u00e0 contestuali, alle quali si assegna peso costante e pari all'unit\u00e0.\nIn ciascun istante, gli ingressi si propagano nel modo tradizionale e tipico delle reti feedforward, compresa l'applicazione dell'algoritmo d'apprendimento (solitamente la \"backpropagation\"). Le connessioni retroattive fisse hanno come effetto quello di mantenere una copia dei precedenti valori dei neuroni intermedi, dal momento che tale flusso avviene sempre prima della fase d'apprendimento.\nIn questo modo la rete di Elman tiene conto del suo stato precedente, cosa che le consente di svolgere compiti di previsione di sequenze temporali che sono difficilmente alla portata dei percettroni multistrato convenzionali.\nInfine, un ultimo interessante tipo di rete \u00e8 costituita dalla cosiddetta mappa auto-organizzante o rete SOM (\"Self-Organizing Map\"). Tale innovativo tipo di rete neurale \u00e8 stata elaborata da Teuvo Kohonen dell'Universit\u00e0 Tecnologica di Helsinki; il suo algoritmo d'apprendimento \u00e8 senza dubbio una brillante formulazione di apprendimento non supervisionato, e ha dato luogo a un gran numero di applicazioni nell'ambito dei problemi di classificazione. Una mappa o rete SOM \u00e8 basata essenzialmente su un reticolo o griglia di neuroni artificiali i cui pesi sono continuamente adattati ai vettori presentati in ingresso nel relativo insieme di addestramento. Tali vettori possono essere di dimensione generica, anche se nella maggior parte delle applicazioni essa \u00e8 piuttosto alta. Per ci\u00f2 che riguarda le uscite della rete, al contrario, ci si limita di solito ad una dimensione massima pari a tre, il che consente di dare luogo a mappe 2D o 3D.\nIn termini pi\u00f9 analitici, l'algoritmo pu\u00f2 essere agevolmente descritto, come accennato, nei termini di un insieme di neuroni artificiali, ciascuno con una precisa collocazione sulla mappa rappresentativa degli \"output\", che prendono parte ad un processo noto come \"winner takes all\" (\"Il vincitore piglia tutto\"), al termine del quale il nodo avente un vettore di pesi pi\u00f9 vicino ad un certo \"input\" \u00e8 dichiarato vincitore, mentre i pesi stessi sono aggiornati in modo da avvicinarli al vettore in ingresso. Ciascun nodo ha un certo numero di nodi adiacenti. Quando un nodo vince una competizione, anche i pesi dei nodi adiacenti sono modificati, secondo la regola generale che pi\u00f9 un nodo \u00e8 lontano dal nodo vincitore, meno marcata deve essere la variazione dei suoi pesi. Il processo \u00e8 quindi ripetuto per ogni vettore dell'insieme di \"training\", per un certo numero, solitamente grande, di cicli. Va da s\u00e9 che ingressi diversi producono vincitori diversi.\nOperando in tal modo, la mappa riesce alfine ad associare i nodi d'uscita con i gruppi o schemi ricorrenti nell'insieme dei dati in ingresso. Se questi schemi sono riconoscibili, essi possono essere associati ai corrispondenti nodi della rete addestrata. In maniera analoga a quella della maggioranza delle reti neurali artificiali, anche la mappa o rete SOM pu\u00f2 operare in due distinte modalit\u00e0:\nIn generale una ANN (\"Attractor Neural Network\") \u00e8 una rete di nodi (es: biologicamente ispirati), spesso interconnessi in modo ricorsivo, la cui dinamica nel tempo stabilisce un assestamento in un particolare modo di oscillazione. Questo modo di oscillazione pu\u00f2 essere stazionario, variante nel tempo o di tipo stocastico ed \u00e8 chiamato il suo 'attrattore'. In neuroscienza teorica diversi tipi di reti ad attrattori sono state associate a differenti funzioni, come: memoria, attenzione, condotta del moto e classificazione.\nPi\u00f9 precisamente, una rete ad attrattori \u00e8 una rete di N nodi connessi in modo che la loro intera dinamica diventi stabile in uno spazio D dimensionale, dove solitamente N\u00bbD. Ci\u00f2 assume che non vi sia pi\u00f9 input dall'esterno del sistema. La stabilit\u00e0 nello stato ad attrattore indica l'esistenza di uno stato stabile in una qualche variet\u00e0 algebrica (es: linea, cerchio, piano, toroide).\nL'utilit\u00e0 dei modelli di rete neurale sta nel fatto che queste possono essere usate per comprendere una funzione utilizzando solo le osservazioni sui dati. Ci\u00f2 \u00e8 particolarmente utile nelle applicazioni in cui la complessit\u00e0 dei dati o la difficolt\u00e0 di elaborazione rende la progettazione di una tale funzione impraticabile con i normali procedimenti di analisi manuale.\nI compiti a cui le reti neurali sono applicate possono essere classificate nelle seguenti grandi categorie di applicazioni:\nLe aree di applicazione includono i sistemi di controllo (controllo di veicoli, controllo di processi), simulatori di giochi e processi decisionali (backgammon, scacchi), riconoscimento di pattern (sistemi radar, identificazione di volti, riconoscimento di oggetti, ecc), riconoscimenti di sequenze (riconoscimento di gesti, riconoscimento vocale, OCR), diagnosi medica, applicazioni finanziarie, data mining, filtri spam per e-mail.\nLe reti neurali per come sono costruite lavorano in parallelo e sono quindi in grado di trattare molti dati. Si tratta in sostanza di un sofisticato sistema di tipo statistico dotato di una buona immunit\u00e0 al rumore; se alcune unit\u00e0 del sistema dovessero funzionare male, la rete nel suo complesso avrebbe delle riduzioni di prestazioni ma difficilmente andrebbe incontro ad un blocco del sistema. I software di ultima generazione dedicati alle reti neurali richiedono comunque buone conoscenze statistiche; il grado di apparente utilizzabilit\u00e0 immediata non deve trarre in inganno, pur permettendo all'utente di effettuare subito previsioni o classificazioni, seppure con i limiti del caso.\nDa un punto di vista industriale, risultano efficaci quando si dispone di dati storici che possono essere trattati con gli algoritmi neurali. Ci\u00f2 \u00e8 di interesse per la produzione perch\u00e9 permette di estrarre dati e modelli senza effettuare ulteriori prove e sperimentazioni.\nI modelli prodotti dalle reti neurali, anche se molto efficienti, non sono spiegabili in linguaggio simbolico umano: i risultati vanno accettati \"cos\u00ec come sono\", da cui anche la definizione inglese delle reti neurali come \"black box\": in altre parole, a differenza di un sistema algoritmico, dove si pu\u00f2 esaminare passo-passo il percorso che dall'input genera l'output, una rete neurale \u00e8 in grado di generare un risultato valido, o comunque con una alta probabilit\u00e0 di essere accettabile, ma non \u00e8 possibile spiegare come e perch\u00e9 tale risultato sia stato generato.\nCome per qualsiasi algoritmo di modellazione, anche le reti neurali sono efficienti solo se le variabili predittive sono scelte con cura.\nNon sono in grado di trattare in modo efficiente variabili di tipo categorico (per esempio, il nome della citt\u00e0) con molti valori diversi. Necessitano di una fase di addestramento del sistema che fissi i pesi dei singoli neuroni e questa fase pu\u00f2 richiedere molto tempo, se il numero dei record e delle variabili analizzate \u00e8 molto grande. Non esistono teoremi o modelli che permettano di definire la rete ottima, quindi la riuscita di una rete dipende molto dall'esperienza del creatore.\nLe reti neurali vengono solitamente usate in contesti dove i dati possono essere parzialmente errati oppure dove non esistano modelli analitici in grado di affrontare il problema. Un loro tipico utilizzo \u00e8 nei software di OCR, nei sistemi di riconoscimento facciale e pi\u00f9 in generale nei sistemi che si occupano di trattare dati soggetti a errori o rumore. Esse sono anche uno degli strumenti maggiormente utilizzati nelle analisi di Data mining.\nLe reti neurali vengono anche utilizzate come mezzo per previsioni nell'analisi finanziaria o meteorologica. Negli ultimi anni \u00e8 aumentata notevolmente la loro importanza anche nel campo della bioinformatica nel quale vengono utilizzate per la ricerca di pattern funzionali e/o strutturali in proteine e acidi nucleici. Mostrando opportunamente una lunga serie di input (fase di training o apprendimento), la rete \u00e8 in grado di fornire l'output pi\u00f9 probabile. Negli ultimi anni inoltre sono in corso studi per il loro utilizzo nella previsione degli attacchi Epilettici (Analisi dei Dati provenienti dall' EEG).\nRecenti studi hanno dimostrato buone potenzialit\u00e0 delle reti neurali in sismologia per la localizzazione di epicentri di terremoti e predizione della loro intensit\u00e0."], "concept_A": "Rete neurale artificiale", "wikipedia_passage_concept_B": ["3612028", "Classificazione statistica", "La classificazione statistica \u00e8 quell'attivit\u00e0 che si serve di un algoritmo statistico al fine di individuare una rappresentazione di alcune caratteristiche di un'entit\u00e0 da classificare (oggetto o nozione), associandole una etichetta classificatoria. Tale attivit\u00e0 pu\u00f2 essere svolta mediante algoritmi di apprendimento automatico supervisionato o non supervisionato. Esempi di questi algoritmi sono:\nI programmi che effettuano l'attivit\u00e0 di classificazione sono detti classificatori. Talora si usa l'aggettivo \"statistica\" anche per classificazioni utilizzate per costruire indicazioni statistiche sulle entit\u00e0 assegnate ai diversi contenitori di una classificazione, soprattutto nel caso delle tassonomie, mentre nella definizione della classificazione non si sono utilizzati precisi metodi statistici."], "concept_B": "Classificazione statistica", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["4314", "Teorema di Bayes", "Il teorema di Bayes (conosciuto anche come formula di Bayes o teorema della probabilit\u00e0 delle cause), proposto da Thomas Bayes, deriva da due teoremi fondamentali delle probabilit\u00e0:\nil teorema della probabilit\u00e0 composta e il teorema della probabilit\u00e0 assoluta. Viene impiegato per calcolare la probabilit\u00e0 di una causa che ha scatenato l'evento verificato. Per esempio si pu\u00f2 calcolare la probabilit\u00e0 che una certa persona soffra della malattia per cui ha eseguito il test diagnostico (nel caso in cui questo sia risultato negativo) o viceversa non sia affetta da tale malattia (nel caso in cui il test sia risultato positivo), conoscendo la frequenza con cui si presenta la malattia e la percentuale di efficacia del test diagnostico.\nFormalmente il teorema di Bayes \u00e8 valido in tutte le interpretazioni della probabilit\u00e0. In ogni caso, l'importanza di questo teorema per la statistica \u00e8 tale che la divisione tra le due scuole (statistica bayesiana e statistica frequentista) nasce dall'interpretazione che si d\u00e0 al teorema stesso.\nConsiderando un insieme di alternative formula_1 che partizionano lo spazio degli eventi formula_2 (ossia formula_3 e formula_4) si trova la seguente espressione per la probabilit\u00e0 condizionata:\nDove:\nIntuitivamente, il teorema descrive il modo in cui le opinioni nell'osservare A siano arricchite dall'aver osservato l'evento E.\nSi consideri una scuola che ha il 60% di studenti maschi e il 40% di studentesse femmine.\nLe studentesse indossano in egual numero gonne o pantaloni; gli studenti indossano tutti quanti i pantaloni. Un osservatore, da lontano, nota un generico studente coi pantaloni. Qual \u00e8 la probabilit\u00e0 che quello studente sia una femmina?\nIl problema pu\u00f2 essere risolto con il teorema di Bayes, ponendo l'evento A che lo studente osservato sia femmina, e l'evento B che lo studente osservato indossi i pantaloni. Per calcolare P(A|B), dovremo sapere:\nCi\u00f2 detto, possiamo applicare il teorema:\nC'\u00e8 pertanto 1/4 di probabilit\u00e0 che lo studente sia femmina cio\u00e8 25%.\nIl teorema deriva dalla definizione di probabilit\u00e0 condizionata. La probabilit\u00e0 di un evento \"A\", noto un evento \"B\", risulta:\nIn modo analogo, la probabilit\u00e0 di un evento \"B\" noto un evento \"A\":\nPertanto:\nSostituendo nella prima uguaglianza, si trova il teorema di Bayes:\nSi supponga di partecipare a un gioco a premi, in cui si pu\u00f2 scegliere fra tre porte: dietro una di esse c'\u00e8 un'automobile, dietro le altre, due capre. Si sceglie una porta, diciamo la numero 1, e il conduttore del gioco a premi, che sa cosa si nasconde dietro ciascuna porta, ne apre un'altra, diciamo la 3, rivelando una capra. Quindi domanda: \u00abVorresti scegliere la numero 2?\u00bb Ti conviene cambiare la tua scelta originale?\nSi potrebbe pensare che, con due porte chiuse, si abbia una probabilit\u00e0 50:50 per ognuna, e che quindi non ci sia motivo di cambiare porta. Non \u00e8 questo il caso. Chiamiamo l'evento che la macchina si trovi dietro una certa porta rispettivamente A, A e A.\nAll'inizio, \u00e8 ovvio che:\nformula_11\nCome detto prima, la porta scelta \u00e8 la numero 1. Chiamiamo B l'evento \"il presentatore apre la porta 3\". Ora:\nLa probabilit\u00e0 a priori per l'evento B \u00e8 del 50%, infatti:\nDa cui:\nDa ci\u00f2 \u00e8 evidente che si deve sempre cambiare con la porta 2.\nI filtri bayesiani sono uno strumento utilizzato per combattere lo spam che deve il suo funzionamento proprio al teorema di Bayes. Un filtro bayesiano fa uso di un classificatore bayesiano per riconoscere se una certa sequenza di simboli (come una parola) si presenta spesso nei messaggi di spam, quindi applica l'inferenza bayesiana per calcolare la probabilit\u00e0 che un determinato messaggio sia spam.\nIl teorema si chiama cos\u00ec in onore del reverendo Thomas Bayes (1702\u20131761), il quale studi\u00f2 come calcolare una distribuzione per il parametro di una distribuzione binomiale. Un suo amico, Richard Price, pubblic\u00f2 il lavoro nel 1763, dopo la morte di Bayes, nell'articolo \"Essay Towards Solving a Problem in the Doctrine of Chances\". \nAlcuni anni dopo (nel 1774) viene formulato da Pierre Simon Laplace che probabilmente non era a conoscenza del lavoro di Bayes.\nUna ricerca da parte di un professore di statistica (Stigler, 1982) sembrerebbe suggerire che il teorema di Bayes sia stato scoperto da Nicholas Saunderson anni prima di Bayes."], "concept_A": "Teorema di Bayes", "wikipedia_passage_concept_B": ["3678589", "Distribuzione condizionata", "variabili aleatorie \"X\" e \"Y\", la distribuzione condizionata di Y dato X \u00e8 la probabilit\u00e0 di Y quando \u00e8 conosciuto il valore assunto da X. A ogni distribuzione condizionata \u00e8 associato un valore atteso condizionato e una varianza condizionata.\nNel caso di variabili aletorie discrete, la distribuzione condizionata di \"Y\" dato \"X=x\", \u00e8 data da:\n\u00c8 necessario quindi che \"P(X=x)>0\".\nNel caso di variabili aleatorie continue, la densit\u00e0 condizionata di \"Y\" dato \"X=x\" \u00e8 data da\nAnche in questo caso, si deve avere che formula_3.\nSe per due variabili aleatorie \"X\" e \"Y\" si ha che \"P\"(\"Y\" = \"y\" | \"X\" = \"x\") = \"P\"(\"Y\" = \"y\") per ogni \"x\" e \"y\" o, nel caso continuo, \"f\"(\"y\" | \"X=x\") = \"f\"(\"y\") per ogni \"x\" e \"y\", allora le due variabili sono dette indipendenti"], "concept_B": "Distribuzione condizionata", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_A": "Boosting", "wikipedia_passage_concept_B": ["40388", "Funzione di densit\u00e0 di probabilit\u00e0", "In matematica, una funzione di densit\u00e0 di probabilit\u00e0 (o PDF dall'inglese \"probability density function\") \u00e8 l'analogo della funzione di probabilit\u00e0 di una variabile casuale nel caso in cui la variabile casuale formula_1 sia continua, cio\u00e8 l'insieme dei possibili valori che ha la potenza del continuo.\nEssa descrive la \"densit\u00e0\" di probabilit\u00e0 in ogni punto nello spazio campionario.\nLa funzione di densit\u00e0 di probabilit\u00e0 di una variabile casuale formula_1 \u00e8 un'applicazione formula_3 non negativa integrabile secondo Lebesgue e reale di variabile reale tale che la probabilit\u00e0 dell'insieme \"A\" sia data da\nper tutti i sottinsiemi \"A\" dello spazio campionario.\nIntuitivamente, se una distribuzione di probabilit\u00e0 ha densit\u00e0 formula_3, allora l'intervallo formula_6 ha probabilit\u00e0 formula_7. Da ci\u00f2 deriva che la funzione formula_3 \u00e8 un'applicazione definita come\nAssumendo formula_10, ci\u00f2 corrisponde al limite della probabilit\u00e0 che formula_11 si trovi nell'intervallo formula_6 per formula_13 che tende a zero. Di qui il nome di funzione di 'densit\u00e0', in quanto essa rappresenta il rapporto tra una probabilit\u00e0 e un'ampiezza.\nPer la condizione di normalizzazione l'integrale su tutto lo spazio di formula_3 deve essere 1. Di conseguenza ogni funzione non negativa, integrabile secondo Lebesgue, con integrale su tutto lo spazio uguale a 1, \u00e8 la funzione densit\u00e0 di probabilit\u00e0 di una ben definita distribuzione di probabilit\u00e0. Una variabile casuale che possiede densit\u00e0 si dice \"variabile casuale continua\".\nPer le variabili casuali multivariate (o vettoriali) la trattazione formale \u00e8 assolutamente identica: formula_15 si dice assolutamente continua se esiste una funzione a valori reali definita in formula_16, detta densit\u00e0 congiunta, tale che per ogni sottoinsieme \"A\" dello spazio campionario\nEssa conserva tutte le propriet\u00e0 di una densit\u00e0 scalare: \u00e8 una funzione non negativa a integrale unitario su tutto lo spazio. Una propriet\u00e0 importante \u00e8 che se formula_15 \u00e8 assolutamente continua allora lo \u00e8 ogni sua componente; il viceversa invece non vale. La densit\u00e0 di una componente, detta densit\u00e0 marginale, si ottiene con un ragionamento analogo al teorema della probabilit\u00e0 assoluta, cio\u00e8 fissando l'insieme di suoi valori di cui si vuole determinare la probabilit\u00e0 e lasciando libere di variare tutte le altre componenti. Infatti (nel caso bivariato per semplicit\u00e0) l'evento formula_19 \u00e8 l'evento formula_20, dunque\nutilizzando il teorema di Fubini. La densit\u00e0 marginale di formula_1 \u00e8 data dunque da\nLa funzione di densit\u00e0 della variabile casuale normale di media 0\ne varianza 1 (detta \"normale standard\"), di cui a destra \u00e8 riportato il grafico e l'espressione analitica della corrispondente densit\u00e0 nel caso generico (media formula_24 e varianza formula_25).\nUn altro esempio pu\u00f2 essere dato dalla densit\u00e0 di probabilit\u00e0 uniforme su un segmento (0,1). Si pu\u00f2 verificare immediatamente che \u00e8 densit\u00e0 di probabilit\u00e0 facendo l'integrale tra (0,1)."], "concept_B": "Funzione di densit\u00e0 di probabilit\u00e0", "choices": ["False", "True"], "label": 1}
{"wikipedia_passage_concept_A": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_A": "Intervallo di confidenza", "wikipedia_passage_concept_B": ["3587354", "Distribuzione congiunta", "In probabilit\u00e0, date due variabili aleatorie \"X\" e \"Y\", definite sullo stesso spazio di probabilit\u00e0, si definisce la loro distribuzione congiunta come la distribuzione di probabilit\u00e0 associata al vettore formula_1. Nel caso di due sole variabili, si parla di distribuzione bivariata, mentre nel caso di pi\u00f9 variabili si parla di distribuzione multivariata.\nLa funzione di ripartizione di una distribuzione congiunta \u00e8 definita come\no pi\u00f9 generalmente\nNel caso di variabili aleatorie discrete, la densit\u00e0 discreta congiunta (o funzione di massa di probabilit\u00e0 congiunta) \u00e8 data da\nSiccome la densit\u00e0 congiunta \u00e8 anch'essa una densit\u00e0, \u00e8 soddisfatta la seguente equazione:\nNel caso di variabili aleatorie continue, la densit\u00e0 congiunta \u00e8 data da\ndove \"f\"(\"y\"|\"x\") e \"f\"(\"x\"|\"y\") sono le distribuzioni condizionate di Y dato X=x e di X dato Y=y, mentre \"f\"(\"x\") e \"f\"(\"y\") sono le distribuzioni marginali della densit\u00e0 congiunta, rispettivamente per X e Y.\nAnche in questo caso, \u00e8 soddisfatto"], "concept_B": "Distribuzione congiunta", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["4145289", "Distribuzione di probabilit\u00e0 a priori", "Nell'ambito dell'inferenza statistica bayesiana, una distribuzione di probabilit\u00e0 a priori, detta spesso anche distribuzione a priori, di una quantit\u00e0 incognita \"p\" (per esempio, supponiamo \"p\" essere la proporzione di votanti che voteranno per il politico Rossi in un'elezione futura) \u00e8 la distribuzione di probabilit\u00e0 che esprimerebbe l'incertezza di \"p\" prima che i \"dati\" (per esempio, un sondaggio di opinione) siano presi in considerazione. Il proposito \u00e8 di attribuire incertezza piuttosto che casualit\u00e0 a una quantit\u00e0 incerta. La quantit\u00e0 incognita pu\u00f2 essere un parametro o una variabile latente.\nSi applica il teorema di Bayes, moltiplicando la distribuzione a priori per la funzione di verosimiglianza e quindi normalizzando, per ottenere la distribuzione di probabilit\u00e0 a posteriori, la quale \u00e8 la distribuzione condizionata della quantit\u00e0 incerta una volta ottenuti i dati.\nSpesso una distribuzione a priori \u00e8 l'accertamento soggettivo (elicitazione) di una persona esperta. Quando possibile, alcuni sceglieranno una \"distribuzione a priori coniugata\" per rendere pi\u00f9 semplice il calcolo della distribuzione a posteriori.\nI parametri di una distribuzione a priori sono chiamati \"iperparametri\", per distinguerli dai parametri del modello dei dati sottostanti. Per esempio, se si sta usando una distribuzione beta per modellare la distribuzione di un parametro \"p\" di una distribuzione di Bernoulli, allora:\nUna \"distribuzione a priori informativa\" esprime una specifica, definita informazione circa una variabile.\nUn esempio \u00e8 la distribuzione a priori per la temperatura di domattina.\nUn approccio ragionevole \u00e8 costruire la distribuzione a priori come una distribuzione normale con valore atteso uguale alla temperatura mattutina di oggi, con una varianza uguale alla varianza giorno per giorno della temperatura atmosferica, oppure come una distribuzione della temperatura per quel tal giorno dell'anno.\nQuesto esempio ha una propriet\u00e0 in comune con molte distribuzioni a priori, ovvero che la distribuzione a posteriori di un problema (temperatura odierna) diventa la distribuzione a priori per un altro problema (temperatura di domani); l'evidenza preesistente, che \u00e8 gi\u00e0 stata tenuta in conto, \u00e8 parte della distribuzione a priori e come ulteriore evidenza viene accumulata. \nLa distribuzione a priori \u00e8 largamente determinata dall'evidenza piuttosto che da qualche assunzione originale, sempre che l'assunzione originale ammetta la possibilit\u00e0 (ossia sia compatibile) con quello che l'evidenza suggerisce. I termini \"a priori\" e \"a posteriori\" sono generalmente relativi a un dato o un'osservazione specifica.\nUna \"distribuzione a priori non informativa\" esprime vaghezza o informazione a carattere generale circa una variabile.\nIl termine \"non informativa\" pu\u00f2 essere un po' fuorviante; spesso, tale tipo di distribuzione \u00e8 chiamata \"a priori non molto informativa\", oppure \"a priori oggettiva\", cio\u00e8 una distribuzione che non \u00e8 soggettivamente esplicitata.\nLe distribuzioni a priori non informative possono esprimere informazione \"oggettiva\" come ad esempio \"la variabile \u00e8 positiva\" oppure \"la variabile \u00e8 minore di tal limite\".\nLa pi\u00f9 semplice e vecchia regola per determinare una distribuzione a priori non informativa \u00e8 il principio d'indifferenza, il quale assegna a tutti gli eventi uguale probabilit\u00e0.\nIn problemi di stima parametrica, l'uso di una distribuzione a priori non informativa d\u00e0 risultati che sono non troppo differenti dall'analisi statistica convenzionale. Questo accade in quanto la funzione di verosimiglianza fornisce la parte maggiore dell'informazione rispetto a quella fornita dalla distribuzione a priori non informativa nel determinare una distribuzione a posteriori.\nVari tentativi sono stati fatti per trovare probabilit\u00e0 a priori, cio\u00e8 distribuzioni di probabilit\u00e0 in un certo senso logicamente richieste dalla natura di uno stato di incertezza; queste sono soggette a controversia filosofica, con i sostenitori del metodo bayesiano approssimativamente divisi in due scuole: i \"bayesiani oggettivistici\", che credono che tali distribuzioni a priori esistano in molte situazioni, e i \"bayesiani soggettivisti\" che credono che in pratica le distribuzioni a priori rappresentino giudizi di opinione che non possono essere rigorosamente giustificati. Per la maggiore le pi\u00f9 forti argomentazioni a favore della scuola oggettivistica furono date da Edwin T. Jaynes.\nCome esempio di una distribuzione a priori, dovuta a, consideriamo una situazione in cui sappiamo che una pallina \u00e8 nascosta sotto una di tre tazze rovesciate, A, B o C, ma nessun'altra informazione \u00e8 disponibile circa la sua posizione. In questo caso una distribuzione a priori uniforme di formula_1 sembra intuitivamente verosimile la sola scelta ragionevole. Pi\u00f9 formalmente, noi possiamo vedere che il problema rimane lo stesso se scambiamo le lettere identificative \"A\", \"B\" e \"C\" delle tazze. Sarebbe perci\u00f2 strano scegliere una distribuzione a priori per la quale una permutazione delle lettere causerebbe un cambio nella nostra predizione circa la posizione dove la pallina sar\u00e0 trovata; la distribuzione a priori uniforme \u00e8 la sola che preserva questa invarianza. Se si accetta questo principio di invarianza allora si pu\u00f2 vedere che la distribuzione a priori uniforme \u00e8 la distribuzione logicamente corretta che rappresenta questo stato di conoscenza a priori. Si avr\u00e0 notato che questa distribuzione a priori \u00e8 \"oggettiva\" nel senso di essere la scelta corretta per rappresentare un particolare stato di conoscenza, ma non \u00e8 oggettiva nel senso di essere una caratteristica del sistema osservato indipendente dall'osservatore: in realt\u00e0 la pallina esiste sotto una specifica tazza e in questa situazione ha solo senso parlare di probabilit\u00e0 se c'\u00e8 un osservatore con una conoscenza limitata del sistema ossia della posizione della pallina sotto le tazze.\nCome esempio pi\u00f9 controverso, Jaynes pubblic\u00f2 un argomento basato sui gruppi di Lie suggerente che la distribuzione a priori rappresentante in maniera completa l'incertezza sarebbe la distribuzione a priori di Haldane \"p\"(1\u00a0\u2212\u00a0\"p\"). L'esempio fornito da Jaynes \u00e8 quello di trovare un chimico in un laboratorio e di chiedergli di eseguire ripetutamente degli esperimenti di dissoluzione in acqua. La distribuzione a priori di Haldane da prevalentemente la maggiore probabilit\u00e0 agli eventi formula_2 and formula_3, indicando che il campione ogni volta si scioglier\u00e0 oppure no, con uguale probabilit\u00e0. Tuttavia se sono stati osservati campioni non disciogliersi in un esperimento e disciogliersi in un altro, allora questa distribuzione a priori \u00e8 aggiornata alla distribuzione uniforme sull'intervallo [0, 1]. Questo risultato si ottiene applicando il teorema di Bayes all'insieme di dati consistente in un'osservazione di dissoluzione e una di non dissoluzione, usando la distribuzione a priori precedente. sulla base che essa fornisce una distribuzione a posteriori impropria che pone il 100% del contenuto di probabilit\u00e0 sia a \"p\" = 0 o a \"p\" = 1 se un numero finito di esperimenti ha dato lo stesso risultato (ad esempio il discioglimento). La distribuzione a priori di Jeffreys \"p\"(1\u00a0\u2212\u00a0\"p\") \u00e8 perci\u00f2 preferita (\"cfr.\" sotto).\nSe lo spazio parametrico X \u00e8 dotato di una struttura di gruppo naturale che lascia invariato il nostro stato di conoscenza bayesiano, allora la distribuzione a priori pu\u00f2 essere costruita proporzionale alla Misura di Haar. Questo pu\u00f2 essere visto come una generalizzazione del principio di invarianza che giustificava la distribuzione a priori uniforme dell'esempio delle tre tazze visto sopra. Per esempio, in fisica ci si aspetta che un esperimento dia i medesimi risultati indipendentemente dalla scelta dell'origine del sistema di coordinate. Questo induce la struttura gruppale del gruppo delle traslazioni su \"X\", il quale determina la distribuzione di probabilit\u00e0 a priori come una distribuzione a priori impropria costante. Analogamente alcuni sistemi fisici presentano un'invarianza di scala (ossia i risultati sperimentali sono indipendenti dal fatto che, ad esempio, usiamo centimetri o pollici). In tal caso il gruppo di scala \u00e8 la struttura di gruppo naturale, e la corrispondente distribuzione a priori su \"X\" \u00e8 proporzionale a 1/\"x\". Qualche volta risulta importante se viene usata la misura di Haar invariante a sinistra piuttosto che quella invariante a destra. Per esempio, le misure di Haar invarianti a destra e a sinistra sul gruppo affine non sono uguali. Berger (1985, p.\u00a0413) arguisce che la scelta corretta \u00e8 la misura di Haar invariante a destra.\nUn'altra idea, supportata da Edwin T. Jaynes, \u00e8 di usare il principio di massima entropia (MAXENT). La motivazione \u00e8 che l'entropia di Shannon di una distribuzione di probabilit\u00e0 misura l'ammontare di informazione contenuta nella distribuzione. Maggiore \u00e8 l'entropia, minore \u00e8 l'informazione fornita dalla distribuzione. Perci\u00f2, mediante la massimizzazione dell'entropia sopra un adeguato insieme di distribuzioni di probabilit\u00e0 su \"X\", si trova la distribuzione che \u00e8 meno informativa nel senso che essa contiene il minore ammontare di informazione consistente con le costrizioni definite dall'insieme scelto. Per esempio, la distribuzione a priori di massima entropia su uno spazio discreto, dato solo il fatto che la probabilit\u00e0 \u00e8 normalizzata a 1, \u00e8 la distribuzione a priori che assegna uguale probabilit\u00e0 ad ogni stato. Mentre nel caso continuo, la distribuzione a priori di massima entropia con densit\u00e0 normalizzata, media nulla e varianza unitaria, \u00e8 la ben nota distribuzione normale. Il principio di minima entropia incrociata generalizza il principio di massima entropia al caso di \"aggiornamento\" di una distribuzione a priori arbitraria con adeguate costrizioni nel senso di massima entropia.\nUn'idea collegata, la distribuzione a priori di riferimento, fu introdotta da Jos\u00e9-Miguel Bernardo. Qui l'idea \u00e8 di massimizzare il valore atteso della divergenza di Kullback\u2013Leibler della distribuzione a posteriori rispetto alla distribuzione a priori. Questo massimizza l'informazione attesa riguardante \"X\" quando la densit\u00e0 a priori \u00e8 \"p\"(\"x\"); perci\u00f2, in un certo senso, \"p\"(\"x\") \u00e8 la distribuzione a priori \"meno informativa\" riguardo X. La distribuzione a priori di riferimento \u00e8 definita nel limite asintotico, cio\u00e8 si considera il limite delle distribuzioni a priori cos\u00ec ottenute come il numero di dati va all'infinito. Nei problemi multivariati spesso vengono scelte come distribuzioni a priori oggettive le distribuzioni a priori di riferimento, dato che altre scelte (ad esempio la regola di Jeffreys possono portare a distribuzioni a priori dal comportamento problematico.\nDistribuzioni a priori oggettive possono anche essere derivate da altri principi, come le teorie dell'informazione o le teorie della codifica (vedi ad esempio lunghezza di descrizione minima) oppure della statistica frequentista.\nProblemi filosofici legati alle distribuzioni a priori non informative sono associati alla scelta di una metrica appropriata o scala di misurazione. Supponiamo di volere una distribuzione a priori per la valocit\u00e0 di un corridore a noi sconosciuto. Potremmo specificare, diciamo, per la sua velocit\u00e0 una distribuzione a priori di tipo normale, ma in alternativa potremmo specificare una distribuzione a priori normale per il tempo impiegato a percorrere 100 metri, il quale \u00e8 proporzionale al reciproco della prima distribuzione a priori. Queste due distribuzioni a priori sono effettivamente differenti, ma non \u00e8 chiaro quale delle due preferire. Il metodo, spesso sopravvalutato, di trasformazione dei gruppi di Jaynes pu\u00f2 rispondere a tale questione in varie situazioni.\nIn maniera simile, se ci \u00e8 chiesto di stimare una proporzione incognita tra 0 e 1, noi possiamo affermare che tutte le proporzioni sono ugualmente probabili ed usare una distribuzione a priori uniforme. Alternativamente, potremmo dire che tutti gli ordini di grandezza per la proporzione sono ugualmente probabili, e scegliere la distribuzione a priori logaritmica, la quale \u00e8 la distribuzione a priori uniforme sul logaritmo della proporzione. La distribuzione a priori di Jeffreys tenta di risolvere questo problema calcolando una distribuzione a priori che esprime la medesima credenza indipendentemente dalla metrica utilizzata. La distribuzione a priori di Jeffreys per una proporzione incognita \"p\" \u00e8 \"p\"(1\u00a0\u2212\u00a0\"p\"), che differisce da quella raccomandata da Jaynes.\nDistribuzioni a priori basate sulla nozione di probabilit\u00e0 algoritmica vengono impiegate nel campo dell'inferenza induttiva come base induttiva in configurazioni del tutto generali.\nProblemi pratici associati con le distribuzioni a priori non informative includono il requisito che la distribuzione a posteriori sia propria. Le distribuzioni a priori non informative su variabili continue, non limitate sono improprie. Questo non \u00e8 necessariamente un problema se la distribuzione a posteriori \u00e8 propria. Un altro argomento importante \u00e8 quello in cui se una distribuzione a priori non informativa viene usata in maniera regolare, cio\u00e8 con svariati insiemi di dati, allora essa avrebbe buone propriet\u00e0 frequentiste. Normalmente un bayesiano non dovrebbe porsi questo problema, ma potrebbe essere importante farlo in questa situazione. Per esempio, uno potrebbe volere che qualsiasi regola di decisione basata sulla distribuzione a posteriori sia ammissibile sotto la funzionedi perdita adottata. Sfortunatamente, l'ammissibilit\u00e0 \u00e8 difficile da verificare, nonostante vari risultati siano noti (\"cfr.\" ad esempio, Berger and Strawderman, 1996). Il problema \u00e8 particolarmente acuto con i modelli di Bayes gerarchici; le distribuzioni a priori usuali (ad esempio la distribuzione a priori di Jeffreys) possono dare regole di decisione praticamente inammissibili se impiegate ai livelli gerarchici pi\u00f9 elevati.\nSe il teorema di Bayes viene scritto come\nallora \u00e8 chiaro che si otterrebbe il medesimo risultato se tutte le probabilit\u00e0 a priori \"P\"(\"A\") e \"P\"(\"A\") fossero moltiplicate per una data costante; lo stesso sarebbe vero per una variabile casuale continua. Se la sommatoria al denominatore converge, le probabilit\u00e0 a posteriori sommeranno (o integreranno) ancora a 1 anche se i valori della distribuzione a priori non lo fanno, e in tal modo pu\u00f2 solo essere necessario richiedere alle distribuzioni a priori di essere specificate nella proporzione corretta. Spingendo oltre questa idea, in molti casi non \u00e8 neanche richiesto che la somma o l'integrale dei valori della distribuzione a priori sia finita per ottenere risposte significative circa le probabilit\u00e0 a posteriori. Quando questo \u00e8 il caso, la distribuzione a priori \u00e8 chiamata distribuzione a priori impropria. Tuttavia, se la distribuzione a priori \u00e8 impropria, allora non \u00e8 necessario che la distribuzione a posteriori sia propria. Questo \u00e8 chiaro nella situazione in cui l'evento \"B\" \u00e8 indipendente da tutti gli altri eventi \"A\".\nVari statistici usano le distribuzioni a priori improprie come distribuzioni a priori non informative. Per esempio, se hanno bisogno di una distribuzione a priori per la media e la varianza di una variabile casuale, allora essi assumono \"p\"(\"m\",\u00a0\"v\")\u00a0~\u00a01/\"v\" (per \"v\" > 0) il che suggerirebbe che qualsiasi valore per la media \u00e8 \"ugualmente probabile\" e che un valore per la varianza positiva diventa \"meno probabile\" in proporzione inversa al suo valore. Molti autori (Lindley, 1973; De Groot, 1937; Kass and Wasserman, 1996) mettono in guardia contro il pericolo di sovra-interpretare tali distribuzioni a priori poich\u00e9 non sono densit\u00e0 di probabilit\u00e0. La loro sola rilevanza che esse hanno si trova nella distribuzione a posteriori corrispondente, fintanto che questa \u00e8 ben definita per tutte le osservazioni. (La distribuzione a priori di Haldane \u00e8 un tipico controesempio.)\nEsempi di distribuzioni a priori includono:\nIl concetto di probabilit\u00e0 algoritmica fornisce una via per specificare la probabilit\u00e0 delle distribuzioni a priori basata sulla complessit\u00e0 relativa di modelli presi in considerazione e tra loro alternativi."], "concept_A": "Distribuzione di probabilit\u00e0 a priori", "wikipedia_passage_concept_B": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_B": "Probabilit\u00e0 condizionata", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_A": "Boosting", "wikipedia_passage_concept_B": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_B": "Data mining", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["5960768", "Rete neurale feed-forward", "Una rete neurale feed-forward (\"rete neurale con flusso in avanti\") o rete feed-forward \u00e8 una rete neurale artificiale dove le connessioni tra le unit\u00e0 non formano cicli, differenziandosi dalle reti neurali ricorrenti. Questo tipo di rete neurale fu la prima e pi\u00f9 semplice tra quelle messe a punto. In questa rete neurale le informazioni si muovono solo in una direzione, avanti, rispetto a nodi d'ingresso, attraverso nodi nascosti (se esistenti) fino ai nodi d'uscita. Nella rete non ci sono cicli. Le reti feed-forward non hanno memoria di input avvenuti a tempi precedenti, per cui l'output \u00e8 determinato solamente dall'attuale input.\nLa pi\u00f9 semplice rete feed-forward \u00e8 il \"percettrone a singolo strato\" (SLP dall'inglese single layer perceptron), utilizzato verso la fine degli anni '60. Un SLP \u00e8 costituito da un strato in ingresso, seguito direttamente dall'uscita. Ogni unit\u00e0 di ingresso \u00e8 collegata ad ogni unit\u00e0 di uscita. In pratica questo tipo di rete neurale ha un solo strato che effettua l'elaborazione dei dati, e non presenta nodi nascosti, da cui il nome.\nGli SLP sono molto limitati a causa del piccolo numero di connessioni e dell'assenza di gerarchia nelle caratteristiche che la rete pu\u00f2 estrarre dai dati (questo significa che \u00e8 capace di combinare i dati in ingresso una sola volta). Famosa fu la dimostrazione che un SLP non riesce neanche a rappresentare la funzione XOR. Questo risultato, apparso nel 1969, scoraggi\u00f2 i ricercatori e blocc\u00f2 la ricerca sulle reti neurali per diversi anni.\nQuesta classe di reti feedforward si distingue dalla precedente dal fatto che tra lo strato di input e quello di output abbiamo uno o pi\u00f9 strati di neuroni nascosti (hidden layers). Ogni strato ha connessioni entranti dal precedente strato e uscenti in quello successivo, quindi la propagazione del segnale avviene in avanti senza cicli e senza connessioni trasversali.\nQuesto tipo di architettura fornisce alla rete una prospettiva globale in quanto aumentano le interazioni tra neuroni."], "concept_A": "Rete neurale feed-forward", "wikipedia_passage_concept_B": ["480718", "Discesa del gradiente", "In ottimizzazione e analisi numerica il metodo di discesa del gradiente (detto anche \"metodo del gradiente\", \"metodo steepest descent\" o \"metodo di discesa pi\u00f9 ripida\") \u00e8 una tecnica che consente di determinare i punti di massimo e minimo di una funzione di pi\u00f9 variabili.\nIl metodo \u00e8 stato sviluppato - e pubblicato nel 1847 - dal matematico francese Augustin-Louis Cauchy nel tentativo di risolvere il problema di determinare l'orbita di un corpo celeste a partire dalle sue equazioni del moto.\nSi supponga di voler minimizzare la funzioneformula_1 e si scelga come soluzione iniziale il vettore formula_2. Allora\ne, muovendosi in un intorno di formula_4:\nQuesti calcoli mostrano che, per individuare dei punti - \"vicini\" a formula_4 - in corrispondenza dei quali la funzione assuma un valore minore di formula_7, conviene spostarsi lungo direzioni che abbiano la prima e la terza componente formula_8 pi\u00f9 piccole o seconda componente formula_9 pi\u00f9 grande. Inoltre esistono delle direzioni \"preferenziali\" lungo le quali la funzione formula_10 decresce pi\u00f9 velocemente (ad esempio scegliere una coordinata formula_11 pi\u00f9 piccola \u00e8 preferibile, ad esempio, rispetto a far diminuire formula_12).\nLa procedura pu\u00f2 essere iterata partendo da un nuovo punto, ad esempio formula_13, fino ad individuare un minimo per formula_10. L'esempio mostra che una procedura che aggiorni la soluzione in modo iterativo sulla base delle informazioni disponibili \"localmente\" pu\u00f2 portare ad individuare un punto di minimo per la funzione assegnata.\nSi voglia risolvere il seguente problema di ottimizzazione non vincolata nello spazio formula_15-dimensionale formula_16\nLa tecnica di discesa secondo gradiente si basa sul fatto che, per una data funzione formula_18, la direzione di massima discesa in un assegnato punto formula_19 corrisponde a quella determinata dall'opposto del suo gradiente in quel punto formula_20. Questa scelta per la direzione di discesa garantisce che la soluzione tenda a un punto di minimo di formula_10. Il metodo del gradiente prevede dunque di partire da una soluzione iniziale formula_4 scelta arbitrariamente e di procedere iterativamente aggiornandola come\ndove formula_24 corrisponde alla lunghezza del passo di discesa, la cui scelta diventa cruciale nel determinare la velocit\u00e0 con cui l'algoritmo converger\u00e0 alla soluzione richiesta.\nSi parla di metodo \"stazionario\" nel caso in cui si scelga un passo formula_25 costante per ogni formula_26, viceversa il metodo si definisce \"dinamico\". In quest'ultimo caso una scelta conveniente, ma computazionalmente pi\u00f9 onerosa rispetto a un metodo stazionario, consiste nell'ottimizzare, una volta determinata la direzione di discesa formula_27, la funzione di una variabile formula_28 in maniera analitica o in maniera approssimata. Si noti che, a seconda della scelta del passo di discesa, l'algoritmo potr\u00e0 convergere a uno qualsiasi dei minimi della funzione formula_10, sia esso locale o globale.\nLo schema generale per l'ottimizzazione di una funzione formula_18 mediante metodo del gradiente \u00e8 il seguente:\nUn caso particolare di applicazione del metodo del gradiente consiste nella risoluzione di sistemi lineari della forma\ndove formula_33 \u00e8 una matrice simmetrica e definita positiva.\nPer le propriet\u00e0 di formula_33 la soluzione di tale problema \u00e8 equivalente alla procedura di minimizzazione della forma quadratica associata:\nInfatti:\nda cui\nPer la funzione formula_38 si ha che la direzione di massima discesa nel punto formula_39 \u00e8:\ncoincidente con il residuo formula_41 del sistema lineare. Dunque la direzione di discesa scelta a ogni iterazione \u00e8 formula_42.\nInoltre vale la seguente relazione:\nche permette di calcolare analiticamente il passo formula_44 ottimale. Infatti, imponendo la condizione di stazionariet\u00e0\nsi ricava\nL'algoritmo del metodo del gradiente per la risoluzione di sistemi lineari \u00e8 dunque\nIn aritmetica floating point la condizione del ciclo while pu\u00f2 essere valutata verificando che la norma del residuo formula_48 non sia pi\u00f9 piccola di una tolleranza impostata dall'utente.\nIn molti casi \u00e8 possibile accelerare la velocit\u00e0 di convergenza dell'algoritmo migliorando le propriet\u00e0 di condizionamento della matrice formula_33. Si introduca a tal fine una matrice di precondizionamento formula_50 simmetrica e definita positiva.\nLo schema risolutivo in questo caso diventa:\nIl metodo del gradiente coniugato costituisce una variante del metodo del gradiente in cui viene effettuata una scelta diversa, ma particolarmente conveniente nel caso di sistemi lineari simmetrici e definiti positivi, per le direzioni di discesa formula_27. Tale scelta garantisce la convergenza del metodo (in aritmetica esatta) in un numero di iterazioni pari al pi\u00f9 alla dimensione del sistema da risolvere.\n\u00c8 possibile dimostrare che l'errore commesso alla formula_26-esima iterazione del metodo del gradiente soddisfa la seguente stima:\ndove\nformula_56 indica il numero di condizionamento in norma formula_57 di formula_33 e formula_59 \u00e8 la norma indotta da formula_33.\nNel caso precondizionato vale la stessa stima con\nSi riporta un esempio di possibile implementazione del metodo del gradiente nella versione precondizionata compatibile con i linguaggi di programmazione Octave e MATLAB.\nQuando la funzione obiettivo \u00e8 troppo costosa da calcolare ad ogni iterazione, ma pu\u00f2 essere scomposta in una somma di molti addendi (ad esempio, la somma del costo calcolato su ogni singolo record in un dataset), il gradiente pu\u00f2 essere approssimato stocasticamente restringendo la somma su un sottinsieme di addendi ad ogni iterazione, metodo noto come discesa stocastica del gradiente.\nLa discesa del gradiente \u00e8 ampiamente utilizzata in statistica e apprendimento automatico per l'addestramento tramite apprendimento supervisionato di modelli come reti neurali artificiali e modelli grafici. Il principio \u00e8 noto come regola delta, e consiste nel valutare il modello su un input il cui corrispondente output esatto sia noto, e correggere ciascun parametro del modello in una quantit\u00e0 proporzionale (ma di segno opposto) rispetto al suo contributo all'errore sul risultato. L'algoritmo usato nelle reti neurali per implementare questo principio \u00e8 noto come retropropagazione dell'errore, che consiste in un'applicazione della discesa del gradiente, essendo il contributo di ciascun parametro all'errore del modello dato dalla derivata parziale della funzione di perdita rispetto al parametro stesso.\nLa regola, classificabile fra i metodi per l'apprendimento supervisionato, pu\u00f2 essere applicata a reti neurali di tipo \"in avanti\" (cio\u00e8 con propagazione unidirezionale dei segnali, in inglese: \"feedforward\") e permette di calcolare la differenza tra i valori di output che la rete ottiene e quelli che invece dovrebbe apprendere. La regola deve essere applicata a reti che usano unit\u00e0 di output ad attivazione continua e differenziabile ed \u00e8 l'elemento fondamentale dell'algoritmo di retropropagazione dell'errore (\"backpropagation\"), alla base dell'approccio connessionista.\nData una rete \"in avanti\" con le propriet\u00e0 sopra descritte, l'obiettivo che ci si prefigge \u00e8 minimizzare la diversit\u00e0 tra i valori di attivazione delle unit\u00e0 di output formula_62 della rete (ottenuti sommando i segnali provenienti dalle diverse unit\u00e0 di input formula_63 moltiplicati per l'efficacia, o \"pesi sinaptici\" formula_64 delle connessioni in ingresso), e i valori formula_65 della risposta desiderata. Tale diversit\u00e0 viene quantificata attraverso una funzione di perdita. La funzione obiettivo che si vuole minimizzare \u00e8 il valore atteso della perdita (in pratica la perdita media sui dati).\nPer applicare il metodo del gradiente, la funzione di perdita deve essere derivabile rispetto ai valori di output formula_62. Una scelta adatta a problemi di regressione \u00e8 lo scarto quadratico medio tra formula_62 e formula_65 (valutato per tutte le unit\u00e0 di output e per tutti i pattern d'apprendimento); per problemi di classificazione si pu\u00f2 utilizzare la divergenza di Kullback-Leibler o equivalentemente l'entropia incrociata.\nNella fase di addestramento, variando i pesi sinaptici formula_64 (parametri del modello) si pu\u00f2 aumentare o diminuire la funzione obiettivo; la \"prestazione\" della rete sar\u00e0 funzione delle variabili formula_64, e sar\u00e0 massima quando si raggiunge il minimo della funzione obiettivo, il che si ottiene applicando il metodo del gradiente e aggiornando iterativamente i valori dei pesi sinaptici.\nPoich\u00e9 nelle applicazioni pratiche le dimensioni dei modelli e dei relativi dataset usati nell'addestramento sono molto grandi, in pratica si fa generalmente uso della discesa stocastica del gradiente per l'addestramento delle reti neurali e di altri modelli statistici e di apprendimento automatico."], "concept_B": "Discesa del gradiente", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_A": "Data mining", "wikipedia_passage_concept_B": ["2354612", "Clustering gerarchico", "In statistica e apprendimento automatico, il clustering gerarchico \u00e8 un approccio di clustering che mira a costruire una gerarchia di cluster. Le strategie per il clustering gerarchico sono tipicamente di due tipi:\nIl risultato di un clustering gerarchico \u00e8 rappresentato in un dendrogramma.\nPer decidere quali cluster devono essere combinati (approccio agglomerativo) o quale cluster deve essere suddiviso (approccio divisivo) \u00e8 necessario definire una misura di dissimilarit\u00e0 tra cluster. Nella maggior parte dei metodi di clustering gerarchico si fa uso di metriche specifiche che quantificano la distanza tra coppie di elementi e di un criterio di collegamento che specifica la dissimilarit\u00e0 di due insiemi di elementi (cluster) come funzione della distanza a coppie tra elementi nei due insiemi.\nLa scelta di una metrica appropriata influenza la forma dei cluster, poich\u00e9 alcuni elementi possono essere pi\u00f9 \"vicini\" utilizzando una distanza e pi\u00f9 \"lontani\" utilizzandone un'altra. Per esempio, in uno spazio a 2 dimensioni, la distanza tra il punto (1, 1) e l'origine (0, 0) \u00e8 2, formula_1 or 1 se si utilizzando rispettivamente le norme 1, 2 o infinito.\nMetriche comuni sono le seguenti:\nIl criterio di collegamento (\"linkage criterion\") specifica la distanza tra insiemi di elementi come funzione di distanze tra gli elementi negli insiemi.\nDati due insiemi di elementi \"A\" e \"B\" alcuni criteri comunemente utilizzati sono:\ndove \"d\" \u00e8 la metrica prescelta per determinare la similarit\u00e0 tra coppie di elementi."], "concept_B": "Clustering gerarchico", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_B": "Outlier", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["5960762", "Retropropagazione dell'errore", "La retropropagazione dell'errore (in lingua inglese \"backward propagation of errors\", solitamente abbreviato in backpropagation), \u00e8 un algoritmo per l'allenamento delle reti neurali artificiali, usato in combinazione con un metodo di ottimizzazione come per esempio la discesa stocastica del gradiente.\nLa retropropagazione richiede un'uscita desiderata per ogni valore in ingresso per poter calcolare il gradiente della funzione di perdita (funzione di costo). Viene considerato quindi un metodo di apprendimento supervisionato, sebbene venga usato anche in reti non supervisionate come gli autocodificatori o Reti Diabolo.\n\u00c8 una generalizzazione della regola delta di reti feed-forward multistrato, resa possibile usando la regola di catena che iterativamente calcola i gradienti per ogni strato.\nLa retropropagazione richiede che la funzione d'attivazione usata dai neuroni artificiali (o \"nodi\") sia differenziabile.\nUna delle principali difficolt\u00e0 nell'uso della retropropagazione dell'errore \u00e8 il problema noto come scomparsa del gradiente, dovuto all'uso di funzioni di attivazione non lineari che causano una diminuzione esponenziale del valore del gradiente all'aumentare della profondit\u00e0 della rete neurale."], "concept_A": "Retropropagazione dell'errore", "wikipedia_passage_concept_B": ["5960768", "Rete neurale feed-forward", "Una rete neurale feed-forward (\"rete neurale con flusso in avanti\") o rete feed-forward \u00e8 una rete neurale artificiale dove le connessioni tra le unit\u00e0 non formano cicli, differenziandosi dalle reti neurali ricorrenti. Questo tipo di rete neurale fu la prima e pi\u00f9 semplice tra quelle messe a punto. In questa rete neurale le informazioni si muovono solo in una direzione, avanti, rispetto a nodi d'ingresso, attraverso nodi nascosti (se esistenti) fino ai nodi d'uscita. Nella rete non ci sono cicli. Le reti feed-forward non hanno memoria di input avvenuti a tempi precedenti, per cui l'output \u00e8 determinato solamente dall'attuale input.\nLa pi\u00f9 semplice rete feed-forward \u00e8 il \"percettrone a singolo strato\" (SLP dall'inglese single layer perceptron), utilizzato verso la fine degli anni '60. Un SLP \u00e8 costituito da un strato in ingresso, seguito direttamente dall'uscita. Ogni unit\u00e0 di ingresso \u00e8 collegata ad ogni unit\u00e0 di uscita. In pratica questo tipo di rete neurale ha un solo strato che effettua l'elaborazione dei dati, e non presenta nodi nascosti, da cui il nome.\nGli SLP sono molto limitati a causa del piccolo numero di connessioni e dell'assenza di gerarchia nelle caratteristiche che la rete pu\u00f2 estrarre dai dati (questo significa che \u00e8 capace di combinare i dati in ingresso una sola volta). Famosa fu la dimostrazione che un SLP non riesce neanche a rappresentare la funzione XOR. Questo risultato, apparso nel 1969, scoraggi\u00f2 i ricercatori e blocc\u00f2 la ricerca sulle reti neurali per diversi anni.\nQuesta classe di reti feedforward si distingue dalla precedente dal fatto che tra lo strato di input e quello di output abbiamo uno o pi\u00f9 strati di neuroni nascosti (hidden layers). Ogni strato ha connessioni entranti dal precedente strato e uscenti in quello successivo, quindi la propagazione del segnale avviene in avanti senza cicli e senza connessioni trasversali.\nQuesto tipo di architettura fornisce alla rete una prospettiva globale in quanto aumentano le interazioni tra neuroni."], "concept_B": "Rete neurale feed-forward", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_B": "Boosting", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["434228", "Information retrieval", "L'information retrieval (IR) (in italiano \"recupero delle informazioni\") \u00e8 l'insieme delle tecniche utilizzate per gestire la rappresentazione, la memorizzazione, l'organizzazione e l'accesso ad oggetti contenenti informazioni quali documenti, pagine web, cataloghi online e oggetti multimediali. Il termine \u00e8 stato coniato da Calvin Mooers alla fine degli anni quaranta del Novecento ed oggi \u00e8 usato quasi esclusivamente in ambito informatico.\nL'information retrieval \u00e8 un campo interdisciplinare che nasce dall'incrocio di discipline diverse coinvolgendo la psicologia cognitiva, l'architettura informativa, la filosofia (vedi la voce ontologia), il \"design\", il comportamento umano sull'informazione, la linguistica, la semiotica, la scienza dell'informazione e l'informatica. Molte universit\u00e0 e biblioteche pubbliche utilizzano sistemi di information retrieval per fornire accesso a pubblicazioni, libri ed altri documenti.\nLo scopo dell'information retrieval \u00e8 di soddisfare il cosiddetto \"bisogno informativo dell'utente\", ovvero garantire a quest'ultimo, in seguito ad una sua ricerca, i documenti e le informazioni che rispondono alla sua richiesta.\nDue concetti sono di fondamentale importanza per analizzare un sistema di information retrieval: query ed oggetto.\nComunemente, si definisce \"task\" di un sistema di \"information retrieval\" una situazione tipica che un sistema di questo genere deve risolvere.\nNel momento in cui un utente intende usare un qualsiasi sistema di reperimento dell'informazione (per esempio, un motore di ricerca) per acquisire informazioni su un determinato argomento, questi deve tradurre tale necessit\u00e0 in una query; il sistema di information retrieval ha il compito di restituire, a partire da essa, tutti i documenti rilevanti alla richiesta effettuata.\nCi sono molti modi per misurare quanto l'informazione intesa si associa bene all'informazione recuperata.\nLa precisione (in inglese \"precision\") \u00e8 la proporzione di documenti pertinenti fra quelli recuperati:\nNella classificazione binaria la precisione \u00e8 analoga al valore positivo di previsione. \nLa precisione pu\u00f2 anche essere valutata rispetto a un certo valore soglia, indicato con \"P@n\", piuttosto che relativamente a tutti i documenti recuperati: in questo modo, si pu\u00f2 valutare quanti fra i primi \"n\" documenti recuperati sono rilevanti per la query.\nIl significato e l'uso del termine \"precisione\" nel campo dell'information retrieval differiscono quindi dalla definizione di accuratezza e precisione tipiche di altre discipline scientifiche e tecnologiche.\nIl recupero o richiamo (in inglese \"recall\") \u00e8 la proporzione fra il numero di documenti rilevanti recuperati e il numero di tutti i documenti rilevanti disponibili nella collezione considerata:\nNella classificazione binaria, questo valore \u00e8 chiamato sensitivit\u00e0.\nLa misura F (in inglese \"F-measure\") \u00e8 la media armonica pesata fra precisione e recupero. La versione tradizionale, detta anche \"bilanciata\", \u00e8 data da:\nQuesta misura \u00e8 anche detta formula_2, perch\u00e9 sia la precisione che il recupero nella formula precedente hanno appunto il peso 1.\nIn generale, la formula \u00e8:\nAltre due formule comuni sono formula_4, che assegna alla precisione un peso doppio rispetto al recupero, e la formula_5, che al contrario pesa il recupero al doppio della precisione.\nPer concludere con successo una ricerca di informazioni, \u00e8 necessario rappresentare i documenti in qualche modo. C'\u00e8 un certo numero di modelli aventi tale scopo. Essi possono essere classificati secondo due criteri, come mostrato nella figura a destra: in base ad un criterio matematico e in base alle propriet\u00e0 del modello (tradotto da fonte originale logos-verlag.de).\nSistemi di Information Retrieval in campo scientifico\nSoftware di Information Retrieval Open Source\nPrincipali gruppi di ricerca sull'Information Retrieval\nApprofondimenti"], "concept_B": "Information retrieval", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["1555", "Scarto quadratico medio", "Lo scarto quadratico medio (o deviazione standard o scarto tipo) \u00e8 un indice di dispersione statistico, vale a dire una stima della variabilit\u00e0 di una popolazione di dati o di una variabile casuale.\n\u00c8 uno dei modi per esprimere la dispersione dei dati intorno ad un indice di posizione, quale pu\u00f2 essere, ad esempio, la media aritmetica o una sua stima. Ha pertanto la stessa unit\u00e0 di misura dei valori osservati (al contrario della varianza che ha come unit\u00e0 di misura il quadrato dell'unit\u00e0 di misura dei valori di riferimento). In statistica la precisione si pu\u00f2 esprimere come lo scarto quadratico medio.\nIl termine \"\"standard deviation\"\" \u00e8 stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca formula_1 (sigma) che lo rappresenta. Il termine italiano \"deviazione standard\" ne \u00e8 la traduzione pi\u00f9 utilizzata nel linguaggio comune; il termine dell'Ente Nazionale Italiano di Unificazione \u00e8 tuttavia \"scarto tipo\", definito come la radice quadrata positiva della varianza per lo meno fin dal 1984.\nSe non indicato diversamente, lo scarto quadratico medio \u00e8 la radice quadrata della varianza, la quale viene coerentemente rappresentata con il quadrato di sigma (formula_2).\nIn statistica lo scarto quadratico medio di un carattere rilevato su una popolazione di formula_3 unit\u00e0 statistiche si definisce esplicitamente come:\ndove formula_5 \u00e8 la media aritmetica di formula_6.\nFormalmente lo scarto quadratico medio di una variabile pu\u00f2 essere calcolata a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato.\nA partire dallo scarto quadratico medio si definisce anche il coefficiente di variazione o la \"deviazione standard relativa\" come il rapporto tra lo scarto tipo formula_7 e il valore assoluto della media aritmetica della variabile in esame:\nQuesto indice relativo (che viene spesso espresso in termini percentuali) consente di effettuare confronti tra dispersioni di dati di tipo diverso, indipendentemente dalle loro quantit\u00e0 assolute.\nNell'ambito della statistica inferenziale (dove \u00e8 noto solo un campione della popolazione), soprattutto nell'ambito della teoria della stima, a volte si rimpiazza il denominatore formula_3 con formula_10 ottenendo:\nSostanzialmente, poich\u00e9 non \u00e8 nota la media dell'intera popolazione, ma solo una sua stima (la media del campione), bisogna utilizzare formula_10 per ottenere uno stimatore corretto formula_13 della varianza incognita formula_7 di formula_6 sull'intera popolazione a partire dai dati del campione. La sua radice quadrata diviene lo scarto quadratico medio \"corretto\".\nQuesta correzione al denominatore fa s\u00ec che la nuova definizione sia un po' pi\u00f9 grande della precedente, correggendo cos\u00ec la tendenza della precedente a sottostimare le incertezze soprattutto nel caso in cui si lavori con pochi dati (formula_3 piccolo).\nOsserviamo il caso limite di formula_17, cio\u00e8 quando si ha un campione di un solo elemento: la prima definizione d\u00e0 il risultato formula_18, che ovviamente non \u00e8 molto ragionevole nell'ambito della statistica inferenziale, mentre quella \"corretta\" d\u00e0 un risultato non definito del tipo formula_19, rispecchiando cos\u00ec la totale ignoranza inerente all'incertezza su una singola misura. In questo senso, si dice che la statistica non dice nulla sul singolo caso.\nOsserviamo che la differenza tra le due definizioni per campioni molto estesi \u00e8 spesso numericamente insignificante.\nIl calcolo pu\u00f2 essere semplificato come segue:\ncio\u00e8, applicando il tutto alla formula originale:\nSia formula_6 una variabile aleatoria, lo scarto quadratico medio \u00e8 definito come la radice quadrata della varianza di formula_6\nFormalmente lo scarto quadratico medio di una variabile aleatoria pu\u00f2 essere calcolato a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato, cio\u00e8\ndove formula_26 \u00e8 il valore atteso di formula_6.\nIn ambito finanziario, lo scarto quadratico medio viene usato per indicare la variabilit\u00e0 di un'attivit\u00e0 finanziaria e dei suoi payoff (rendimenti). Esso fornisce quindi, implicitamente, una misura della volatilit\u00e0 dell'attivit\u00e0, quindi del suo rischio.\nIn fisica, \u00e8 un ottimo indice dell'errore casuale della misurazione di una grandezza fisica.\nIn ambito sportivo \u00e8 utilizzato per valutare la prestazione di un giocatore di bowling in riferimento ad un certo numero di partite. Il valore trovato non incide sul punteggio ma sintetizza le capacit\u00e0 e i miglioramenti del giocatore.\nIn ingegneria, \u00e8 uno dei parametri da considerare per valutare la capacit\u00e0 di un processo produttivo.\nNelle applicazioni informatiche, \u00e8 a volte conveniente utilizzare la formula\nche consente, con sole tre variabili formula_29, di calcolare lo scarto quadratico medio, oltre che la media, di un flusso di numeri di lunghezza formula_3 senza dover ricorrere ad una memorizzazione degli stessi."], "concept_B": "Scarto quadratico medio", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["1103542", "K-medoids", "\u00e8 un algoritmo di clustering partizionale correlato all'algoritmo K-means. Prevede in input un insieme di n oggetti e un numero k che determina quanti cluster si vogliono in output.\nEntrambi gli algoritmi sono partizionali (suddividendo il dataset in gruppi) ed entrambi cercano di minimizzare l'errore quadratico medio, la distanza tra punti di un cluster e il punto designato per esserne il centro. In K-means il punto \u00e8 \"artificiale\" \u2014 \u00e8 la pura media di tutti i punti nel cluster. Nel K-medoids \u00e8 usato il punto collocato pi\u00f9 centralmente, in questo modo il centro \u00e8 uno dei datapoint attuali. K-medoids \u00e8 pi\u00f9 robusto al rumore e agli outlier rispetto al k-means.\nUn medoid pu\u00f2 essere definito come un oggetto di un cluster la cui dissimilarit\u00e0 media rispetto a tutti gli oggetti nel cluster \u00e8 minima, in questo modo esso sar\u00e0 il punto pi\u00f9 centrale di un dato dataset.\nL'algoritmo di clustering \u00e8 il seguente:\nSi deve clusterizzare il seguente data set di 10 oggetti in 2 cluster, quindi n \u00e8 10 e k \u00e8 2:\nSi inizializzano i k centri.\nAssumiamo che C1=(3,4) e C2=(7,4) siano i nostri medoid iniziali.\nCalcoliamo la distanza cos\u00ec da associare ogni data object al suo medoid pi\u00f9 vicino.\nIniziamo quindi il clustering:\nEssendo (3,4) (2,6) (3,8) e (4,7) punti vicini a c1 essi formeranno un cluster mentre i punti rimanenti ne formeranno un altro.\nIl costo totale sar\u00e0 20.\nIl costo tra 2 punti qualsiasi \u00e8 trovato usando la formula\nformula_1\nIl costo totale \u00e8 la somma dei costi per gli oggetti dal proprio medoid.\nCosto totale= {cost((3,4),(2,6)) + cost((3,4),(3,8)) + cost((3,4),(4,7))} + {cost((7,4),(6,2)) + cost((7,4),(6,4)) + cost((7,4),(7,3)) + cost((7,4),(8,5)) + cost((7,4),(7,6))} = 3 + 4 + 4 + 3 + 1 + 1 + 2 + 2 = 20\nSelezione di un nonmedoid O' in modo casuale.\nAssumiamo O'=(7,3)\nI medoid sono quindi c1(3,4) e O'(7,3).\nSe c1 e O' sono nuovi medoid, si calcola il costo totale usando la formula al passo 1.\nCosto totale = 3 + 4 + 4 + 2 + 2 + 1 + 3 + 3 = 22\nCos\u00ec il costo per cambiare il medoid da c2 a O' sar\u00e0:\nS = Costo totale attuale \u2013 Costo totale precedente = 22 - 20 = 2 > 0\nQuindi cambiare medoid in O' non \u00e8 una buona idea, la scelta precedente \u00e8 stata buona e l'algoritmo termina in questo punto (in quanto non ci sono cambiamenti per i medoid).\nPu\u00f2 accadere che qualche data point possa migrare da un cluster ad un altro, ci\u00f2 dipende dalla vicinanza rispetto al nuovo medoid scelto."], "concept_A": "K-medoids", "wikipedia_passage_concept_B": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_B": "K-means", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["3854", "Scarto interquartile", "In statistica lo scarto interquartile (o differenza interquartile o ampiezza interquartile, in inglese \"interquartile range\" o \"IQR\") \u00e8 la differenza tra il terzo e il primo quartile, ovvero l'ampiezza della fascia di valori che contiene la met\u00e0 \"centrale\" dei valori osservati.\nLo scarto interquartile \u00e8 un indice di dispersione, cio\u00e8 una misura di quanto i valori si allontanino da un valore centrale. Viene utilizzato nel disegno del diagramma box-plot.\nLo scarto interquartile di una variabile aleatoria si ottiene tramite la funzione di ripartizione, come differenza formula_1\nPer una variabile casuale normale formula_2 lo scarto interquartile \u00e8 circa formula_3.\nPer una variabile casuale di Cauchy formula_4 lo scarto interquartile \u00e8 formula_5."], "concept_A": "Scarto interquartile", "wikipedia_passage_concept_B": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_B": "Outlier", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["71808", "Funzione di verosimiglianza", "In statistica, la funzione di verosimiglianza (o funzione di likelihood) \u00e8 una funzione di probabilit\u00e0 condizionata, considerata come funzione del suo \"secondo\" argomento, mantenendo fissato il primo argomento.\nIn gergo colloquiale spesso \"verosimiglianza\" \u00e8 usato come sinonimo di \"probabilit\u00e0\", ma in campo statistico vi \u00e8 una distinzione tecnica precisa. Questo esempio chiarisce la differenza tra i due concetti: una persona potrebbe chiedere \"Se lanciassi una moneta non truccata 100 volte, qual \u00e8 la probabilit\u00e0 che esca testa tutte le volte?\" oppure \"Dato che ho lanciato una moneta 100 volte ed \u00e8 uscita testa 100 volte, qual \u00e8 la verosimiglianza che la moneta sia truccata?\". Scambiare tra loro, nelle due frasi, i termini \"verosimiglianza\" e \"probabilit\u00e0\" sarebbe errato.\nUna distribuzione di probabilit\u00e0 che dipende da un parametro pu\u00f2 essere considerata in due modi differenti:\nFormalmente la funzione di verosimiglianza \u00e8 una funzione:\nSi definisce ancora funzione di verosimiglianza ogni funzione proporzionale a tale probabilit\u00e0. Dunque, la funzione di verosimiglianza per formula_2 \u00e8 la classe delle funzioni:\nper ogni costante formula_4. A causa di ci\u00f2, l'esatto valore di formula_5 non \u00e8 in generale rilevante; ci\u00f2 che \u00e8 importante sono rapporti nella forma: formula_6, invarianti rispetto alla costante di proporzionalit\u00e0.\nA livello interpretativo, l'uso di una funzione di verosimiglianza trae giustificazione dal teorema di Bayes, in base al quale, per due qualsiasi eventi formula_7 e formula_2:\ndove sia formula_10 che formula_11 sono funzioni di verosimiglianza. L'uso di funzioni di verosimiglianza ai fini dell'inferenza statistica costituisce un tratto distintivo dell'inferenza classica, o \"frequentista\"; esso rappresenta inoltre una fondamentale differenza rispetto alla scuola dell'inferenza bayesiana, in quanto lo statistico bayesiano conduce inferenza tramite la probabilit\u00e0 formula_12 nell'espressione sopra.\nAlcune idee relative alla funzione di verosimiglianza sembrano essere state introdotte da T. N. Thiele in un lavoro del 1889. Il primo contributo in cui il concetto di funzione di verosimiglianza \u00e8 esplicitamente formulato \u00e8 tuttavia dovuto a Ronald Fisher in un suo lavoro del 1922. In tale lavoro, Fisher usa inoltre l'espressione metodo della massima verosimiglianza; argomenta inoltre contro il ricorso alla condizionata nella forma formula_13 nell'espressione sopra, da lui ritenuta ingiustificabile a causa dell'elemento di soggettivit\u00e0 introdotto tramite la probabilit\u00e0 \"a priori\" (nel linguaggio che ora \u00e8 proprio della statistica bayesiana) formula_14. \nIl metodo della massima verosimiglianza ha le sue applicazioni pi\u00f9 rilevanti nella prassi come metodo di stima di modelli parametrici. Considerando un insieme di osservazioni formula_15, e una famiglia di funzioni di densit\u00e0 (o di massa, nel caso di distribuzioni discrete), parametrizzate tramite il vettore formula_16:\nla funzione di verosimiglianza associata \u00e8:\nNel caso in cui, come normalmente si ipotizza, gli formula_19 siano indipendenti e identicamente distribuiti, inoltre:\nPoich\u00e9 l'espressione sopra pu\u00f2 risultare scarsamente trattabile, specie nei problemi di massimizzazione collegati al metodo della massima verosimiglianza, spesso risulta preferibile lavorare sul logaritmo della funzione di verosimiglianza, in gergo chiamata \"log-verosimiglianza\":"], "concept_A": "Funzione di verosimiglianza", "wikipedia_passage_concept_B": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_B": "Intervallo di confidenza", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_A": "Macchine a vettori di supporto", "wikipedia_passage_concept_B": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_B": "Outlier", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["5960762", "Retropropagazione dell'errore", "La retropropagazione dell'errore (in lingua inglese \"backward propagation of errors\", solitamente abbreviato in backpropagation), \u00e8 un algoritmo per l'allenamento delle reti neurali artificiali, usato in combinazione con un metodo di ottimizzazione come per esempio la discesa stocastica del gradiente.\nLa retropropagazione richiede un'uscita desiderata per ogni valore in ingresso per poter calcolare il gradiente della funzione di perdita (funzione di costo). Viene considerato quindi un metodo di apprendimento supervisionato, sebbene venga usato anche in reti non supervisionate come gli autocodificatori o Reti Diabolo.\n\u00c8 una generalizzazione della regola delta di reti feed-forward multistrato, resa possibile usando la regola di catena che iterativamente calcola i gradienti per ogni strato.\nLa retropropagazione richiede che la funzione d'attivazione usata dai neuroni artificiali (o \"nodi\") sia differenziabile.\nUna delle principali difficolt\u00e0 nell'uso della retropropagazione dell'errore \u00e8 il problema noto come scomparsa del gradiente, dovuto all'uso di funzioni di attivazione non lineari che causano una diminuzione esponenziale del valore del gradiente all'aumentare della profondit\u00e0 della rete neurale."], "concept_A": "Retropropagazione dell'errore", "wikipedia_passage_concept_B": ["4303005", "Apprendimento ensemble", "L'Apprendimento ensemble (apprendimento d'insieme) in statistica e apprendimento automatico sono una serie di metodi d'insieme che usano modelli multipli per ottenere una migliore prestazione predittiva rispetto ai modelli da cui \u00e8 costituito.\nA differenza dell'Insieme statistico che si ritiene infinito, in meccanica statistica, in un insieme di apprendimento automatico ci si riferisce solo ad un insieme concreto e finito di modelli alternativi.\nNel machine learning l'apprendimento ensemble si divide in tre tecniche fondamentali:"], "concept_B": "Apprendimento ensemble", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["3587354", "Distribuzione congiunta", "In probabilit\u00e0, date due variabili aleatorie \"X\" e \"Y\", definite sullo stesso spazio di probabilit\u00e0, si definisce la loro distribuzione congiunta come la distribuzione di probabilit\u00e0 associata al vettore formula_1. Nel caso di due sole variabili, si parla di distribuzione bivariata, mentre nel caso di pi\u00f9 variabili si parla di distribuzione multivariata.\nLa funzione di ripartizione di una distribuzione congiunta \u00e8 definita come\no pi\u00f9 generalmente\nNel caso di variabili aleatorie discrete, la densit\u00e0 discreta congiunta (o funzione di massa di probabilit\u00e0 congiunta) \u00e8 data da\nSiccome la densit\u00e0 congiunta \u00e8 anch'essa una densit\u00e0, \u00e8 soddisfatta la seguente equazione:\nNel caso di variabili aleatorie continue, la densit\u00e0 congiunta \u00e8 data da\ndove \"f\"(\"y\"|\"x\") e \"f\"(\"x\"|\"y\") sono le distribuzioni condizionate di Y dato X=x e di X dato Y=y, mentre \"f\"(\"x\") e \"f\"(\"y\") sono le distribuzioni marginali della densit\u00e0 congiunta, rispettivamente per X e Y.\nAnche in questo caso, \u00e8 soddisfatto"], "concept_A": "Distribuzione congiunta", "wikipedia_passage_concept_B": ["3678589", "Distribuzione condizionata", "variabili aleatorie \"X\" e \"Y\", la distribuzione condizionata di Y dato X \u00e8 la probabilit\u00e0 di Y quando \u00e8 conosciuto il valore assunto da X. A ogni distribuzione condizionata \u00e8 associato un valore atteso condizionato e una varianza condizionata.\nNel caso di variabili aletorie discrete, la distribuzione condizionata di \"Y\" dato \"X=x\", \u00e8 data da:\n\u00c8 necessario quindi che \"P(X=x)>0\".\nNel caso di variabili aleatorie continue, la densit\u00e0 condizionata di \"Y\" dato \"X=x\" \u00e8 data da\nAnche in questo caso, si deve avere che formula_3.\nSe per due variabili aleatorie \"X\" e \"Y\" si ha che \"P\"(\"Y\" = \"y\" | \"X\" = \"x\") = \"P\"(\"Y\" = \"y\") per ogni \"x\" e \"y\" o, nel caso continuo, \"f\"(\"y\" | \"X=x\") = \"f\"(\"y\") per ogni \"x\" e \"y\", allora le due variabili sono dette indipendenti"], "concept_B": "Distribuzione condizionata", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["43370", "Test di verifica d'ipotesi", "Il test di verifica d'ipotesi si utilizza per verificare la bont\u00e0 di un'ipotesi.\nPer ipotesi \u00e8 da intendersi un'affermazione che ha come oggetto accadimenti nel mondo reale, che si presta ad essere confermata o smentita dai dati osservati sperimentalmente.\nIl metodo con cui si valuta l'attendibilit\u00e0 di un'ipotesi \u00e8 il metodo sperimentale. Quest'ultimo consiste nel determinare le conseguenze di un'ipotesi in termini di eventi osservabili, e di valutare se la realt\u00e0 effettivamente osservata si accorda o meno con l'ipotesi su di essa fatta. \nA tal riguardo si distinguono due ambiti in cui tale attivit\u00e0 si esplica:\nNell'ambito statistico, a seconda delle ipotesi si distingue tra:\nNel primo caso, si tende a pervenire a delle conclusioni pi\u00f9 sicure possibili. Ad esempio volendo provare se in un circuito elettrico passa corrente si inserir\u00e0 una lampadina o un amperometro e si constater\u00e0 l'accensione o l'attivazione dello strumento. In tal caso si perviene con maggior sicurezza alla conclusione. Se la lampadina si accende allora passa corrente; in caso contrario il circuito non \u00e8 predisposto correttamente.\nIn questo ambito, se nel circuito passa corrente la maggior parte delle volte che si inserisce una lampadina questa si accende. In caso contrario il ripetuto inserimento della lampadina dar\u00e0 sempre esito negativo.\nNel secondo caso la situazione \u00e8 modificata in quanto interviene un elemento nuovo, ovvero il caso e/o l'errore di misura. Si supponga di avere una moneta recante due facce contrassegnate con testa e croce. Volendo verificare l'ipotesi di bilanciamento della moneta si eseguono 20 lanci e si contano quelli che danno esito testa. La conseguenza del bilanciamento consiste nell'osservare un valore di teste attorno a 10. Tuttavia anche in ipotesi di bilanciamento non si pu\u00f2 escludere di osservare 20 teste. D'altronde, l'ipotesi di bilanciamento \u00e8 logicamente compatibile con un numero di teste variante da 0 a 20. In tale contesto una qualsiasi decisione in merito all'ipotesi da verificare comporta un rischio di errore. Ad esempio rigettare l'ipotesi di bilanciamento della moneta avendo osservato 20 teste su 20 lanci comporta il rischio di prendere una decisione errata. \nNel procedere alla verifica dell'ipotesi di bilanciamento della moneta, si ricorre a una variabile casuale X. Tale variabile casuale X \u00e8 una variabile aleatoria discreta con distribuzione binomiale B(20; 0,5), dove 20 indica il numero di lanci e 0,5 la probabilit\u00e0 che si verifichi l'evento \"testa\".\nIl risultato sperimentale si deve quindi confrontare con tale distribuzione: quanto \u00e8 distante tale risultato dal valore medio della distribuzione B(20; 0,5)? Per rispondere alla domanda si deve individuare un valore caratteristico della distribuzione B(20; 0,5). Nel nostro caso tale valore caratteristico \u00e8 il valore medio 20/2 = 10. Per valutare la distanza tra il valore sperimentale e quello atteso si valuta la probabilit\u00e0 di ottenere un valore sperimentale lontano dal valore medio di B(20; 0,5), oss\u00eca nel caso che dal nostro esperimento risulti X=15 (15 teste dopo 20 lanci), si calcola P{|X-10|>=15-10} quindi P{X<=5 oppure X>=15}=0,041.\nQuindi, usando una moneta ben bilanciata, la probabilit\u00e0 di ottenere un numero di teste X >= 15 (oppure X <= 5) dopo 20 lanci \u00e8 pari a 0,041 ossia al 4,1%. Giudicando bassa tale probabilit\u00e0 si rifiuter\u00e0 l'ipotesi di bilanciamento della moneta in esame, accettando quindi il rischio del 4,1% di compiere un errore nel rifiutarla. Di solito, il valore della probabilit\u00e0 adottato per rifiutare l'ipotesi nulla \u00e8 < 0,05. Tale valore \u00e8 detto livello di significativit\u00e0 ed \u00e8 definibile come segue: il livello di significativit\u00e0 sotto l'ipotesi nulla \u00e8 la probabilit\u00e0 di cadere nella zona di rifiuto quando l'ipotesi nulla \u00e8 vera. Tale livello di significativit\u00e0 si indica convenzionalmente con \u03b1. Il livello di significativit\u00e0 osservato \u03b1 del test per il quale si rifiuterebbe l'ipotesi nulla \u00e8 detto valore-p (\"p-value\"). Riprendendo l'esempio sopra riportato il valore-p \u00e8 pari a 0,041.\nAdottando nell'esempio \u03b1 = 0,05, si rifiuter\u00e0 l'ipotesi se P{|X-10|>=x}<0,05. Tale condizione si raggiunge appunto se X<6 oppure X>14. Tale insieme di valori si definisce convenzionalmente come regione di rifiuto. Viceversa l'insieme { 6,7\u202614} si definisce regione di accettazione. In questo modo si \u00e8 costruita una regola di comportamento per verificare l'ipotesi di bilanciamento della moneta. Tale regola definisce il test statistico.\nIn termini tecnici l'ipotesi da verificare si chiama ipotesi nulla e si indica con \"H\", mentre l'ipotesi alternativa con \"H\". Nel caso della moneta, se \"p\" \u00e8 la probabilit\u00e0 di ottenere testa in un lancio la verifica di ipotesi si traduce nel seguente sistema:\nCome gi\u00e0 osservato, il modo di condurre un test statistico comporta un rischio di errore. Nella pratica statistica si individuano due tipi di errori:\nTornando all'esempio della moneta in cui la regione di accettazione \u00e8 data dall'insieme di valori {6..14}, la probabilit\u00e0 di rifiutare H quando \u00e8 vera \u00e8 stato calcolato pari a 0,041.Tale probabilit\u00e0 rappresenta il rischio di incorrere in un errore di primo tipo e si indica con \u03b1. Per valutare la probabilit\u00e0 di un errore di secondo tipo \u00e8 necessario specificare un valore di \"p\" in caso di verit\u00e0 di H. Si supponga che p=0,80, in tal caso la distribuzione di X \u00e8 una B(20;0,80)\nCon tale distribuzione di probabilit\u00e0, l'errore di tipo \"2\" si calcola sommando le probabilit\u00e0 relative ai valori di X della zona di accettazione, ci\u00f2 supponendo H vera. Si trova quindi che la probabilit\u00e0 cercata \u00e8 pari a circa 0,20. Tale probabilit\u00e0 quantifica il rischio di incorrere nell'errore di tipo \"2.\" e si indica convenzionalmente con \u03b2. La quantit\u00e0 1-\u03b2 si chiama \"potenza del test\" ed esprime quindi la capacit\u00e0 di un test statistico di riconoscere la falsit\u00e0 di H quando questa \u00e8 effettivamente falsa. La potenza del test trova applicazione nella pratica statistica in fase di pianificazione di un esperimento."], "concept_A": "Test di verifica d'ipotesi", "wikipedia_passage_concept_B": ["4314", "Teorema di Bayes", "Il teorema di Bayes (conosciuto anche come formula di Bayes o teorema della probabilit\u00e0 delle cause), proposto da Thomas Bayes, deriva da due teoremi fondamentali delle probabilit\u00e0:\nil teorema della probabilit\u00e0 composta e il teorema della probabilit\u00e0 assoluta. Viene impiegato per calcolare la probabilit\u00e0 di una causa che ha scatenato l'evento verificato. Per esempio si pu\u00f2 calcolare la probabilit\u00e0 che una certa persona soffra della malattia per cui ha eseguito il test diagnostico (nel caso in cui questo sia risultato negativo) o viceversa non sia affetta da tale malattia (nel caso in cui il test sia risultato positivo), conoscendo la frequenza con cui si presenta la malattia e la percentuale di efficacia del test diagnostico.\nFormalmente il teorema di Bayes \u00e8 valido in tutte le interpretazioni della probabilit\u00e0. In ogni caso, l'importanza di questo teorema per la statistica \u00e8 tale che la divisione tra le due scuole (statistica bayesiana e statistica frequentista) nasce dall'interpretazione che si d\u00e0 al teorema stesso.\nConsiderando un insieme di alternative formula_1 che partizionano lo spazio degli eventi formula_2 (ossia formula_3 e formula_4) si trova la seguente espressione per la probabilit\u00e0 condizionata:\nDove:\nIntuitivamente, il teorema descrive il modo in cui le opinioni nell'osservare A siano arricchite dall'aver osservato l'evento E.\nSi consideri una scuola che ha il 60% di studenti maschi e il 40% di studentesse femmine.\nLe studentesse indossano in egual numero gonne o pantaloni; gli studenti indossano tutti quanti i pantaloni. Un osservatore, da lontano, nota un generico studente coi pantaloni. Qual \u00e8 la probabilit\u00e0 che quello studente sia una femmina?\nIl problema pu\u00f2 essere risolto con il teorema di Bayes, ponendo l'evento A che lo studente osservato sia femmina, e l'evento B che lo studente osservato indossi i pantaloni. Per calcolare P(A|B), dovremo sapere:\nCi\u00f2 detto, possiamo applicare il teorema:\nC'\u00e8 pertanto 1/4 di probabilit\u00e0 che lo studente sia femmina cio\u00e8 25%.\nIl teorema deriva dalla definizione di probabilit\u00e0 condizionata. La probabilit\u00e0 di un evento \"A\", noto un evento \"B\", risulta:\nIn modo analogo, la probabilit\u00e0 di un evento \"B\" noto un evento \"A\":\nPertanto:\nSostituendo nella prima uguaglianza, si trova il teorema di Bayes:\nSi supponga di partecipare a un gioco a premi, in cui si pu\u00f2 scegliere fra tre porte: dietro una di esse c'\u00e8 un'automobile, dietro le altre, due capre. Si sceglie una porta, diciamo la numero 1, e il conduttore del gioco a premi, che sa cosa si nasconde dietro ciascuna porta, ne apre un'altra, diciamo la 3, rivelando una capra. Quindi domanda: \u00abVorresti scegliere la numero 2?\u00bb Ti conviene cambiare la tua scelta originale?\nSi potrebbe pensare che, con due porte chiuse, si abbia una probabilit\u00e0 50:50 per ognuna, e che quindi non ci sia motivo di cambiare porta. Non \u00e8 questo il caso. Chiamiamo l'evento che la macchina si trovi dietro una certa porta rispettivamente A, A e A.\nAll'inizio, \u00e8 ovvio che:\nformula_11\nCome detto prima, la porta scelta \u00e8 la numero 1. Chiamiamo B l'evento \"il presentatore apre la porta 3\". Ora:\nLa probabilit\u00e0 a priori per l'evento B \u00e8 del 50%, infatti:\nDa cui:\nDa ci\u00f2 \u00e8 evidente che si deve sempre cambiare con la porta 2.\nI filtri bayesiani sono uno strumento utilizzato per combattere lo spam che deve il suo funzionamento proprio al teorema di Bayes. Un filtro bayesiano fa uso di un classificatore bayesiano per riconoscere se una certa sequenza di simboli (come una parola) si presenta spesso nei messaggi di spam, quindi applica l'inferenza bayesiana per calcolare la probabilit\u00e0 che un determinato messaggio sia spam.\nIl teorema si chiama cos\u00ec in onore del reverendo Thomas Bayes (1702\u20131761), il quale studi\u00f2 come calcolare una distribuzione per il parametro di una distribuzione binomiale. Un suo amico, Richard Price, pubblic\u00f2 il lavoro nel 1763, dopo la morte di Bayes, nell'articolo \"Essay Towards Solving a Problem in the Doctrine of Chances\". \nAlcuni anni dopo (nel 1774) viene formulato da Pierre Simon Laplace che probabilmente non era a conoscenza del lavoro di Bayes.\nUna ricerca da parte di un professore di statistica (Stigler, 1982) sembrerebbe suggerire che il teorema di Bayes sia stato scoperto da Nicholas Saunderson anni prima di Bayes."], "concept_B": "Teorema di Bayes", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["100003", "Albero di decisione", "Nella teoria delle decisioni (per esempio nella gestione dei rischi), un albero di decisione \u00e8 un grafo di decisioni e delle loro possibili conseguenze, (incluso i relativi costi, risorse e rischi) utilizzato per creare un 'piano di azioni' (\"plan\") mirato ad uno scopo (\"goal\"). Un albero di decisione \u00e8 costruito al fine di supportare l'azione decisionale (\"decision making\").\nNel machine learning un albero di decisione \u00e8 un modello predittivo, dove ogni nodo interno rappresenta una variabile, un arco verso un nodo figlio rappresenta un possibile valore per quella propriet\u00e0 e una foglia il valore predetto per la variabile obiettivo a partire dai valori delle altre propriet\u00e0, che nell'albero \u00e8 rappresentato dal cammino (\"path\") dal nodo radice (\"root\") al nodo foglia.\nNormalmente un albero di decisione viene costruito utilizzando tecniche di apprendimento a partire dall'insieme dei dati iniziali (\"data set\"), il quale pu\u00f2 essere diviso in due sottoinsiemi: il \"training set\" sulla base del quale si crea la struttura dell'albero e il \"test set\" che viene utilizzato per testare l'accuratezza del modello predittivo cos\u00ec creato.\nNel data mining un albero di decisione viene utilizzato per classificare le istanze di grandi quantit\u00e0 di dati (per questo viene anche chiamato albero di classificazione). In questo ambito un albero di decisione descrive una struttura ad albero dove i nodi foglia rappresentano le classificazioni e le ramificazioni l'insieme delle propriet\u00e0 che portano a quelle classificazioni. Di conseguenza ogni nodo interno risulta essere una macro-classe costituita dall'unione delle classi associate ai suoi nodi figli.\nIl predicato che si associa ad ogni nodo interno (sulla base del quale avviene la ripartizione dei dati) \u00e8 chiamato \"condizione di split\".\nIn molte situazioni \u00e8 utile definire un criterio di arresto (\"halting\"), o anche \"criterio di potatura\" (\"pruning\") al fine di determinarne la profondit\u00e0 massima. Questo perch\u00e9 il crescere della profondit\u00e0 di un albero (ovvero della sua dimensione) non influisce direttamente sulla bont\u00e0 del modello. Infatti, una crescita eccessiva della dimensione dell'albero potrebbe portare solo ad aumento sproporzionato della complessit\u00e0 computazionale rispetto ai benefici riguardanti l'accuratezza delle previsioni/classificazioni.\nUna sua evoluzione \u00e8 la tecnica foresta casuale (\"random forest\").\nI parametri pi\u00f9 largamente usati per le condizioni di split sono:\nformula_1\nL'indice di Gini raggiunge il suo minimo (zero) quando il nodo appartiene ad una singola categoria. \nformula_2\nIn entrambe le formule \"f\" rappresenta la frequenza del valore \"j\" nel nodo \"i\".\nL'indice di Gini e la variazione di entropia sono i parametri che vengono usualmente utilizzati per guidare la costruzione dell'albero, mentre la valutazione del tasso di errore nella classificazione viene utilizzato per effettuare una ottimizzazione dell'albero nota come processo di \"pruning\" (\"potatura\" dei nodi superflui). Poich\u00e9, in generale, in un buon albero di decisione i nodi foglia dovrebbero essere il pi\u00f9 possibile \"puri\" (ovvero contenere solo istanze di dati che appartengono ad una sola classe), un'ottimizzazione dell'albero consiste nel cercare di minimizzare il livello di entropia man mano che si scende dalla radice verso le foglie. In tal senso, la valutazione dell'entropia determina quali sono, fra le varie scelte a disposizione, le condizioni di split ottimali per l'albero di classificazione."], "concept_A": "Albero di decisione", "wikipedia_passage_concept_B": ["3645149", "Regole di associazione", "Nel data mining, le regole di associazione sono uno dei metodi per estrarre relazioni nascoste tra i dati.\nAgrawal et al. introdussero le regole di associazione per la scoperta di regolarit\u00e0 all'interno delle transazioni registrate nelle vendite dei supermercati. Per esempio, la regola formula_1 individuata nell'analisi degli scontrini di un supermercato indica che il se il cliente compra insieme cipolle e patate \u00e8 probabile che acquisti anche della carne per hamburger. Tale informazione pu\u00f2 essere utilizzata come base per le decisioni riguardanti le attivit\u00e0 di marketing, come ad esempio le offerte promozionali o il posizionamento dei prodotti negli scaffali.\nLe regole di associazione sono anche usate in molte altre aree, quali il Web mining, la scoperta di anomalie e la bioinformatica.\nIl concetto di regola di associazione divenne popolare a causa di un articolo del 1993 di Agrawal et al.. Secondo Google Scholar esso possiede pi\u00f9 di 9500 citazioni (Settembre 2010) ed \u00e8 uno degli articoli pi\u00f9 citati nel campo del data mining. Tuttavia \u00e8 possibile che quella che viene chiamata come \"regola di associazione\" sia simile a un approccio di data mining presentato nel 1966 e sviluppato da H\u00e1jek et al..\nSeguendo la definizione originale di Agrawal et al. il problema della scoperta di regole di associazione \u00e8 rappresentato come segue.\nConsideriamo l'insieme di formula_2 attributi binari (\"oggetti\" o \"item\") formula_3 e l'insieme di transazioni (\"database\")formula_4. Ciascuna transazione appartenente a formula_5 possiede un codice identificativo (ID) e contiene un sottoinsieme degli oggetti contenuti in formula_6. Una \"regola\" \u00e8 definita come un'implicazione nella forma formula_7 dove formula_8\ne formula_9. L'insieme di oggetti (o \"itemsets\") formula_10 e formula_11 vengono chiamati rispettivamente \"antecendente\" e \"conseguente\" della regola.\nPer illustrare questo concetto, \u00e8 possibile usare un esempio giocattolo riguardante un supermercato.\nL'insieme di oggetti \u00e8 formula_12 e il database contenente gli oggetti \u00e8 rappresentato nella tabella a destra, dove 1 indica la presenza di un oggetto in una transazione e 0 l'assenza. Un esempio di regola di associazione potrebbe essere: formula_13. Essa indica che se il cliente acquista pane e burro, comprer\u00e0 anche il latte.\nAttenzione: questo esempio \u00e8 estremamente piccolo. In un'applicazione reale una regola necessita di un supporto di diverse centinaia di transazioni perch\u00e9 sia considerata statisticamente significativa e il database deve contenere migliaia (o milioni) di transazioni."], "concept_B": "Regole di associazione", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_A": "Foresta casuale", "wikipedia_passage_concept_B": ["19505", "Sistema esperto", "Un sistema esperto \u00e8 un programma che cerca di riprodurre le prestazioni di una o pi\u00f9 persone esperte in un determinato campo di attivit\u00e0, ed \u00e8 un'applicazione o una branca dell'intelligenza artificiale.\nI programmi utilizzati dai sistemi esperti sono in grado di porre in atto procedure di inferenza adeguate alla risoluzione di problemi particolarmente complessi, a cui potrebbe, se posto in una dimensione umana, porre rimedio solo un esperto del settore disciplinare in cui rientra la questione da risolvere. Ci\u00f2 implica che tale sistema possa avvalersi in modo risoluto e autorevole delle istanze inferenziali che soggiacciono al corretto funzionamento del programma, cosicch\u00e9 sia capace di superare le incertezze e le difficolt\u00e0 su cui volge la propria attivit\u00e0.\nI sistemi esperti si differenziano dunque da altri programmi simili, in quanto, facendo riferimento a tecnologie elaborate in funzione dell'intelligenza artificiale, sono sempre in grado di esibire i passaggi logici che soggiacciono alle loro decisioni: proposito che, ad esempio, non \u00e8 attuabile da parte della mente umana.\nIl sistema esperto si compone principalmente di tre sezioni: \nQueste informazioni sono piuttosto generiche, ed estremamente flessibili per ci\u00f2 che concerne la designazione di un programma con una tale definizione. Non esistono infatti sistemi capaci per davvero di soddisfare nella sua interezza il tipo di conoscenza che dovrebbe caratterizzare un sistema di tale fatta. Difatti, nella maggior parte dei programmi, le componenti che presiedono alle procedure di inferenza, non riescono ad attenere il rigore connaturato ad un algoritmo, in quanto nelle situazioni altamente complicate sarebbe troppo dispendioso analizzare ogni possibilit\u00e0; si ricorre cos\u00ec allo stratagemma dell'euristica, che, tramite ragionamenti approssimativi (\"fuzzy logic\"), sacrifica la sicurezza dell'algoritmo per giungere a risultati altamente probabili, ma comunque fallibili.\nI sistemi esperti si dividono in due categorie principali.\nI sistemi esperti basati su regole sono dei programmi composti da regole nella forma codice_1 (se condizione, allora azione). Dati una serie di fatti, i sistemi esperti, grazie alle regole di cui sono composti, riescono a dedurre nuovi fatti.\nPer esempio, supponiamo di avere un problema di salute, forniamo al sistema esperto i seguenti fatti:\nil sistema esperto assume i fatti e sceglie una regola cos\u00ec formata:\nEsempi di sistemi a regole sono Jess e CLIPS.\nUn sistema esperto basato su alberi, dato un insieme di dati ed alcune deduzioni, creerebbe un albero che classificherebbe i vari dati. Nuovi dati verrebbero analizzati dall'albero e il nodo di arrivo rappresenterebbe la deduzione.\n\u00c8 da notare che un sistema esperto non \u00e8 \"intelligente\" nel senso comune della parola, ossia in modo creativo. Le deduzioni di un sistema esperto non possono uscire dall'insieme di nozioni immesse inizialmente e dalle loro conseguenze. Ci\u00f2 che li rende utili \u00e8 che, come i calcolatori elettronici, possono maneggiare una gran quantit\u00e0 di dati molto velocemente e tenere quindi conto di una miriade di regole e dettagli che un esperto umano pu\u00f2 ignorare, tralasciare o dimenticare."], "concept_B": "Sistema esperto", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_A": "Boosting", "wikipedia_passage_concept_B": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_B": "Macchine a vettori di supporto", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["161098", "Rapporto segnale/rumore", "In telecomunicazioni ed elettronica il rapporto segnale-rumore, spesso abbreviato con la sigla inglese SNR (\"Signal to Noise Ratio\") o S/N anche nell'uso italiano, \u00e8 una grandezza numerica che mette in relazione la potenza del segnale utile rispetto a quella del rumore in un qualsiasi sistema di acquisizione, elaborazione o trasmissione dell'informazione.\nIl rapporto segnale-rumore \u00e8 un numero puro o adimensionale dato dal rapporto fra due grandezze omogenee che esprime quanto il segnale sia pi\u00f9 potente del rumore nel sistema considerato. \u00c8 formalmente espresso dalla relazione:\ndove formula_2 \u00e8 la potenza del segnale utile e formula_3 la potenza totale del rumore presente nel sistema, grandezze queste solitamente espresse in watt o dBm.\nPu\u00f2 essere applicato indifferentemente a sistemi di natura ottica, elettronica, ecc. e si tratta di una grandezza fondamentale nell'ambito del trattamento dei segnali e della teoria dell'informazione. Un qualsiasi sistema che debba trasportare o trattare informazioni \u00e8 infatti affetto da rumore, primo fra tutti il rumore termico, che \u00e8 un fattore non ideale della trasmissione ovvero del tutto indesiderato che corrompe il segnale utile spesso sommandovisi in maniera additiva: tanto maggiore \u00e8 la potenza di rumore rispetto alla potenza del segnale utile tanto minore \u00e8 la qualit\u00e0 della comunicazione. \u00c8 logico dunque aspettarsi che l'SNR sia un parametro di qualit\u00e0 che si cerca o si tenda in qualche modo a massimizzare o preservare il pi\u00f9 possibile.\nEsso \u00e8 dunque un parametro di merito molto importante per il dimensionamento e il corretto funzionamento del sistemi di telecomunicazioni in quanto strettamente collegato alla capacit\u00e0 del sistema ricevente di rilevare il flusso informativo originario senza incorrere in alterazioni dovute a distorsione ed errori dovuti essenzialmente all'azione disturbante del rumore. Pi\u00f9 basso \u00e8 l'SNR, pi\u00f9 sar\u00e0 difficoltosa la decodifica del segnale ovvero pi\u00f9 alta sar\u00e0 la probabilit\u00e0 di errore e quindi anche il BER nelle trasmissioni digitali.\nNel caso di trasmissioni analogiche una diminuzione di SNR determina un deperimento graduale della qualit\u00e0 del segnale ricevuto (si pensi ad esempio a una radio FM che riceve male o a un televisore in cui compaiono audio o video disturbati: tipici casi di SNR basso); per le trasmissioni analogiche tuttavia \u00e8 l'utente finale a stabilire una soglia di fruibilit\u00e0 del sistema.\nNel caso di trasmissioni digitali, invece, esiste una soglia minima di SNR sotto la quale il sistema non \u00e8 in grado di funzionare (si pensi alla televisione digitale satellitare: o si vede bene o non si vede del tutto); l'errore di decisione/decodifica pu\u00f2 essere tale da far decidere per un simbolo piuttosto che un altro; tuttavia grazie alle moderne tecniche di modulazione e di protezione dei dati tramite codifica di canale tale soglia \u00e8 piuttosto bassa, al di sotto di quella che servirebbe per ottenere prestazioni analoghe su sistemi analogici.\nLa soglia minima di SNR \u00e8 determinata dalla tecnologia dell'apparato ricevente; in fase di progetto di un sistema di telecomunicazioni il primo obiettivo \u00e8 quindi quello di far pervenire al ricevitore un SNR sufficientemente elevato.\nIn Alta Fedelt\u00e0 il rapporto segnale-rumore \u00e8 uno dei parametri di merito fondamentali, anche se non l'unico, per la valutazione delle prestazioni di un impianto per quello che concerne la pulizia del suono prodotto, tanto che i preamplificatori di fascia alta sono realizzati in due distinti telai, uno contenente il circuito amplificatore, l'altro il circuito alimentatore.\nTale rapporto \u00e8 legato inoltre alla velocit\u00e0 di trasmissione sul canale tramite il Teorema di Shannon-Hartley.\nIl rapporto segnale-rumore decade con la distanza percorsa dal segnale sul canale o mezzo trasmissivo in virt\u00f9 dell'attenuazione della potenza del segnale utile cos\u00ec che a una certa distanza dal trasmettitore rimane solo rumore. Tale decadimento fa decadere a sua volta la velocit\u00e0 di trasmissione con la distanza sul canale stesso.\nEsiste inoltre un parametro, il SINAD, concettualmente molto simile al SNR, e che insieme al rumore include anche la distorsione generata dal circuito: esso d\u00e0 una valutazione pi\u00f9 precisa della degradazione assunta da un segnale per effetto delle non idealit\u00e0 delle apparecchiature che attraversa, in particolare degli ADC e dei DAC, che possono in alcuni casi essere parecchio distorcenti.\nIn molti sistemi elettronici e di telecomunicazioni per ottenere una massimizzazione del rapporto segnale-rumore si usa comunemente un filtro adattato."], "concept_A": "Rapporto segnale/rumore", "wikipedia_passage_concept_B": ["1555", "Scarto quadratico medio", "Lo scarto quadratico medio (o deviazione standard o scarto tipo) \u00e8 un indice di dispersione statistico, vale a dire una stima della variabilit\u00e0 di una popolazione di dati o di una variabile casuale.\n\u00c8 uno dei modi per esprimere la dispersione dei dati intorno ad un indice di posizione, quale pu\u00f2 essere, ad esempio, la media aritmetica o una sua stima. Ha pertanto la stessa unit\u00e0 di misura dei valori osservati (al contrario della varianza che ha come unit\u00e0 di misura il quadrato dell'unit\u00e0 di misura dei valori di riferimento). In statistica la precisione si pu\u00f2 esprimere come lo scarto quadratico medio.\nIl termine \"\"standard deviation\"\" \u00e8 stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca formula_1 (sigma) che lo rappresenta. Il termine italiano \"deviazione standard\" ne \u00e8 la traduzione pi\u00f9 utilizzata nel linguaggio comune; il termine dell'Ente Nazionale Italiano di Unificazione \u00e8 tuttavia \"scarto tipo\", definito come la radice quadrata positiva della varianza per lo meno fin dal 1984.\nSe non indicato diversamente, lo scarto quadratico medio \u00e8 la radice quadrata della varianza, la quale viene coerentemente rappresentata con il quadrato di sigma (formula_2).\nIn statistica lo scarto quadratico medio di un carattere rilevato su una popolazione di formula_3 unit\u00e0 statistiche si definisce esplicitamente come:\ndove formula_5 \u00e8 la media aritmetica di formula_6.\nFormalmente lo scarto quadratico medio di una variabile pu\u00f2 essere calcolata a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato.\nA partire dallo scarto quadratico medio si definisce anche il coefficiente di variazione o la \"deviazione standard relativa\" come il rapporto tra lo scarto tipo formula_7 e il valore assoluto della media aritmetica della variabile in esame:\nQuesto indice relativo (che viene spesso espresso in termini percentuali) consente di effettuare confronti tra dispersioni di dati di tipo diverso, indipendentemente dalle loro quantit\u00e0 assolute.\nNell'ambito della statistica inferenziale (dove \u00e8 noto solo un campione della popolazione), soprattutto nell'ambito della teoria della stima, a volte si rimpiazza il denominatore formula_3 con formula_10 ottenendo:\nSostanzialmente, poich\u00e9 non \u00e8 nota la media dell'intera popolazione, ma solo una sua stima (la media del campione), bisogna utilizzare formula_10 per ottenere uno stimatore corretto formula_13 della varianza incognita formula_7 di formula_6 sull'intera popolazione a partire dai dati del campione. La sua radice quadrata diviene lo scarto quadratico medio \"corretto\".\nQuesta correzione al denominatore fa s\u00ec che la nuova definizione sia un po' pi\u00f9 grande della precedente, correggendo cos\u00ec la tendenza della precedente a sottostimare le incertezze soprattutto nel caso in cui si lavori con pochi dati (formula_3 piccolo).\nOsserviamo il caso limite di formula_17, cio\u00e8 quando si ha un campione di un solo elemento: la prima definizione d\u00e0 il risultato formula_18, che ovviamente non \u00e8 molto ragionevole nell'ambito della statistica inferenziale, mentre quella \"corretta\" d\u00e0 un risultato non definito del tipo formula_19, rispecchiando cos\u00ec la totale ignoranza inerente all'incertezza su una singola misura. In questo senso, si dice che la statistica non dice nulla sul singolo caso.\nOsserviamo che la differenza tra le due definizioni per campioni molto estesi \u00e8 spesso numericamente insignificante.\nIl calcolo pu\u00f2 essere semplificato come segue:\ncio\u00e8, applicando il tutto alla formula originale:\nSia formula_6 una variabile aleatoria, lo scarto quadratico medio \u00e8 definito come la radice quadrata della varianza di formula_6\nFormalmente lo scarto quadratico medio di una variabile aleatoria pu\u00f2 essere calcolato a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato, cio\u00e8\ndove formula_26 \u00e8 il valore atteso di formula_6.\nIn ambito finanziario, lo scarto quadratico medio viene usato per indicare la variabilit\u00e0 di un'attivit\u00e0 finanziaria e dei suoi payoff (rendimenti). Esso fornisce quindi, implicitamente, una misura della volatilit\u00e0 dell'attivit\u00e0, quindi del suo rischio.\nIn fisica, \u00e8 un ottimo indice dell'errore casuale della misurazione di una grandezza fisica.\nIn ambito sportivo \u00e8 utilizzato per valutare la prestazione di un giocatore di bowling in riferimento ad un certo numero di partite. Il valore trovato non incide sul punteggio ma sintetizza le capacit\u00e0 e i miglioramenti del giocatore.\nIn ingegneria, \u00e8 uno dei parametri da considerare per valutare la capacit\u00e0 di un processo produttivo.\nNelle applicazioni informatiche, \u00e8 a volte conveniente utilizzare la formula\nche consente, con sole tre variabili formula_29, di calcolare lo scarto quadratico medio, oltre che la media, di un flusso di numeri di lunghezza formula_3 senza dover ricorrere ad una memorizzazione degli stessi."], "concept_B": "Scarto quadratico medio", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["49731", "Analisi delle componenti principali", "L'analisi delle componenti principali (in inglese \"principal component analysis\" o abbreviata \"PCA\"), anche nota come trasformata di Karhunen-Lo\u00e8ve, trasformata di Hotelling o decomposizione ortogonale propria, \u00e8 una tecnica per la semplificazione dei dati utilizzata nell'ambito della statistica multivariata. Questo metodo fu proposto per la prima volta nel 1901 da Karl Pearson e sviluppato poi da Harold Hotelling nel 1933, e fa parte dell'analisi fattoriale. Lo scopo della tecnica \u00e8 quello di ridurre il numero pi\u00f9 o meno elevato di variabili che descrivono un insieme di dati a un numero minore di variabili latenti, limitando il pi\u00f9 possibile la perdita di informazioni.\nCi\u00f2 avviene tramite una trasformazione lineare delle variabili che proietta quelle originarie in un nuovo sistema cartesiano in cui la nuova variabile con la maggiore varianza viene proiettata sul primo asse, la variabile nuova, seconda per dimensione della varianza, sul secondo asse e cos\u00ec via.\nLa riduzione della complessit\u00e0 avviene limitandosi ad analizzare le principali, per varianza, tra le nuove variabili.\nDiversamente da altre trasformazioni lineari di variabili praticate nell'ambito della statistica, in questa tecnica sono gli stessi dati che determinano i vettori di trasformazione.\nAssumendo che a ciascuna delle variabili originarie venga sottratta la loro media e pertanto la nuova variabile (X) abbia media nulla,\nDove arg max indica l'insieme degli argomenti \"w\" in cui \u00e8 raggiunto il massimo. Con i primi (k-1) componenti, il k-esimo componente pu\u00f2 essere trovato sottraendo i primi (k-1) componenti principali a \"X\"\ne sostituendo questo\nUn metodo pi\u00f9 semplice per calcolare la componente w utilizza la matrice delle covarianze di x. La stessa operazione pu\u00f2 essere eseguita partendo dalla matrice dei coefficienti di correlazione anzich\u00e9 dalla matrice di varianza-covarianza delle variabili \"x\".\nInnanzitutto si devono trovare gli autovalori della matrice di covarianza o della matrice dei coefficienti di correlazione. Si ottengono tanti autovalori quante sono le variabili x. Se viene utilizzata la matrice di correlazione, l'autovalore relativo alla prima componente principale, ossia quella con varianza massima, sar\u00e0 pari ad 1. In ogni caso l'autovalore con il maggiore valore corrisponde alla dimensione w che ha la maggiore varianza: esso sar\u00e0 dunque la varianza della componente principale 1. In ordine decrescente, il secondo autovalore sar\u00e0 la varianza della componente principale 2, e cos\u00ec via per gli n autovalori. Per ciascun autovalore viene calcolato il corrispondente autovettore, ossia la matrice (riga vettore) dei coefficienti che moltiplicano le vecchie variabili x nella combinazione lineare per l'ottenimento delle nuove variabili w. Questi coefficienti sono anche definiti loading. La matrice degli autovettori, ossia la matrice che ha per riga ciascun autovettore prima calcolato, \u00e8 la cosiddetta matrice di rotazione V. Eseguendo l'operazione matriciale formula_4, dove W \u00e8 il vettore colonna avente come elementi le nuove variabili w1, w2, ..., wn e X \u00e8 il vettore colonna avente come elementi le \"vecchie variabili\" x1, x2, ..., xn, si possono trovare le coordinate di ciascun punto nel nuovo spazio vettoriale. Utilizzando le coordinate per ciascun punto relative alle componenti principali si costruisce il grafico denominato score plot. Se le componenti principali sono 3 si avr\u00e0 un grafico tridimensionale, se sono 2 sar\u00e0 bidimensionale, se invece si \u00e8 scelta una sola componente principale lo score plot sar\u00e0 allora monodimensionale. Mediante lo score plot \u00e8 possibile verificare quali dati sono simili tra di loro e quindi si pu\u00f2 ad esempio dedurre quali campioni presentano la medesima composizione.\nIn PCA esiste anche un altro tipo di grafico, definito loading plot, in cui sono le variabili x ad essere riportate nel nuovo sistema avente per assi le componenti principali. Con questo tipo di grafico \u00e8 possibile osservare se due variabili sono simili, e pertanto forniscono lo stesso tipo di informazione, oppure se sono distanti (e quindi non sono simili).\nQuindi gli elementi dell'autovettore colonna corrispondente a un autovalore esprimono il legame tra le variabili di partenza e la componente considerata attraverso dei pesi. Il numero di variabili latenti da considerare come componenti principali si fonda sulla grandezza relativa di un autovalore rispetto agli altri. Invece nel caso in cui sia l'operatore a scegliere le componenti principali senza considerare la relativa varianza espressa dai rispettivi autovalori, si ha un supervised pattern recognition.\nSi pu\u00f2 costruire la matrice dei fattori, in pratica una matrice modale, che elenca per riga le variabili originarie e per colonna le variabili latenti: ogni valore, compreso tra 0 e 1, dice quanto le seconde incidano sulle prime.\nInvece la matrice del punteggio fattoriale ha la stessa struttura della precedente, ma dice quanto le singole variabili originarie abbiano pesato sulla determinazione della grandezza di quelle latenti.\nSi supponga di disporre di un'indagine che riporta per 10 soggetti: voto medio (da 0 a 33), intelligenza (da 0 a 10), media ore studiate in un giorno e zona d'origine, che varia da 1 a 3. Si standardizzino i valori con la formula:\nformula_5\nE(x) \u00e8 il valore atteso di X, ovvero il valor medio, SD \u00e8 la deviazione standard.\nLa matrice dei coefficienti di correlazione \u00e8:\nLa diagonale principale \u00e8 composta da valori uguali ad 1 perch\u00e9 \u00e8 il coefficiente di correlazione di una variabile con se stessa. \u00c8 pure una matrice simmetrica perch\u00e9 il coefficiente di correlazione tra la variabile \"x\" e la variabile \"y\" \u00e8 uguale a quello tra \"y\" e \"x\". Si vede come ci sia un forte legame tra voto, media ore studio e intelligenza.\nDall'analisi degli autovalori si possono trarre conclusioni:\nGli autovalori sono in ordine decrescente e il loro rapporto con la somma degli autovalori d\u00e0 la percentuale di varianza che spiegano. Sono stati selezionati arbitrariamente solo quelli che hanno valore maggiore di 1 in quanto pi\u00f9 significativi, che spiegano il 70,708% e il 26,755% rispettivamente.\nSi osservi alla matrice delle componenti principali:\nIl fattore 1 pesa fortemente sul voto medio. Sembrerebbe pure che pesi in maniera negativa sulla variabile della zona di origine; chiaramente questa affermazione non ha senso perch\u00e9 inverte il nesso di causalit\u00e0: spetta allo statistico dare una spiegazione e una lettura sensate.\nSi calcoli quindi la matrice di punteggio fattoriale:\nCome si vede la variabile provenienza continua ad avere un influsso di segno negativo sull'autovalore principale. Le altre variabili invece hanno peso positivo."], "concept_A": "Analisi delle componenti principali", "wikipedia_passage_concept_B": ["161098", "Rapporto segnale/rumore", "In telecomunicazioni ed elettronica il rapporto segnale-rumore, spesso abbreviato con la sigla inglese SNR (\"Signal to Noise Ratio\") o S/N anche nell'uso italiano, \u00e8 una grandezza numerica che mette in relazione la potenza del segnale utile rispetto a quella del rumore in un qualsiasi sistema di acquisizione, elaborazione o trasmissione dell'informazione.\nIl rapporto segnale-rumore \u00e8 un numero puro o adimensionale dato dal rapporto fra due grandezze omogenee che esprime quanto il segnale sia pi\u00f9 potente del rumore nel sistema considerato. \u00c8 formalmente espresso dalla relazione:\ndove formula_2 \u00e8 la potenza del segnale utile e formula_3 la potenza totale del rumore presente nel sistema, grandezze queste solitamente espresse in watt o dBm.\nPu\u00f2 essere applicato indifferentemente a sistemi di natura ottica, elettronica, ecc. e si tratta di una grandezza fondamentale nell'ambito del trattamento dei segnali e della teoria dell'informazione. Un qualsiasi sistema che debba trasportare o trattare informazioni \u00e8 infatti affetto da rumore, primo fra tutti il rumore termico, che \u00e8 un fattore non ideale della trasmissione ovvero del tutto indesiderato che corrompe il segnale utile spesso sommandovisi in maniera additiva: tanto maggiore \u00e8 la potenza di rumore rispetto alla potenza del segnale utile tanto minore \u00e8 la qualit\u00e0 della comunicazione. \u00c8 logico dunque aspettarsi che l'SNR sia un parametro di qualit\u00e0 che si cerca o si tenda in qualche modo a massimizzare o preservare il pi\u00f9 possibile.\nEsso \u00e8 dunque un parametro di merito molto importante per il dimensionamento e il corretto funzionamento del sistemi di telecomunicazioni in quanto strettamente collegato alla capacit\u00e0 del sistema ricevente di rilevare il flusso informativo originario senza incorrere in alterazioni dovute a distorsione ed errori dovuti essenzialmente all'azione disturbante del rumore. Pi\u00f9 basso \u00e8 l'SNR, pi\u00f9 sar\u00e0 difficoltosa la decodifica del segnale ovvero pi\u00f9 alta sar\u00e0 la probabilit\u00e0 di errore e quindi anche il BER nelle trasmissioni digitali.\nNel caso di trasmissioni analogiche una diminuzione di SNR determina un deperimento graduale della qualit\u00e0 del segnale ricevuto (si pensi ad esempio a una radio FM che riceve male o a un televisore in cui compaiono audio o video disturbati: tipici casi di SNR basso); per le trasmissioni analogiche tuttavia \u00e8 l'utente finale a stabilire una soglia di fruibilit\u00e0 del sistema.\nNel caso di trasmissioni digitali, invece, esiste una soglia minima di SNR sotto la quale il sistema non \u00e8 in grado di funzionare (si pensi alla televisione digitale satellitare: o si vede bene o non si vede del tutto); l'errore di decisione/decodifica pu\u00f2 essere tale da far decidere per un simbolo piuttosto che un altro; tuttavia grazie alle moderne tecniche di modulazione e di protezione dei dati tramite codifica di canale tale soglia \u00e8 piuttosto bassa, al di sotto di quella che servirebbe per ottenere prestazioni analoghe su sistemi analogici.\nLa soglia minima di SNR \u00e8 determinata dalla tecnologia dell'apparato ricevente; in fase di progetto di un sistema di telecomunicazioni il primo obiettivo \u00e8 quindi quello di far pervenire al ricevitore un SNR sufficientemente elevato.\nIn Alta Fedelt\u00e0 il rapporto segnale-rumore \u00e8 uno dei parametri di merito fondamentali, anche se non l'unico, per la valutazione delle prestazioni di un impianto per quello che concerne la pulizia del suono prodotto, tanto che i preamplificatori di fascia alta sono realizzati in due distinti telai, uno contenente il circuito amplificatore, l'altro il circuito alimentatore.\nTale rapporto \u00e8 legato inoltre alla velocit\u00e0 di trasmissione sul canale tramite il Teorema di Shannon-Hartley.\nIl rapporto segnale-rumore decade con la distanza percorsa dal segnale sul canale o mezzo trasmissivo in virt\u00f9 dell'attenuazione della potenza del segnale utile cos\u00ec che a una certa distanza dal trasmettitore rimane solo rumore. Tale decadimento fa decadere a sua volta la velocit\u00e0 di trasmissione con la distanza sul canale stesso.\nEsiste inoltre un parametro, il SINAD, concettualmente molto simile al SNR, e che insieme al rumore include anche la distorsione generata dal circuito: esso d\u00e0 una valutazione pi\u00f9 precisa della degradazione assunta da un segnale per effetto delle non idealit\u00e0 delle apparecchiature che attraversa, in particolare degli ADC e dei DAC, che possono in alcuni casi essere parecchio distorcenti.\nIn molti sistemi elettronici e di telecomunicazioni per ottenere una massimizzazione del rapporto segnale-rumore si usa comunemente un filtro adattato."], "concept_B": "Rapporto segnale/rumore", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["4100372", "Rete neurale artificiale", "Nel campo dell'apprendimento automatico, una rete neurale artificiale (in inglese \"artificial neural network\", abbreviato in ANN o anche come NN) \u00e8 un modello computazionale composto di \"neuroni\" artificiali, ispirato vagamente dalla semplificazione di una rete neurale biologica.\nQuesti modelli matematici sono troppo semplici per ottenere una comprensione delle reti neurali biologiche, ma sono utilizzati per tentare di risolvere problemi ingegneristici di intelligenza artificiale come quelli che si pongono in diversi ambiti tecnologici (in elettronica, informatica, simulazione, e altre discipline).\nUna rete neurale artificiale pu\u00f2 essere realizzata sia da programmi software che da hardware dedicato (DSP, \"Digital Signal Processing\"). Questa branca pu\u00f2 essere utilizzata in congiunzione alla logica fuzzy.\nL'ampia variet\u00e0 di modelli non pu\u00f2 prescindere dal costituente di base, il neurone artificiale proposto da W.S. McCulloch e Walter Pitts in un famoso lavoro del 1943: \"\"A logical calculus of the ideas immanent in nervous activity\"\", il quale schematizza un combinatore lineare a soglia, con dati binari multipli in entrata e un singolo dato binario in uscita: un numero opportuno di tali elementi, connessi in modo da formare una rete, \u00e8 in grado di calcolare semplici funzioni booleane.\nLe prime ipotesi di apprendimento furono introdotte da D. O. Hebb nel libro del 1949: \"\"The organization of behavior\"\", nel quale vengono proposti collegamenti con i modelli complessi del cervello.\nNel 1958, J. Von Neumann nella sua opera \"\"The computer and the brain\"\" esamina le soluzioni proposte dai precedenti autori sottolineando la scarsa precisione che queste strutture possedevano per potere svolgere operazioni complesse.\nNello stesso anno, Frank Rosenblatt nel libro \"Psychological review\" introduce il primo schema di rete neurale, detto \"Perceptron\" (percettrone), antesignano delle attuali reti neurali, per il riconoscimento e la classificazione di forme, allo scopo di fornire un'interpretazione dell'organizzazione generale dei sistemi biologici. Il modello probabilistico di Rosenblatt \u00e8 quindi mirato all'analisi, in forma matematica, di funzioni quali l'immagazzinamento delle informazioni, e della loro influenza sul riconoscimento dei pattern; esso costituisce un progresso decisivo rispetto al modello binario di McCulloch e Pitts, perch\u00e9 i suoi pesi sinaptici sono variabili e quindi il percettrone \u00e8 in grado di apprendere.\nL'opera di Rosenblatt stimola una quantit\u00e0 di studi e ricerche che dura per un decennio, e suscita un vivo interesse e notevoli aspettative nella comunit\u00e0 scientifica, destinate tuttavia ad essere notevolmente ridimensionate allorch\u00e9 nel 1969 Marvin Minsky e Seymour A. Papert, nell'opera \"\"An introduction to computational geometry\"\", mostrano i limiti operativi delle semplici reti a due strati basate sul percettrone, e dimostrano l'impossibilit\u00e0 di risolvere per questa via molte classi di problemi, ossia tutti quelli non caratterizzati da separabilit\u00e0 lineare delle soluzioni: questo tipo di rete neurale non \u00e8 abbastanza potente: non \u00e8 infatti neanche in grado di calcolare la funzione \"or esclusivo\" (XOR). A causa di queste limitazioni, al periodo di euforia dovuto ai primi risultati della cibernetica (come veniva chiamata negli anni sessanta) segue un periodo di diffidenza durante il quale tutte le ricerche in questo campo non ricevono pi\u00f9 alcun finanziamento dal governo degli Stati Uniti d'America; le ricerche sulle reti tendono, di fatto, a ristagnare per oltre un decennio, e l'entusiasmo iniziale risulta fortemente ridimensionato.\nIl contesto matematico per addestrare le reti MLP (\"Multi-Layers Perceptron\", ossia percettrone multistrato) fu stabilito dal matematico americano Paul Werbos nella sua tesi di dottorato (Ph.D.) del 1974. Non fu dato molto peso al suo lavoro tanto fu forte la confutazione dimostrata da Minsky e Papert anni prima, e solo l'intervento di J. J. Hopfield, nel 1982, che in un suo lavoro studia dei modelli di riconoscimento di pattern molto generali, si oppose in modo diretto alla confutazione di Minsky riaprendo cos\u00ec degli spiragli per la ricerca in questo campo.\nUno dei metodi pi\u00f9 noti ed efficaci per l'addestramento di tale classe di reti neurali \u00e8 il cosiddetto algoritmo di retropropagazione dell'errore (error backpropagation), proposto nel 1986 da David E. Rumelhart, G. Hinton e R. J. Williams, il quale modifica sistematicamente i pesi delle connessioni tra i nodi, cos\u00ec che la risposta della rete si avvicini sempre di pi\u00f9 a quella desiderata. Tale lavoro fu prodotto riprendendo il modello creato da Werbos. L'algoritmo di retropropagazione (\"backpropagation\" o BP) \u00e8 una tecnica d'apprendimento tramite esempi, costituente una generalizzazione dell'algoritmo d'apprendimento per il percettrone sviluppato da Rosenblatt nei primi anni '60. Mediante questa tecnica era possibile, come detto, trattare unicamente applicazioni caratterizzabili come funzioni booleane linearmente separabili.\nL'algoritmo di apprendimento si basa sul metodo della discesa del gradiente che permette di trovare un minimo locale di una funzione in uno spazio a N dimensioni. I pesi associati ai collegamenti tra gli strati di neuroni si inizializzano a valori piccoli (ovvero molto inferiori ai valori reali che poi assumeranno) e casuali e poi si applica la regola di apprendimento presentando alla rete dei pattern di esempio. Queste reti neurali sono poi capaci di generalizzare in modo appropriato, cio\u00e8 di dare risposte plausibili per input che non hanno mai visto.\nL'addestramento di une rete neurale di tipo BP avviene in due diversi stadi: \"forward-pass\" e \"backward-pass\". Nella prima fase i vettori in input sono applicati ai nodi in ingresso con una propagazione in avanti dei segnali attraverso ciascun livello della rete (\"forward-pass\"). Durante questa fase i valori dei pesi sinaptici sono tutti fissati. Nella seconda fase la risposta della rete viene confrontata con l'uscita desiderata ottenendo il segnale d'errore. L'errore calcolato \u00e8 propagato nella direzione inversa rispetto a quella delle connessioni sinaptiche. I pesi sinaptici infine sono modificati in modo da minimizzare la differenza tra l'uscita attuale e l'uscita desiderata (\"backward-pass\").\nTale algoritmo consente di superare le limitazioni del percettrone e di risolvere il problema della separabilit\u00e0 non lineare (e quindi di calcolare la funzione XOR), segnando il definitivo rilancio delle reti neurali, come testimoniato anche dall'ampia variet\u00e0 d'applicazioni commerciali: attualmente la BP rappresenta un algoritmo di largo uso in molti campi applicativi.\nUna rete neurale artificiale (ANN \"\"Artificial Neural Network\"\" in inglese), normalmente chiamata solo \"rete neurale\" (NN \"\"Neural Network\"\" in inglese), \u00e8 un modello matematico/informatico di calcolo basato sulle reti neurali biologiche. Tale modello \u00e8 costituito da un gruppo di interconnessioni di informazioni costituite da neuroni artificiali e processi che utilizzano un approccio di connessionismo di calcolo. Nella maggior parte dei casi una rete neurale artificiale \u00e8 un sistema adattivo che cambia la propria struttura in base a informazioni esterne o interne che scorrono attraverso la rete stessa durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare.\nUna rete neurale artificiale riceve segnali esterni su uno strato di nodi (unit\u00e0 di elaborazione) d'ingresso, ciascuno dei quali \u00e8 collegato con numerosi nodi interni, organizzati in pi\u00f9 livelli. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\nIl concetto di rete neurale si pone perch\u00e9 una funzione formula_1 \u00e8 definita come una composizione di altre funzioni formula_2, che possono a loro volta essere ulteriormente definite come composizione di altre funzioni. Questo pu\u00f2 essere comodamente rappresentato come una struttura di reti, con le frecce raffiguranti le dipendenze tra variabili. Una rappresentazione ampiamente utilizzata \u00e8 la somma ponderata non lineare, dove formula_3, dove formula_4 \u00e8 una funzione predefinita, come ad esempio la tangente iperbolica. Sar\u00e0 conveniente per le seguenti far riferimento ad un insieme di funzioni come un vettore formula_5.\nLa Figura 1 esemplifica una decomposizione della funzione formula_6, con dipendenze tra le variabili indicate dalle frecce. Queste possono essere interpretate in due modi:\nI due punti di vista sono in gran parte equivalenti. In entrambi i casi, per questa particolare architettura di rete, i componenti dei singoli strati sono indipendenti l'uno dall'altro (ad esempio, le componenti di formula_8 sono indipendenti l'una dall'altra, dato il loro ingresso formula_15). Questo, naturalmente, permette un certo grado di parallelismo nella costruzione del sistema.\nReti, come ad esempio quelle precedenti vengono comunemente chiamate \"\"feedforward\"\", perch\u00e9 il loro \u00e8 un grafico aciclico diretto. Reti con cicli al loro interno sono comunemente chiamati reti ricorrenti. Tali reti sono comunemente raffigurate nel modo indicato nella parte superiore della Figura 2, dove la funzione formula_6 \u00e8 mostrata come dipendente su se stessa. Tuttavia, vi \u00e8 una dipendenza temporale implicita che non \u00e8 possibile dimostrare. Questo significa in pratica che il valore di formula_6 ad un certo punto nel tempo formula_18 dipende dai valori di formula_6 al tempo zero o su uno o pi\u00f9 altri punti temporali. Il modello del grafico nella parte inferiore della Figura 2 illustra il caso in cui il valore di formula_6 al tempo formula_18 dipende solo dal suo valore finale.\nTuttavia la funzionalit\u00e0 pi\u00f9 interessante di queste funzioni, ci\u00f2 che ha attirato l'interesse e lo studio per la maggior parte delle reti neurali, \u00e8 la possibilit\u00e0 di apprendimento, che in pratica significa la seguente:\nCi\u00f2 comporta la definizione di una funzione di costo formula_24 tale che, per la soluzione ottimale formula_25 formula_26 nessuna soluzione ha un costo inferiore al costo della soluzione ottimale.\nLa funzione di costo formula_27 \u00e8 un concetto importante nell'apprendimento, poich\u00e9 si tratta di una misura di quanto \u00e8 lontana da noi la soluzione ottimale del problema che vogliamo risolvere. Quindi vi sono una serie di algoritmi di apprendimento che cercano nello spazio delle soluzioni al fine di trovare una funzione che abbia il minor costo possibile.\nPer applicazioni in cui la soluzione dipende da alcuni dati, il costo deve essere necessariamente funzione delle osservazioni.\nMentre \u00e8 possibile definire per alcune reti una funzione di costo ad hoc, spesso si pu\u00f2 utilizzare una particolare funzione di costo poich\u00e9 gode delle propriet\u00e0 desiderate (ad esempio, la convessit\u00e0), o perch\u00e9 proviene da una particolare formulazione del problema (vale a dire, in una formulazione probabilistica, la probabilit\u00e0 a posteriori del modello pu\u00f2 essere utilizzata come l'inverso del costo). In ultima analisi, la funzione di costo dipender\u00e0 dal compito.\nVi sono tre grandi paradigmi di apprendimento, ciascuno corrispondente ad un particolare compito astratto di apprendimento. Si tratta dell'apprendimento supervisionato, apprendimento non supervisionato e l'apprendimento per rinforzo. Di solito un tipo di architettura di rete pu\u00f2 essere impiegato in qualsiasi di tali compiti.\nL'algoritmo di apprendimento hebbiano (1984) si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata.\nformula_28 dove formula_29,\ndove formula_30 \u00e8 l'formula_31 ingresso e formula_32 \u00e8 il tasso di apprendimento formula_33.\nLa regola di Hebb \u00e8 la seguente: l'efficacia di una particolare sinapsi cambia se e solo se c'\u00e8 un'intensa attivit\u00e0 simultanea dei due neuroni, con un'alta trasmissione di input nella sinapsi in questione.\nEsempio di procedura:\nIn questo modo le connessioni possono solo irrobustirsi.\nLe connessioni si considerano irrobustite quando le unit\u00e0 presinaptica e postsinaptica sono d'accordo, altrimenti si indeboliscono.\nSi considerano funzioni bipolari (-1,1) invece che booleane (0,1).\nLe reti neurali si basano principalmente sulla simulazione di neuroni artificiali opportunamente collegati. Il modello rappresentato in figura \u00e8 quello proposto da McCulloch e Pitts.\nI suddetti neuroni ricevono in ingresso degli stimoli e li elaborano. L'elaborazione pu\u00f2 essere anche molto sofisticata ma in un caso semplice si pu\u00f2 pensare che i singoli ingressi vengano moltiplicati per un opportuno valore detto peso, il risultato delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone si attiva attivando la sua uscita. Il peso indica l'efficacia sinaptica della linea di ingresso e serve a quantificarne l'importanza, un ingresso molto importante avr\u00e0 un peso elevato, mentre un ingresso poco utile all'elaborazione avr\u00e0 un peso inferiore. Si pu\u00f2 pensare che se due neuroni comunicano fra loro utilizzando maggiormente alcune connessioni allora tali connessioni avranno un peso maggiore, fino a che non si creeranno delle connessioni tra l'ingresso e l'uscita della rete che sfruttano \"percorsi preferenziali\". Tuttavia \u00e8 sbagliato pensare che la rete finisca col produrre un unico percorso di connessione: tutte le combinazioni infatti avranno un certo peso, e quindi contribuiscono al collegamento ingresso/uscita.\nIl modello in figura rappresenta una classica rete neurale pienamente connessa.\nI singoli neuroni vengono collegati alla schiera di neuroni successivi, in modo da formare una rete di neuroni. Normalmente una rete \u00e8 formata da tre strati. Nel primo abbiamo gli ingressi (I), questo strato si preoccupa di trattare gli ingressi in modo da adeguarli alle richieste dei neuroni. Se i segnali in ingresso sono gi\u00e0 trattati pu\u00f2 anche non esserci. Il secondo strato \u00e8 quello nascosto (H, \"hidden\"), si preoccupa dell'elaborazione vera e propria e pu\u00f2 essere composto anche da pi\u00f9 colonne di neuroni. Il terzo strato \u00e8 quello di uscita (O) e si preoccupa di raccogliere i risultati ed adattarli alle richieste del blocco successivo della rete neurale. Queste reti possono essere anche molto complesse e coinvolgere migliaia di neuroni e decine di migliaia di connessioni.\nPer costruire la struttura di una rete neurale multistrato si possono inserire formula_38 strati \"hidden.\" L'efficacia di generalizzare di una rete neurale multistrato dipende ovviamente dall'addestramento che ha ricevuto e dal fatto di essere riuscita o meno ad entrare in un minimo locale buono.\nL'algoritmo di retropropagazione dell'errore (\"backpropagation\") \u00e8 utilizzato nell'apprendimento con supervisione. Esso permette di modificare i pesi delle connessioni in modo tale che si minimizzi una certa funzione errore E. Tale funzione dipende dal vettore h-esimo di output formula_39 restituito dalla rete, dato il vettore h-esimo di ingresso formula_40 e dal vettore h-esimo di output formula_41che noi desideriamo (che fa parte del training set). Il training set \u00e8 dunque un insieme di N coppie di vettori formula_42, con formula_43. La funzione errore che si deve minimizzare si pu\u00f2 scrivere come:\nformula_44\ndove l'indice k rappresenta il valore corrispondente al k-esimo neurone di output. E(w) \u00e8 una funzione dipendente dai pesi (che in generale variano nel tempo), per minimizzarla si pu\u00f2 usare l'algoritmo della discesa del gradiente (\"gradient descent\"). L'algoritmo parte da un punto generico formula_45 e calcola il gradiente formula_46. Il gradiente d\u00e0 la direzione verso cui muoversi lungo la quale si ha il massimo incremento (o decremento se considero formula_47). Definita la direzione ci si muove di una distanza formula_32 predefinita a priori e si trova un nuovo punto formula_49 sul quale \u00e8 calcolato nuovamente il gradiente. Si continua iterativamente finch\u00e9 il gradiente non \u00e8 nullo.\nL'algoritmo di backpropagation pu\u00f2 essere diviso in due passi:\nI passi logici per addestrare una rete neurale con apprendimento supervisionato sono i seguenti:\nPer l'addestramento di reti neurali profonde, impiegando dataset molto vasti, la discesa del gradiente classica risulta computazionalmente proibitiva, per cui nell'ottimizzare i parametri del modello si fa tipicamente uso dell'algoritmo di discesa stocastica del gradiente.\nNel 1982, il fisico John J. Hopfield pubblica un articolo fondamentale in cui presenta un modello matematico comunemente noto appunto come rete di Hopfield: tale rete si distingue per \"l'emergere spontaneo di nuove capacit\u00e0 computazionali dal comportamento collettivo di un gran numero di semplici elementi d'elaborazione\". Le propriet\u00e0 collettive del modello producono una memoria associativa per il riconoscimento di configurazioni corrotte e il recupero di informazioni mancanti.\nInoltre, Hopfield ritiene che ogni sistema fisico possa essere considerato come un potenziale dispositivo di memoria, qualora esso disponga di un certo numero di stati stabili, i quali fungano da attrattore per il sistema stesso. Sulla base di tale considerazione, egli si spinge a formulare la tesi secondo cui la stabilit\u00e0 e la collocazione di tali attrattori sono propriet\u00e0 spontanee di sistemi costituiti, come accennato, da considerevoli quantit\u00e0 di neuroni reciprocamente interagenti.\nLe applicazioni delle reti di Hopfield riguardano principalmente la realizzazione di memorie associative, resistenti all'alterazione delle condizioni operative, e la soluzione di problemi d'ottimizzazione combinatoriale.\nDa un punto di vista strutturale, la rete di Hopfield costituisce una rete neurale ricorrente simmetrica, di cui \u00e8 garantita la convergenza.\nUna rete ricorrente \u00e8 un modello neurale in cui \u00e8 presente un flusso bidirezionale d'informazioni; in altri termini, mentre nelle reti di tipo feedforward la propagazione dei segnali avviene unicamente, in maniera continua, nella direzione che conduce dagli ingressi alle uscite, nelle reti ricorrenti tale propagazione pu\u00f2 anche manifestarsi da uno strato neurale successivo ad uno precedente, oppure tra neuroni appartenenti ad uno stesso strato, e persino tra un neurone e s\u00e9 stesso.\nUn significativo e noto esempio di semplice rete ricorrente \u00e8 dovuto a Jeffrey L. Elman (1990). Essa costituisce una variazione sul tema del percettrone multistrato, con esattamente tre strati e l'aggiunta di un insieme di neuroni \"contestuali\" nello strato d'ingresso. Le connessioni retroattive si propagano dallo strato intermedio (e nascosto) a tali unit\u00e0 contestuali, alle quali si assegna peso costante e pari all'unit\u00e0.\nIn ciascun istante, gli ingressi si propagano nel modo tradizionale e tipico delle reti feedforward, compresa l'applicazione dell'algoritmo d'apprendimento (solitamente la \"backpropagation\"). Le connessioni retroattive fisse hanno come effetto quello di mantenere una copia dei precedenti valori dei neuroni intermedi, dal momento che tale flusso avviene sempre prima della fase d'apprendimento.\nIn questo modo la rete di Elman tiene conto del suo stato precedente, cosa che le consente di svolgere compiti di previsione di sequenze temporali che sono difficilmente alla portata dei percettroni multistrato convenzionali.\nInfine, un ultimo interessante tipo di rete \u00e8 costituita dalla cosiddetta mappa auto-organizzante o rete SOM (\"Self-Organizing Map\"). Tale innovativo tipo di rete neurale \u00e8 stata elaborata da Teuvo Kohonen dell'Universit\u00e0 Tecnologica di Helsinki; il suo algoritmo d'apprendimento \u00e8 senza dubbio una brillante formulazione di apprendimento non supervisionato, e ha dato luogo a un gran numero di applicazioni nell'ambito dei problemi di classificazione. Una mappa o rete SOM \u00e8 basata essenzialmente su un reticolo o griglia di neuroni artificiali i cui pesi sono continuamente adattati ai vettori presentati in ingresso nel relativo insieme di addestramento. Tali vettori possono essere di dimensione generica, anche se nella maggior parte delle applicazioni essa \u00e8 piuttosto alta. Per ci\u00f2 che riguarda le uscite della rete, al contrario, ci si limita di solito ad una dimensione massima pari a tre, il che consente di dare luogo a mappe 2D o 3D.\nIn termini pi\u00f9 analitici, l'algoritmo pu\u00f2 essere agevolmente descritto, come accennato, nei termini di un insieme di neuroni artificiali, ciascuno con una precisa collocazione sulla mappa rappresentativa degli \"output\", che prendono parte ad un processo noto come \"winner takes all\" (\"Il vincitore piglia tutto\"), al termine del quale il nodo avente un vettore di pesi pi\u00f9 vicino ad un certo \"input\" \u00e8 dichiarato vincitore, mentre i pesi stessi sono aggiornati in modo da avvicinarli al vettore in ingresso. Ciascun nodo ha un certo numero di nodi adiacenti. Quando un nodo vince una competizione, anche i pesi dei nodi adiacenti sono modificati, secondo la regola generale che pi\u00f9 un nodo \u00e8 lontano dal nodo vincitore, meno marcata deve essere la variazione dei suoi pesi. Il processo \u00e8 quindi ripetuto per ogni vettore dell'insieme di \"training\", per un certo numero, solitamente grande, di cicli. Va da s\u00e9 che ingressi diversi producono vincitori diversi.\nOperando in tal modo, la mappa riesce alfine ad associare i nodi d'uscita con i gruppi o schemi ricorrenti nell'insieme dei dati in ingresso. Se questi schemi sono riconoscibili, essi possono essere associati ai corrispondenti nodi della rete addestrata. In maniera analoga a quella della maggioranza delle reti neurali artificiali, anche la mappa o rete SOM pu\u00f2 operare in due distinte modalit\u00e0:\nIn generale una ANN (\"Attractor Neural Network\") \u00e8 una rete di nodi (es: biologicamente ispirati), spesso interconnessi in modo ricorsivo, la cui dinamica nel tempo stabilisce un assestamento in un particolare modo di oscillazione. Questo modo di oscillazione pu\u00f2 essere stazionario, variante nel tempo o di tipo stocastico ed \u00e8 chiamato il suo 'attrattore'. In neuroscienza teorica diversi tipi di reti ad attrattori sono state associate a differenti funzioni, come: memoria, attenzione, condotta del moto e classificazione.\nPi\u00f9 precisamente, una rete ad attrattori \u00e8 una rete di N nodi connessi in modo che la loro intera dinamica diventi stabile in uno spazio D dimensionale, dove solitamente N\u00bbD. Ci\u00f2 assume che non vi sia pi\u00f9 input dall'esterno del sistema. La stabilit\u00e0 nello stato ad attrattore indica l'esistenza di uno stato stabile in una qualche variet\u00e0 algebrica (es: linea, cerchio, piano, toroide).\nL'utilit\u00e0 dei modelli di rete neurale sta nel fatto che queste possono essere usate per comprendere una funzione utilizzando solo le osservazioni sui dati. Ci\u00f2 \u00e8 particolarmente utile nelle applicazioni in cui la complessit\u00e0 dei dati o la difficolt\u00e0 di elaborazione rende la progettazione di una tale funzione impraticabile con i normali procedimenti di analisi manuale.\nI compiti a cui le reti neurali sono applicate possono essere classificate nelle seguenti grandi categorie di applicazioni:\nLe aree di applicazione includono i sistemi di controllo (controllo di veicoli, controllo di processi), simulatori di giochi e processi decisionali (backgammon, scacchi), riconoscimento di pattern (sistemi radar, identificazione di volti, riconoscimento di oggetti, ecc), riconoscimenti di sequenze (riconoscimento di gesti, riconoscimento vocale, OCR), diagnosi medica, applicazioni finanziarie, data mining, filtri spam per e-mail.\nLe reti neurali per come sono costruite lavorano in parallelo e sono quindi in grado di trattare molti dati. Si tratta in sostanza di un sofisticato sistema di tipo statistico dotato di una buona immunit\u00e0 al rumore; se alcune unit\u00e0 del sistema dovessero funzionare male, la rete nel suo complesso avrebbe delle riduzioni di prestazioni ma difficilmente andrebbe incontro ad un blocco del sistema. I software di ultima generazione dedicati alle reti neurali richiedono comunque buone conoscenze statistiche; il grado di apparente utilizzabilit\u00e0 immediata non deve trarre in inganno, pur permettendo all'utente di effettuare subito previsioni o classificazioni, seppure con i limiti del caso.\nDa un punto di vista industriale, risultano efficaci quando si dispone di dati storici che possono essere trattati con gli algoritmi neurali. Ci\u00f2 \u00e8 di interesse per la produzione perch\u00e9 permette di estrarre dati e modelli senza effettuare ulteriori prove e sperimentazioni.\nI modelli prodotti dalle reti neurali, anche se molto efficienti, non sono spiegabili in linguaggio simbolico umano: i risultati vanno accettati \"cos\u00ec come sono\", da cui anche la definizione inglese delle reti neurali come \"black box\": in altre parole, a differenza di un sistema algoritmico, dove si pu\u00f2 esaminare passo-passo il percorso che dall'input genera l'output, una rete neurale \u00e8 in grado di generare un risultato valido, o comunque con una alta probabilit\u00e0 di essere accettabile, ma non \u00e8 possibile spiegare come e perch\u00e9 tale risultato sia stato generato.\nCome per qualsiasi algoritmo di modellazione, anche le reti neurali sono efficienti solo se le variabili predittive sono scelte con cura.\nNon sono in grado di trattare in modo efficiente variabili di tipo categorico (per esempio, il nome della citt\u00e0) con molti valori diversi. Necessitano di una fase di addestramento del sistema che fissi i pesi dei singoli neuroni e questa fase pu\u00f2 richiedere molto tempo, se il numero dei record e delle variabili analizzate \u00e8 molto grande. Non esistono teoremi o modelli che permettano di definire la rete ottima, quindi la riuscita di una rete dipende molto dall'esperienza del creatore.\nLe reti neurali vengono solitamente usate in contesti dove i dati possono essere parzialmente errati oppure dove non esistano modelli analitici in grado di affrontare il problema. Un loro tipico utilizzo \u00e8 nei software di OCR, nei sistemi di riconoscimento facciale e pi\u00f9 in generale nei sistemi che si occupano di trattare dati soggetti a errori o rumore. Esse sono anche uno degli strumenti maggiormente utilizzati nelle analisi di Data mining.\nLe reti neurali vengono anche utilizzate come mezzo per previsioni nell'analisi finanziaria o meteorologica. Negli ultimi anni \u00e8 aumentata notevolmente la loro importanza anche nel campo della bioinformatica nel quale vengono utilizzate per la ricerca di pattern funzionali e/o strutturali in proteine e acidi nucleici. Mostrando opportunamente una lunga serie di input (fase di training o apprendimento), la rete \u00e8 in grado di fornire l'output pi\u00f9 probabile. Negli ultimi anni inoltre sono in corso studi per il loro utilizzo nella previsione degli attacchi Epilettici (Analisi dei Dati provenienti dall' EEG).\nRecenti studi hanno dimostrato buone potenzialit\u00e0 delle reti neurali in sismologia per la localizzazione di epicentri di terremoti e predizione della loro intensit\u00e0."], "concept_B": "Rete neurale artificiale", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["49731", "Analisi delle componenti principali", "L'analisi delle componenti principali (in inglese \"principal component analysis\" o abbreviata \"PCA\"), anche nota come trasformata di Karhunen-Lo\u00e8ve, trasformata di Hotelling o decomposizione ortogonale propria, \u00e8 una tecnica per la semplificazione dei dati utilizzata nell'ambito della statistica multivariata. Questo metodo fu proposto per la prima volta nel 1901 da Karl Pearson e sviluppato poi da Harold Hotelling nel 1933, e fa parte dell'analisi fattoriale. Lo scopo della tecnica \u00e8 quello di ridurre il numero pi\u00f9 o meno elevato di variabili che descrivono un insieme di dati a un numero minore di variabili latenti, limitando il pi\u00f9 possibile la perdita di informazioni.\nCi\u00f2 avviene tramite una trasformazione lineare delle variabili che proietta quelle originarie in un nuovo sistema cartesiano in cui la nuova variabile con la maggiore varianza viene proiettata sul primo asse, la variabile nuova, seconda per dimensione della varianza, sul secondo asse e cos\u00ec via.\nLa riduzione della complessit\u00e0 avviene limitandosi ad analizzare le principali, per varianza, tra le nuove variabili.\nDiversamente da altre trasformazioni lineari di variabili praticate nell'ambito della statistica, in questa tecnica sono gli stessi dati che determinano i vettori di trasformazione.\nAssumendo che a ciascuna delle variabili originarie venga sottratta la loro media e pertanto la nuova variabile (X) abbia media nulla,\nDove arg max indica l'insieme degli argomenti \"w\" in cui \u00e8 raggiunto il massimo. Con i primi (k-1) componenti, il k-esimo componente pu\u00f2 essere trovato sottraendo i primi (k-1) componenti principali a \"X\"\ne sostituendo questo\nUn metodo pi\u00f9 semplice per calcolare la componente w utilizza la matrice delle covarianze di x. La stessa operazione pu\u00f2 essere eseguita partendo dalla matrice dei coefficienti di correlazione anzich\u00e9 dalla matrice di varianza-covarianza delle variabili \"x\".\nInnanzitutto si devono trovare gli autovalori della matrice di covarianza o della matrice dei coefficienti di correlazione. Si ottengono tanti autovalori quante sono le variabili x. Se viene utilizzata la matrice di correlazione, l'autovalore relativo alla prima componente principale, ossia quella con varianza massima, sar\u00e0 pari ad 1. In ogni caso l'autovalore con il maggiore valore corrisponde alla dimensione w che ha la maggiore varianza: esso sar\u00e0 dunque la varianza della componente principale 1. In ordine decrescente, il secondo autovalore sar\u00e0 la varianza della componente principale 2, e cos\u00ec via per gli n autovalori. Per ciascun autovalore viene calcolato il corrispondente autovettore, ossia la matrice (riga vettore) dei coefficienti che moltiplicano le vecchie variabili x nella combinazione lineare per l'ottenimento delle nuove variabili w. Questi coefficienti sono anche definiti loading. La matrice degli autovettori, ossia la matrice che ha per riga ciascun autovettore prima calcolato, \u00e8 la cosiddetta matrice di rotazione V. Eseguendo l'operazione matriciale formula_4, dove W \u00e8 il vettore colonna avente come elementi le nuove variabili w1, w2, ..., wn e X \u00e8 il vettore colonna avente come elementi le \"vecchie variabili\" x1, x2, ..., xn, si possono trovare le coordinate di ciascun punto nel nuovo spazio vettoriale. Utilizzando le coordinate per ciascun punto relative alle componenti principali si costruisce il grafico denominato score plot. Se le componenti principali sono 3 si avr\u00e0 un grafico tridimensionale, se sono 2 sar\u00e0 bidimensionale, se invece si \u00e8 scelta una sola componente principale lo score plot sar\u00e0 allora monodimensionale. Mediante lo score plot \u00e8 possibile verificare quali dati sono simili tra di loro e quindi si pu\u00f2 ad esempio dedurre quali campioni presentano la medesima composizione.\nIn PCA esiste anche un altro tipo di grafico, definito loading plot, in cui sono le variabili x ad essere riportate nel nuovo sistema avente per assi le componenti principali. Con questo tipo di grafico \u00e8 possibile osservare se due variabili sono simili, e pertanto forniscono lo stesso tipo di informazione, oppure se sono distanti (e quindi non sono simili).\nQuindi gli elementi dell'autovettore colonna corrispondente a un autovalore esprimono il legame tra le variabili di partenza e la componente considerata attraverso dei pesi. Il numero di variabili latenti da considerare come componenti principali si fonda sulla grandezza relativa di un autovalore rispetto agli altri. Invece nel caso in cui sia l'operatore a scegliere le componenti principali senza considerare la relativa varianza espressa dai rispettivi autovalori, si ha un supervised pattern recognition.\nSi pu\u00f2 costruire la matrice dei fattori, in pratica una matrice modale, che elenca per riga le variabili originarie e per colonna le variabili latenti: ogni valore, compreso tra 0 e 1, dice quanto le seconde incidano sulle prime.\nInvece la matrice del punteggio fattoriale ha la stessa struttura della precedente, ma dice quanto le singole variabili originarie abbiano pesato sulla determinazione della grandezza di quelle latenti.\nSi supponga di disporre di un'indagine che riporta per 10 soggetti: voto medio (da 0 a 33), intelligenza (da 0 a 10), media ore studiate in un giorno e zona d'origine, che varia da 1 a 3. Si standardizzino i valori con la formula:\nformula_5\nE(x) \u00e8 il valore atteso di X, ovvero il valor medio, SD \u00e8 la deviazione standard.\nLa matrice dei coefficienti di correlazione \u00e8:\nLa diagonale principale \u00e8 composta da valori uguali ad 1 perch\u00e9 \u00e8 il coefficiente di correlazione di una variabile con se stessa. \u00c8 pure una matrice simmetrica perch\u00e9 il coefficiente di correlazione tra la variabile \"x\" e la variabile \"y\" \u00e8 uguale a quello tra \"y\" e \"x\". Si vede come ci sia un forte legame tra voto, media ore studio e intelligenza.\nDall'analisi degli autovalori si possono trarre conclusioni:\nGli autovalori sono in ordine decrescente e il loro rapporto con la somma degli autovalori d\u00e0 la percentuale di varianza che spiegano. Sono stati selezionati arbitrariamente solo quelli che hanno valore maggiore di 1 in quanto pi\u00f9 significativi, che spiegano il 70,708% e il 26,755% rispettivamente.\nSi osservi alla matrice delle componenti principali:\nIl fattore 1 pesa fortemente sul voto medio. Sembrerebbe pure che pesi in maniera negativa sulla variabile della zona di origine; chiaramente questa affermazione non ha senso perch\u00e9 inverte il nesso di causalit\u00e0: spetta allo statistico dare una spiegazione e una lettura sensate.\nSi calcoli quindi la matrice di punteggio fattoriale:\nCome si vede la variabile provenienza continua ad avere un influsso di segno negativo sull'autovalore principale. Le altre variabili invece hanno peso positivo."], "concept_A": "Analisi delle componenti principali", "wikipedia_passage_concept_B": ["4100372", "Rete neurale artificiale", "Nel campo dell'apprendimento automatico, una rete neurale artificiale (in inglese \"artificial neural network\", abbreviato in ANN o anche come NN) \u00e8 un modello computazionale composto di \"neuroni\" artificiali, ispirato vagamente dalla semplificazione di una rete neurale biologica.\nQuesti modelli matematici sono troppo semplici per ottenere una comprensione delle reti neurali biologiche, ma sono utilizzati per tentare di risolvere problemi ingegneristici di intelligenza artificiale come quelli che si pongono in diversi ambiti tecnologici (in elettronica, informatica, simulazione, e altre discipline).\nUna rete neurale artificiale pu\u00f2 essere realizzata sia da programmi software che da hardware dedicato (DSP, \"Digital Signal Processing\"). Questa branca pu\u00f2 essere utilizzata in congiunzione alla logica fuzzy.\nL'ampia variet\u00e0 di modelli non pu\u00f2 prescindere dal costituente di base, il neurone artificiale proposto da W.S. McCulloch e Walter Pitts in un famoso lavoro del 1943: \"\"A logical calculus of the ideas immanent in nervous activity\"\", il quale schematizza un combinatore lineare a soglia, con dati binari multipli in entrata e un singolo dato binario in uscita: un numero opportuno di tali elementi, connessi in modo da formare una rete, \u00e8 in grado di calcolare semplici funzioni booleane.\nLe prime ipotesi di apprendimento furono introdotte da D. O. Hebb nel libro del 1949: \"\"The organization of behavior\"\", nel quale vengono proposti collegamenti con i modelli complessi del cervello.\nNel 1958, J. Von Neumann nella sua opera \"\"The computer and the brain\"\" esamina le soluzioni proposte dai precedenti autori sottolineando la scarsa precisione che queste strutture possedevano per potere svolgere operazioni complesse.\nNello stesso anno, Frank Rosenblatt nel libro \"Psychological review\" introduce il primo schema di rete neurale, detto \"Perceptron\" (percettrone), antesignano delle attuali reti neurali, per il riconoscimento e la classificazione di forme, allo scopo di fornire un'interpretazione dell'organizzazione generale dei sistemi biologici. Il modello probabilistico di Rosenblatt \u00e8 quindi mirato all'analisi, in forma matematica, di funzioni quali l'immagazzinamento delle informazioni, e della loro influenza sul riconoscimento dei pattern; esso costituisce un progresso decisivo rispetto al modello binario di McCulloch e Pitts, perch\u00e9 i suoi pesi sinaptici sono variabili e quindi il percettrone \u00e8 in grado di apprendere.\nL'opera di Rosenblatt stimola una quantit\u00e0 di studi e ricerche che dura per un decennio, e suscita un vivo interesse e notevoli aspettative nella comunit\u00e0 scientifica, destinate tuttavia ad essere notevolmente ridimensionate allorch\u00e9 nel 1969 Marvin Minsky e Seymour A. Papert, nell'opera \"\"An introduction to computational geometry\"\", mostrano i limiti operativi delle semplici reti a due strati basate sul percettrone, e dimostrano l'impossibilit\u00e0 di risolvere per questa via molte classi di problemi, ossia tutti quelli non caratterizzati da separabilit\u00e0 lineare delle soluzioni: questo tipo di rete neurale non \u00e8 abbastanza potente: non \u00e8 infatti neanche in grado di calcolare la funzione \"or esclusivo\" (XOR). A causa di queste limitazioni, al periodo di euforia dovuto ai primi risultati della cibernetica (come veniva chiamata negli anni sessanta) segue un periodo di diffidenza durante il quale tutte le ricerche in questo campo non ricevono pi\u00f9 alcun finanziamento dal governo degli Stati Uniti d'America; le ricerche sulle reti tendono, di fatto, a ristagnare per oltre un decennio, e l'entusiasmo iniziale risulta fortemente ridimensionato.\nIl contesto matematico per addestrare le reti MLP (\"Multi-Layers Perceptron\", ossia percettrone multistrato) fu stabilito dal matematico americano Paul Werbos nella sua tesi di dottorato (Ph.D.) del 1974. Non fu dato molto peso al suo lavoro tanto fu forte la confutazione dimostrata da Minsky e Papert anni prima, e solo l'intervento di J. J. Hopfield, nel 1982, che in un suo lavoro studia dei modelli di riconoscimento di pattern molto generali, si oppose in modo diretto alla confutazione di Minsky riaprendo cos\u00ec degli spiragli per la ricerca in questo campo.\nUno dei metodi pi\u00f9 noti ed efficaci per l'addestramento di tale classe di reti neurali \u00e8 il cosiddetto algoritmo di retropropagazione dell'errore (error backpropagation), proposto nel 1986 da David E. Rumelhart, G. Hinton e R. J. Williams, il quale modifica sistematicamente i pesi delle connessioni tra i nodi, cos\u00ec che la risposta della rete si avvicini sempre di pi\u00f9 a quella desiderata. Tale lavoro fu prodotto riprendendo il modello creato da Werbos. L'algoritmo di retropropagazione (\"backpropagation\" o BP) \u00e8 una tecnica d'apprendimento tramite esempi, costituente una generalizzazione dell'algoritmo d'apprendimento per il percettrone sviluppato da Rosenblatt nei primi anni '60. Mediante questa tecnica era possibile, come detto, trattare unicamente applicazioni caratterizzabili come funzioni booleane linearmente separabili.\nL'algoritmo di apprendimento si basa sul metodo della discesa del gradiente che permette di trovare un minimo locale di una funzione in uno spazio a N dimensioni. I pesi associati ai collegamenti tra gli strati di neuroni si inizializzano a valori piccoli (ovvero molto inferiori ai valori reali che poi assumeranno) e casuali e poi si applica la regola di apprendimento presentando alla rete dei pattern di esempio. Queste reti neurali sono poi capaci di generalizzare in modo appropriato, cio\u00e8 di dare risposte plausibili per input che non hanno mai visto.\nL'addestramento di une rete neurale di tipo BP avviene in due diversi stadi: \"forward-pass\" e \"backward-pass\". Nella prima fase i vettori in input sono applicati ai nodi in ingresso con una propagazione in avanti dei segnali attraverso ciascun livello della rete (\"forward-pass\"). Durante questa fase i valori dei pesi sinaptici sono tutti fissati. Nella seconda fase la risposta della rete viene confrontata con l'uscita desiderata ottenendo il segnale d'errore. L'errore calcolato \u00e8 propagato nella direzione inversa rispetto a quella delle connessioni sinaptiche. I pesi sinaptici infine sono modificati in modo da minimizzare la differenza tra l'uscita attuale e l'uscita desiderata (\"backward-pass\").\nTale algoritmo consente di superare le limitazioni del percettrone e di risolvere il problema della separabilit\u00e0 non lineare (e quindi di calcolare la funzione XOR), segnando il definitivo rilancio delle reti neurali, come testimoniato anche dall'ampia variet\u00e0 d'applicazioni commerciali: attualmente la BP rappresenta un algoritmo di largo uso in molti campi applicativi.\nUna rete neurale artificiale (ANN \"\"Artificial Neural Network\"\" in inglese), normalmente chiamata solo \"rete neurale\" (NN \"\"Neural Network\"\" in inglese), \u00e8 un modello matematico/informatico di calcolo basato sulle reti neurali biologiche. Tale modello \u00e8 costituito da un gruppo di interconnessioni di informazioni costituite da neuroni artificiali e processi che utilizzano un approccio di connessionismo di calcolo. Nella maggior parte dei casi una rete neurale artificiale \u00e8 un sistema adattivo che cambia la propria struttura in base a informazioni esterne o interne che scorrono attraverso la rete stessa durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare.\nUna rete neurale artificiale riceve segnali esterni su uno strato di nodi (unit\u00e0 di elaborazione) d'ingresso, ciascuno dei quali \u00e8 collegato con numerosi nodi interni, organizzati in pi\u00f9 livelli. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.\nIl concetto di rete neurale si pone perch\u00e9 una funzione formula_1 \u00e8 definita come una composizione di altre funzioni formula_2, che possono a loro volta essere ulteriormente definite come composizione di altre funzioni. Questo pu\u00f2 essere comodamente rappresentato come una struttura di reti, con le frecce raffiguranti le dipendenze tra variabili. Una rappresentazione ampiamente utilizzata \u00e8 la somma ponderata non lineare, dove formula_3, dove formula_4 \u00e8 una funzione predefinita, come ad esempio la tangente iperbolica. Sar\u00e0 conveniente per le seguenti far riferimento ad un insieme di funzioni come un vettore formula_5.\nLa Figura 1 esemplifica una decomposizione della funzione formula_6, con dipendenze tra le variabili indicate dalle frecce. Queste possono essere interpretate in due modi:\nI due punti di vista sono in gran parte equivalenti. In entrambi i casi, per questa particolare architettura di rete, i componenti dei singoli strati sono indipendenti l'uno dall'altro (ad esempio, le componenti di formula_8 sono indipendenti l'una dall'altra, dato il loro ingresso formula_15). Questo, naturalmente, permette un certo grado di parallelismo nella costruzione del sistema.\nReti, come ad esempio quelle precedenti vengono comunemente chiamate \"\"feedforward\"\", perch\u00e9 il loro \u00e8 un grafico aciclico diretto. Reti con cicli al loro interno sono comunemente chiamati reti ricorrenti. Tali reti sono comunemente raffigurate nel modo indicato nella parte superiore della Figura 2, dove la funzione formula_6 \u00e8 mostrata come dipendente su se stessa. Tuttavia, vi \u00e8 una dipendenza temporale implicita che non \u00e8 possibile dimostrare. Questo significa in pratica che il valore di formula_6 ad un certo punto nel tempo formula_18 dipende dai valori di formula_6 al tempo zero o su uno o pi\u00f9 altri punti temporali. Il modello del grafico nella parte inferiore della Figura 2 illustra il caso in cui il valore di formula_6 al tempo formula_18 dipende solo dal suo valore finale.\nTuttavia la funzionalit\u00e0 pi\u00f9 interessante di queste funzioni, ci\u00f2 che ha attirato l'interesse e lo studio per la maggior parte delle reti neurali, \u00e8 la possibilit\u00e0 di apprendimento, che in pratica significa la seguente:\nCi\u00f2 comporta la definizione di una funzione di costo formula_24 tale che, per la soluzione ottimale formula_25 formula_26 nessuna soluzione ha un costo inferiore al costo della soluzione ottimale.\nLa funzione di costo formula_27 \u00e8 un concetto importante nell'apprendimento, poich\u00e9 si tratta di una misura di quanto \u00e8 lontana da noi la soluzione ottimale del problema che vogliamo risolvere. Quindi vi sono una serie di algoritmi di apprendimento che cercano nello spazio delle soluzioni al fine di trovare una funzione che abbia il minor costo possibile.\nPer applicazioni in cui la soluzione dipende da alcuni dati, il costo deve essere necessariamente funzione delle osservazioni.\nMentre \u00e8 possibile definire per alcune reti una funzione di costo ad hoc, spesso si pu\u00f2 utilizzare una particolare funzione di costo poich\u00e9 gode delle propriet\u00e0 desiderate (ad esempio, la convessit\u00e0), o perch\u00e9 proviene da una particolare formulazione del problema (vale a dire, in una formulazione probabilistica, la probabilit\u00e0 a posteriori del modello pu\u00f2 essere utilizzata come l'inverso del costo). In ultima analisi, la funzione di costo dipender\u00e0 dal compito.\nVi sono tre grandi paradigmi di apprendimento, ciascuno corrispondente ad un particolare compito astratto di apprendimento. Si tratta dell'apprendimento supervisionato, apprendimento non supervisionato e l'apprendimento per rinforzo. Di solito un tipo di architettura di rete pu\u00f2 essere impiegato in qualsiasi di tali compiti.\nL'algoritmo di apprendimento hebbiano (1984) si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata.\nformula_28 dove formula_29,\ndove formula_30 \u00e8 l'formula_31 ingresso e formula_32 \u00e8 il tasso di apprendimento formula_33.\nLa regola di Hebb \u00e8 la seguente: l'efficacia di una particolare sinapsi cambia se e solo se c'\u00e8 un'intensa attivit\u00e0 simultanea dei due neuroni, con un'alta trasmissione di input nella sinapsi in questione.\nEsempio di procedura:\nIn questo modo le connessioni possono solo irrobustirsi.\nLe connessioni si considerano irrobustite quando le unit\u00e0 presinaptica e postsinaptica sono d'accordo, altrimenti si indeboliscono.\nSi considerano funzioni bipolari (-1,1) invece che booleane (0,1).\nLe reti neurali si basano principalmente sulla simulazione di neuroni artificiali opportunamente collegati. Il modello rappresentato in figura \u00e8 quello proposto da McCulloch e Pitts.\nI suddetti neuroni ricevono in ingresso degli stimoli e li elaborano. L'elaborazione pu\u00f2 essere anche molto sofisticata ma in un caso semplice si pu\u00f2 pensare che i singoli ingressi vengano moltiplicati per un opportuno valore detto peso, il risultato delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone si attiva attivando la sua uscita. Il peso indica l'efficacia sinaptica della linea di ingresso e serve a quantificarne l'importanza, un ingresso molto importante avr\u00e0 un peso elevato, mentre un ingresso poco utile all'elaborazione avr\u00e0 un peso inferiore. Si pu\u00f2 pensare che se due neuroni comunicano fra loro utilizzando maggiormente alcune connessioni allora tali connessioni avranno un peso maggiore, fino a che non si creeranno delle connessioni tra l'ingresso e l'uscita della rete che sfruttano \"percorsi preferenziali\". Tuttavia \u00e8 sbagliato pensare che la rete finisca col produrre un unico percorso di connessione: tutte le combinazioni infatti avranno un certo peso, e quindi contribuiscono al collegamento ingresso/uscita.\nIl modello in figura rappresenta una classica rete neurale pienamente connessa.\nI singoli neuroni vengono collegati alla schiera di neuroni successivi, in modo da formare una rete di neuroni. Normalmente una rete \u00e8 formata da tre strati. Nel primo abbiamo gli ingressi (I), questo strato si preoccupa di trattare gli ingressi in modo da adeguarli alle richieste dei neuroni. Se i segnali in ingresso sono gi\u00e0 trattati pu\u00f2 anche non esserci. Il secondo strato \u00e8 quello nascosto (H, \"hidden\"), si preoccupa dell'elaborazione vera e propria e pu\u00f2 essere composto anche da pi\u00f9 colonne di neuroni. Il terzo strato \u00e8 quello di uscita (O) e si preoccupa di raccogliere i risultati ed adattarli alle richieste del blocco successivo della rete neurale. Queste reti possono essere anche molto complesse e coinvolgere migliaia di neuroni e decine di migliaia di connessioni.\nPer costruire la struttura di una rete neurale multistrato si possono inserire formula_38 strati \"hidden.\" L'efficacia di generalizzare di una rete neurale multistrato dipende ovviamente dall'addestramento che ha ricevuto e dal fatto di essere riuscita o meno ad entrare in un minimo locale buono.\nL'algoritmo di retropropagazione dell'errore (\"backpropagation\") \u00e8 utilizzato nell'apprendimento con supervisione. Esso permette di modificare i pesi delle connessioni in modo tale che si minimizzi una certa funzione errore E. Tale funzione dipende dal vettore h-esimo di output formula_39 restituito dalla rete, dato il vettore h-esimo di ingresso formula_40 e dal vettore h-esimo di output formula_41che noi desideriamo (che fa parte del training set). Il training set \u00e8 dunque un insieme di N coppie di vettori formula_42, con formula_43. La funzione errore che si deve minimizzare si pu\u00f2 scrivere come:\nformula_44\ndove l'indice k rappresenta il valore corrispondente al k-esimo neurone di output. E(w) \u00e8 una funzione dipendente dai pesi (che in generale variano nel tempo), per minimizzarla si pu\u00f2 usare l'algoritmo della discesa del gradiente (\"gradient descent\"). L'algoritmo parte da un punto generico formula_45 e calcola il gradiente formula_46. Il gradiente d\u00e0 la direzione verso cui muoversi lungo la quale si ha il massimo incremento (o decremento se considero formula_47). Definita la direzione ci si muove di una distanza formula_32 predefinita a priori e si trova un nuovo punto formula_49 sul quale \u00e8 calcolato nuovamente il gradiente. Si continua iterativamente finch\u00e9 il gradiente non \u00e8 nullo.\nL'algoritmo di backpropagation pu\u00f2 essere diviso in due passi:\nI passi logici per addestrare una rete neurale con apprendimento supervisionato sono i seguenti:\nPer l'addestramento di reti neurali profonde, impiegando dataset molto vasti, la discesa del gradiente classica risulta computazionalmente proibitiva, per cui nell'ottimizzare i parametri del modello si fa tipicamente uso dell'algoritmo di discesa stocastica del gradiente.\nNel 1982, il fisico John J. Hopfield pubblica un articolo fondamentale in cui presenta un modello matematico comunemente noto appunto come rete di Hopfield: tale rete si distingue per \"l'emergere spontaneo di nuove capacit\u00e0 computazionali dal comportamento collettivo di un gran numero di semplici elementi d'elaborazione\". Le propriet\u00e0 collettive del modello producono una memoria associativa per il riconoscimento di configurazioni corrotte e il recupero di informazioni mancanti.\nInoltre, Hopfield ritiene che ogni sistema fisico possa essere considerato come un potenziale dispositivo di memoria, qualora esso disponga di un certo numero di stati stabili, i quali fungano da attrattore per il sistema stesso. Sulla base di tale considerazione, egli si spinge a formulare la tesi secondo cui la stabilit\u00e0 e la collocazione di tali attrattori sono propriet\u00e0 spontanee di sistemi costituiti, come accennato, da considerevoli quantit\u00e0 di neuroni reciprocamente interagenti.\nLe applicazioni delle reti di Hopfield riguardano principalmente la realizzazione di memorie associative, resistenti all'alterazione delle condizioni operative, e la soluzione di problemi d'ottimizzazione combinatoriale.\nDa un punto di vista strutturale, la rete di Hopfield costituisce una rete neurale ricorrente simmetrica, di cui \u00e8 garantita la convergenza.\nUna rete ricorrente \u00e8 un modello neurale in cui \u00e8 presente un flusso bidirezionale d'informazioni; in altri termini, mentre nelle reti di tipo feedforward la propagazione dei segnali avviene unicamente, in maniera continua, nella direzione che conduce dagli ingressi alle uscite, nelle reti ricorrenti tale propagazione pu\u00f2 anche manifestarsi da uno strato neurale successivo ad uno precedente, oppure tra neuroni appartenenti ad uno stesso strato, e persino tra un neurone e s\u00e9 stesso.\nUn significativo e noto esempio di semplice rete ricorrente \u00e8 dovuto a Jeffrey L. Elman (1990). Essa costituisce una variazione sul tema del percettrone multistrato, con esattamente tre strati e l'aggiunta di un insieme di neuroni \"contestuali\" nello strato d'ingresso. Le connessioni retroattive si propagano dallo strato intermedio (e nascosto) a tali unit\u00e0 contestuali, alle quali si assegna peso costante e pari all'unit\u00e0.\nIn ciascun istante, gli ingressi si propagano nel modo tradizionale e tipico delle reti feedforward, compresa l'applicazione dell'algoritmo d'apprendimento (solitamente la \"backpropagation\"). Le connessioni retroattive fisse hanno come effetto quello di mantenere una copia dei precedenti valori dei neuroni intermedi, dal momento che tale flusso avviene sempre prima della fase d'apprendimento.\nIn questo modo la rete di Elman tiene conto del suo stato precedente, cosa che le consente di svolgere compiti di previsione di sequenze temporali che sono difficilmente alla portata dei percettroni multistrato convenzionali.\nInfine, un ultimo interessante tipo di rete \u00e8 costituita dalla cosiddetta mappa auto-organizzante o rete SOM (\"Self-Organizing Map\"). Tale innovativo tipo di rete neurale \u00e8 stata elaborata da Teuvo Kohonen dell'Universit\u00e0 Tecnologica di Helsinki; il suo algoritmo d'apprendimento \u00e8 senza dubbio una brillante formulazione di apprendimento non supervisionato, e ha dato luogo a un gran numero di applicazioni nell'ambito dei problemi di classificazione. Una mappa o rete SOM \u00e8 basata essenzialmente su un reticolo o griglia di neuroni artificiali i cui pesi sono continuamente adattati ai vettori presentati in ingresso nel relativo insieme di addestramento. Tali vettori possono essere di dimensione generica, anche se nella maggior parte delle applicazioni essa \u00e8 piuttosto alta. Per ci\u00f2 che riguarda le uscite della rete, al contrario, ci si limita di solito ad una dimensione massima pari a tre, il che consente di dare luogo a mappe 2D o 3D.\nIn termini pi\u00f9 analitici, l'algoritmo pu\u00f2 essere agevolmente descritto, come accennato, nei termini di un insieme di neuroni artificiali, ciascuno con una precisa collocazione sulla mappa rappresentativa degli \"output\", che prendono parte ad un processo noto come \"winner takes all\" (\"Il vincitore piglia tutto\"), al termine del quale il nodo avente un vettore di pesi pi\u00f9 vicino ad un certo \"input\" \u00e8 dichiarato vincitore, mentre i pesi stessi sono aggiornati in modo da avvicinarli al vettore in ingresso. Ciascun nodo ha un certo numero di nodi adiacenti. Quando un nodo vince una competizione, anche i pesi dei nodi adiacenti sono modificati, secondo la regola generale che pi\u00f9 un nodo \u00e8 lontano dal nodo vincitore, meno marcata deve essere la variazione dei suoi pesi. Il processo \u00e8 quindi ripetuto per ogni vettore dell'insieme di \"training\", per un certo numero, solitamente grande, di cicli. Va da s\u00e9 che ingressi diversi producono vincitori diversi.\nOperando in tal modo, la mappa riesce alfine ad associare i nodi d'uscita con i gruppi o schemi ricorrenti nell'insieme dei dati in ingresso. Se questi schemi sono riconoscibili, essi possono essere associati ai corrispondenti nodi della rete addestrata. In maniera analoga a quella della maggioranza delle reti neurali artificiali, anche la mappa o rete SOM pu\u00f2 operare in due distinte modalit\u00e0:\nIn generale una ANN (\"Attractor Neural Network\") \u00e8 una rete di nodi (es: biologicamente ispirati), spesso interconnessi in modo ricorsivo, la cui dinamica nel tempo stabilisce un assestamento in un particolare modo di oscillazione. Questo modo di oscillazione pu\u00f2 essere stazionario, variante nel tempo o di tipo stocastico ed \u00e8 chiamato il suo 'attrattore'. In neuroscienza teorica diversi tipi di reti ad attrattori sono state associate a differenti funzioni, come: memoria, attenzione, condotta del moto e classificazione.\nPi\u00f9 precisamente, una rete ad attrattori \u00e8 una rete di N nodi connessi in modo che la loro intera dinamica diventi stabile in uno spazio D dimensionale, dove solitamente N\u00bbD. Ci\u00f2 assume che non vi sia pi\u00f9 input dall'esterno del sistema. La stabilit\u00e0 nello stato ad attrattore indica l'esistenza di uno stato stabile in una qualche variet\u00e0 algebrica (es: linea, cerchio, piano, toroide).\nL'utilit\u00e0 dei modelli di rete neurale sta nel fatto che queste possono essere usate per comprendere una funzione utilizzando solo le osservazioni sui dati. Ci\u00f2 \u00e8 particolarmente utile nelle applicazioni in cui la complessit\u00e0 dei dati o la difficolt\u00e0 di elaborazione rende la progettazione di una tale funzione impraticabile con i normali procedimenti di analisi manuale.\nI compiti a cui le reti neurali sono applicate possono essere classificate nelle seguenti grandi categorie di applicazioni:\nLe aree di applicazione includono i sistemi di controllo (controllo di veicoli, controllo di processi), simulatori di giochi e processi decisionali (backgammon, scacchi), riconoscimento di pattern (sistemi radar, identificazione di volti, riconoscimento di oggetti, ecc), riconoscimenti di sequenze (riconoscimento di gesti, riconoscimento vocale, OCR), diagnosi medica, applicazioni finanziarie, data mining, filtri spam per e-mail.\nLe reti neurali per come sono costruite lavorano in parallelo e sono quindi in grado di trattare molti dati. Si tratta in sostanza di un sofisticato sistema di tipo statistico dotato di una buona immunit\u00e0 al rumore; se alcune unit\u00e0 del sistema dovessero funzionare male, la rete nel suo complesso avrebbe delle riduzioni di prestazioni ma difficilmente andrebbe incontro ad un blocco del sistema. I software di ultima generazione dedicati alle reti neurali richiedono comunque buone conoscenze statistiche; il grado di apparente utilizzabilit\u00e0 immediata non deve trarre in inganno, pur permettendo all'utente di effettuare subito previsioni o classificazioni, seppure con i limiti del caso.\nDa un punto di vista industriale, risultano efficaci quando si dispone di dati storici che possono essere trattati con gli algoritmi neurali. Ci\u00f2 \u00e8 di interesse per la produzione perch\u00e9 permette di estrarre dati e modelli senza effettuare ulteriori prove e sperimentazioni.\nI modelli prodotti dalle reti neurali, anche se molto efficienti, non sono spiegabili in linguaggio simbolico umano: i risultati vanno accettati \"cos\u00ec come sono\", da cui anche la definizione inglese delle reti neurali come \"black box\": in altre parole, a differenza di un sistema algoritmico, dove si pu\u00f2 esaminare passo-passo il percorso che dall'input genera l'output, una rete neurale \u00e8 in grado di generare un risultato valido, o comunque con una alta probabilit\u00e0 di essere accettabile, ma non \u00e8 possibile spiegare come e perch\u00e9 tale risultato sia stato generato.\nCome per qualsiasi algoritmo di modellazione, anche le reti neurali sono efficienti solo se le variabili predittive sono scelte con cura.\nNon sono in grado di trattare in modo efficiente variabili di tipo categorico (per esempio, il nome della citt\u00e0) con molti valori diversi. Necessitano di una fase di addestramento del sistema che fissi i pesi dei singoli neuroni e questa fase pu\u00f2 richiedere molto tempo, se il numero dei record e delle variabili analizzate \u00e8 molto grande. Non esistono teoremi o modelli che permettano di definire la rete ottima, quindi la riuscita di una rete dipende molto dall'esperienza del creatore.\nLe reti neurali vengono solitamente usate in contesti dove i dati possono essere parzialmente errati oppure dove non esistano modelli analitici in grado di affrontare il problema. Un loro tipico utilizzo \u00e8 nei software di OCR, nei sistemi di riconoscimento facciale e pi\u00f9 in generale nei sistemi che si occupano di trattare dati soggetti a errori o rumore. Esse sono anche uno degli strumenti maggiormente utilizzati nelle analisi di Data mining.\nLe reti neurali vengono anche utilizzate come mezzo per previsioni nell'analisi finanziaria o meteorologica. Negli ultimi anni \u00e8 aumentata notevolmente la loro importanza anche nel campo della bioinformatica nel quale vengono utilizzate per la ricerca di pattern funzionali e/o strutturali in proteine e acidi nucleici. Mostrando opportunamente una lunga serie di input (fase di training o apprendimento), la rete \u00e8 in grado di fornire l'output pi\u00f9 probabile. Negli ultimi anni inoltre sono in corso studi per il loro utilizzo nella previsione degli attacchi Epilettici (Analisi dei Dati provenienti dall' EEG).\nRecenti studi hanno dimostrato buone potenzialit\u00e0 delle reti neurali in sismologia per la localizzazione di epicentri di terremoti e predizione della loro intensit\u00e0."], "concept_B": "Rete neurale artificiale", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_A": "K-means", "wikipedia_passage_concept_B": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_B": "Data mining", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["2735", "Mediana (statistica)", "In statistica, in particolare in statistica descrittiva, data una distribuzione di un carattere quantitativo oppure qualitativo ordinabile (ovvero le cui modalit\u00e0 possano essere ordinate in base a qualche criterio), si definisce la mediana (o valore mediano) come il valore/modalit\u00e0 (o l'insieme di valori/modalit\u00e0) assunto dalle unit\u00e0 statistiche che si trovano nel mezzo della distribuzione.\nLa mediana \u00e8 un indice di posizione e rientra nell'insieme delle statistiche d'ordine.\nIl termine \"mediano\" venne introdotto da Antoine Augustin Cournot e adottato da Francis Galton.\nGustav Theodor Fechner svilupp\u00f2 l'uso della mediana come sostituto della media in quanto riteneva che il calcolo della media fosse troppo laborioso rispetto al vantaggio in termini di precisioni che offriva.\nSe si procede al riordinamento delle unit\u00e0 in base ai valori crescenti del carattere da esse detenuto, in sostanza la mediana bipartisce la distribuzione in due sotto-distribuzioni: la prima a sinistra della mediana (costituita dalla met\u00e0 delle unit\u00e0 la cui modalit\u00e0 \u00e8 minore o uguale alla mediana) e la seconda a destra della mediana (costituita dalla met\u00e0 delle unit\u00e0 la cui modalit\u00e0 \u00e8 maggiore o uguale alla mediana). Tecnicamente si afferma che la mediana \u00e8 il valore/modalit\u00e0 per il quale la frequenza relativa cumulata vale (o supera) 0,5, cio\u00e8 il secondo quartile, ossia il 50\u00b0 percentile. Usualmente si indica la mediana con Me.\nPer calcolare la mediana di formula_1 dati:\nSe le modalit\u00e0 sono raggruppate in classi non si definisce un valore univoco, ma una classe mediana formula_7.\nLa determinazione di tale classe avviene considerando le frequenze cumulate; indicando con formula_8 la generica frequenza cumulata relativa dell'osservazione i-esima sar\u00e0:formula_9 e formula_10. Pur essendo corretto considerare un qualsiasi elemento dell'intervallo formula_7 un valore mediano si \u00e8 soliti procedere, al fine di avere una misura unica del valore, a un'approssimazione della mediana con la seguente formula:\nse si assume che la distribuzione dei dati all'interno della classe sia uniforme, che corrisponde ad un processo di interpolazione.\nUna propriet\u00e0 della mediana \u00e8 di rendere minima la somma dei valori assoluti degli scarti delle formula_13 da un generico valore\nInfatti, sia formula_15 la variabile aleatoria alla quale si riferiscono le osservazioni formula_13. Per la linearit\u00e0 del valore atteso e dell'operatore di derivazione si ha\ndove formula_18 \u00e8 la funzione segno di formula_19. Per la definizione di valore atteso\ndove formula_21 indica la probabilit\u00e0 che formula_15 sia minore di formula_23 e formula_24 quella che formula_15 sia maggiore di formula_23. Per le propriet\u00e0 di normalizzazione della probabilit\u00e0, cio\u00e8 formula_27, l'equazione diventa\nQuindi\ncio\u00e8 formula_23 \u00e8 la mediana.\nIn un sondaggio fatto all'interno di una facolt\u00e0 composta da 250 studenti (la popolazione statistica), si intende rilevare il carattere \"Gradimento dei professori\", secondo le cinque modalit\u00e0 \"molto deluso\", \"insoddisfatto\", \"parzialmente soddisfatto\", \"soddisfatto\", \"entusiasta\". Risulta che 10 studenti si dicono entusiasti dell'operato dei professori, 51 si dicono soddisfatti, 63 parzialmente soddisfatti, 90 insoddisfatti, 36 molto delusi.\nLa distribuzione di frequenza viene rappresentata con una tabella come la seguente:\nNel caso ipotizzato, la mediana \u00e8 rappresentata dalla modalit\u00e0 \"insoddisfatto\". Questo significa che \"almeno\" la met\u00e0 degli studenti non \u00e8 soddisfatto dei professori."], "concept_A": "Mediana (statistica)", "wikipedia_passage_concept_B": ["3854", "Scarto interquartile", "In statistica lo scarto interquartile (o differenza interquartile o ampiezza interquartile, in inglese \"interquartile range\" o \"IQR\") \u00e8 la differenza tra il terzo e il primo quartile, ovvero l'ampiezza della fascia di valori che contiene la met\u00e0 \"centrale\" dei valori osservati.\nLo scarto interquartile \u00e8 un indice di dispersione, cio\u00e8 una misura di quanto i valori si allontanino da un valore centrale. Viene utilizzato nel disegno del diagramma box-plot.\nLo scarto interquartile di una variabile aleatoria si ottiene tramite la funzione di ripartizione, come differenza formula_1\nPer una variabile casuale normale formula_2 lo scarto interquartile \u00e8 circa formula_3.\nPer una variabile casuale di Cauchy formula_4 lo scarto interquartile \u00e8 formula_5."], "concept_B": "Scarto interquartile", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["40388", "Funzione di densit\u00e0 di probabilit\u00e0", "In matematica, una funzione di densit\u00e0 di probabilit\u00e0 (o PDF dall'inglese \"probability density function\") \u00e8 l'analogo della funzione di probabilit\u00e0 di una variabile casuale nel caso in cui la variabile casuale formula_1 sia continua, cio\u00e8 l'insieme dei possibili valori che ha la potenza del continuo.\nEssa descrive la \"densit\u00e0\" di probabilit\u00e0 in ogni punto nello spazio campionario.\nLa funzione di densit\u00e0 di probabilit\u00e0 di una variabile casuale formula_1 \u00e8 un'applicazione formula_3 non negativa integrabile secondo Lebesgue e reale di variabile reale tale che la probabilit\u00e0 dell'insieme \"A\" sia data da\nper tutti i sottinsiemi \"A\" dello spazio campionario.\nIntuitivamente, se una distribuzione di probabilit\u00e0 ha densit\u00e0 formula_3, allora l'intervallo formula_6 ha probabilit\u00e0 formula_7. Da ci\u00f2 deriva che la funzione formula_3 \u00e8 un'applicazione definita come\nAssumendo formula_10, ci\u00f2 corrisponde al limite della probabilit\u00e0 che formula_11 si trovi nell'intervallo formula_6 per formula_13 che tende a zero. Di qui il nome di funzione di 'densit\u00e0', in quanto essa rappresenta il rapporto tra una probabilit\u00e0 e un'ampiezza.\nPer la condizione di normalizzazione l'integrale su tutto lo spazio di formula_3 deve essere 1. Di conseguenza ogni funzione non negativa, integrabile secondo Lebesgue, con integrale su tutto lo spazio uguale a 1, \u00e8 la funzione densit\u00e0 di probabilit\u00e0 di una ben definita distribuzione di probabilit\u00e0. Una variabile casuale che possiede densit\u00e0 si dice \"variabile casuale continua\".\nPer le variabili casuali multivariate (o vettoriali) la trattazione formale \u00e8 assolutamente identica: formula_15 si dice assolutamente continua se esiste una funzione a valori reali definita in formula_16, detta densit\u00e0 congiunta, tale che per ogni sottoinsieme \"A\" dello spazio campionario\nEssa conserva tutte le propriet\u00e0 di una densit\u00e0 scalare: \u00e8 una funzione non negativa a integrale unitario su tutto lo spazio. Una propriet\u00e0 importante \u00e8 che se formula_15 \u00e8 assolutamente continua allora lo \u00e8 ogni sua componente; il viceversa invece non vale. La densit\u00e0 di una componente, detta densit\u00e0 marginale, si ottiene con un ragionamento analogo al teorema della probabilit\u00e0 assoluta, cio\u00e8 fissando l'insieme di suoi valori di cui si vuole determinare la probabilit\u00e0 e lasciando libere di variare tutte le altre componenti. Infatti (nel caso bivariato per semplicit\u00e0) l'evento formula_19 \u00e8 l'evento formula_20, dunque\nutilizzando il teorema di Fubini. La densit\u00e0 marginale di formula_1 \u00e8 data dunque da\nLa funzione di densit\u00e0 della variabile casuale normale di media 0\ne varianza 1 (detta \"normale standard\"), di cui a destra \u00e8 riportato il grafico e l'espressione analitica della corrispondente densit\u00e0 nel caso generico (media formula_24 e varianza formula_25).\nUn altro esempio pu\u00f2 essere dato dalla densit\u00e0 di probabilit\u00e0 uniforme su un segmento (0,1). Si pu\u00f2 verificare immediatamente che \u00e8 densit\u00e0 di probabilit\u00e0 facendo l'integrale tra (0,1)."], "concept_A": "Funzione di densit\u00e0 di probabilit\u00e0", "wikipedia_passage_concept_B": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_B": "Rete bayesiana", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_A": "Outlier", "wikipedia_passage_concept_B": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_B": "Data mining", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["1103542", "K-medoids", "\u00e8 un algoritmo di clustering partizionale correlato all'algoritmo K-means. Prevede in input un insieme di n oggetti e un numero k che determina quanti cluster si vogliono in output.\nEntrambi gli algoritmi sono partizionali (suddividendo il dataset in gruppi) ed entrambi cercano di minimizzare l'errore quadratico medio, la distanza tra punti di un cluster e il punto designato per esserne il centro. In K-means il punto \u00e8 \"artificiale\" \u2014 \u00e8 la pura media di tutti i punti nel cluster. Nel K-medoids \u00e8 usato il punto collocato pi\u00f9 centralmente, in questo modo il centro \u00e8 uno dei datapoint attuali. K-medoids \u00e8 pi\u00f9 robusto al rumore e agli outlier rispetto al k-means.\nUn medoid pu\u00f2 essere definito come un oggetto di un cluster la cui dissimilarit\u00e0 media rispetto a tutti gli oggetti nel cluster \u00e8 minima, in questo modo esso sar\u00e0 il punto pi\u00f9 centrale di un dato dataset.\nL'algoritmo di clustering \u00e8 il seguente:\nSi deve clusterizzare il seguente data set di 10 oggetti in 2 cluster, quindi n \u00e8 10 e k \u00e8 2:\nSi inizializzano i k centri.\nAssumiamo che C1=(3,4) e C2=(7,4) siano i nostri medoid iniziali.\nCalcoliamo la distanza cos\u00ec da associare ogni data object al suo medoid pi\u00f9 vicino.\nIniziamo quindi il clustering:\nEssendo (3,4) (2,6) (3,8) e (4,7) punti vicini a c1 essi formeranno un cluster mentre i punti rimanenti ne formeranno un altro.\nIl costo totale sar\u00e0 20.\nIl costo tra 2 punti qualsiasi \u00e8 trovato usando la formula\nformula_1\nIl costo totale \u00e8 la somma dei costi per gli oggetti dal proprio medoid.\nCosto totale= {cost((3,4),(2,6)) + cost((3,4),(3,8)) + cost((3,4),(4,7))} + {cost((7,4),(6,2)) + cost((7,4),(6,4)) + cost((7,4),(7,3)) + cost((7,4),(8,5)) + cost((7,4),(7,6))} = 3 + 4 + 4 + 3 + 1 + 1 + 2 + 2 = 20\nSelezione di un nonmedoid O' in modo casuale.\nAssumiamo O'=(7,3)\nI medoid sono quindi c1(3,4) e O'(7,3).\nSe c1 e O' sono nuovi medoid, si calcola il costo totale usando la formula al passo 1.\nCosto totale = 3 + 4 + 4 + 2 + 2 + 1 + 3 + 3 = 22\nCos\u00ec il costo per cambiare il medoid da c2 a O' sar\u00e0:\nS = Costo totale attuale \u2013 Costo totale precedente = 22 - 20 = 2 > 0\nQuindi cambiare medoid in O' non \u00e8 una buona idea, la scelta precedente \u00e8 stata buona e l'algoritmo termina in questo punto (in quanto non ci sono cambiamenti per i medoid).\nPu\u00f2 accadere che qualche data point possa migrare da un cluster ad un altro, ci\u00f2 dipende dalla vicinanza rispetto al nuovo medoid scelto."], "concept_B": "K-medoids", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["605", "Apprendimento automatico", "L\u2019apprendimento automatico (noto anche come machine learning) \u00e8 una branca dell'intelligenza artificiale che raccoglie un insieme di metodi, sviluppati a partire dagli ultimi decenni del XX secolo in varie comunit\u00e0 scientifiche, sotto diversi nomi quali: statistica computazionale, riconoscimento di pattern, reti neurali artificiali, filtraggio adattivo, teoria dei sistemi dinamici, elaborazione delle immagini, data mining, algoritmi adattivi, ecc; che utilizza metodi statistici per migliorare progressivamente la performance di un algoritmo nell'identificare pattern nei dati. Nell'ambito dell'informatica, l'apprendimento automatico \u00e8 una variante alla programmazione tradizionale nella quale si predispone in una macchina l'abilit\u00e0 di apprendere qualcosa dai dati in maniera autonoma, senza ricevere istruzioni esplicite a riguardo.\nLo stesso Arthur Samuel che coni\u00f2 il termine nel 1959 in linea di principio identifica due approcci distinti. Il primo metodo, indicato come rete neurale, porta allo sviluppo di macchine ad apprendimento automatico per impiego generale in cui il comportamento \u00e8 appreso da una rete di commutazione connessa casualmente, a seguito di una routine di apprendimento basata su ricompensa e punizione (apprendimento per rinforzo). Il secondo metodo, pi\u00f9 specifico, consiste nel riprodurre l'equivalente di una rete altamente organizzata progettata per imparare solo alcune attivit\u00e0 specifiche. La seconda procedura, che necessita di supervisione, richiede la riprogrammazione per ogni nuova applicazione, ma risulta essere molto pi\u00f9 efficiente dal punto di vista computazionale.\nL'apprendimento automatico \u00e8 strettamente legato al riconoscimento di pattern e alla teoria computazionale dell'apprendimento ed esplora lo studio e la costruzione di algoritmi che possano apprendere da un insieme di dati e fare delle predizioni su questi, costruendo in modo induttivo un modello basato su dei campioni. L'apprendimento automatico viene impiegato in quei campi dell'informatica nei quali progettare e programmare algoritmi espliciti \u00e8 impraticabile; tra le possibili applicazioni citiamo il filtraggio delle email per evitare spam, l'individuazione di intrusioni in una rete o di intrusi che cercano di violare dati, il riconoscimento ottico dei caratteri, i motori di ricerca e la visione artificiale.\nL'apprendimento automatico \u00e8 strettamente collegato, e spesso si sovrappone con la statistica computazionale, che si occupa dell'elaborazione di predizioni tramite l'uso di computer. L'apprendimento automatico \u00e8 anche fortemente legato all'ottimizzazione matematica, che fornisce metodi, teorie e domini di applicazione a questo campo. Per usi commerciali, l'apprendimento automatico \u00e8 conosciuto come analisi predittiva.\nL'apprendimento automatico si sviluppa con lo studio dell'intelligenza artificiale, e vi \u00e8 strettamente collegato: infatti gi\u00e0 dai primi tentativi di definire l'intelligenza artificiale come disciplina accademica, alcuni ricercatori si erano mostrati interessati alla possibilit\u00e0 che le macchine imparassero dai dati. Questi ricercatori, in particolare Marvin Minsky, Arthur Samuel e Frank Rosenblatt, provarono ad avvicinarsi al problema sia attraverso vari metodi formali, sia con quelle che vengono definite reti neurali nei tardi anni '50. Le reti neurali erano allora costituite da singoli percettroni e da modelli matematici derivati dal modello lineare generalizzato della statistica, come l'ADALINE di Widrow. Si prov\u00f2 a sfruttare anche ragionamenti probabilistici, in particolare nelle diagnosi mediche automatiche.\nSempre negli anni '50, Alan Turing propose l'idea di una \"macchina che apprende\", ovvero in grado di imparare e dunque diventare intelligente. La proposta specifica di Turing anticipa gli algoritmi genetici.\nTuttavia gi\u00e0 dalla met\u00e0 degli anni '50 lo studio dell'intelligenza artificiale si stava concentrando su approcci logici di tipo \"knowledge-based\", nota oggi sotto il nome di GOFAI, causando un distacco tra lo studio dell'IA e quello dell'apprendimento automatico. Sistemi di tipo probabilistico erano invasi di problemi sia teoretici sia pratici in termini di acquisizione e rappresentazione dei dati. Negli anni Ottanta, i sistemi esperti dominavano il campo dell'IA, e i sistemi basati sulla statistica non venivano pi\u00f9 studiati.\nLo studio dell'apprendimento simbolico e \"knowledge-based\" continu\u00f2 nell'ambito dell'IA, portando a sviluppare la programmazione logica induttiva, ma ora la ricerca pi\u00f9 prettamente statistica si svolgeva al di fuori del campo vero e proprio dell'intelligenza artificiale, nel riconoscimento di pattern e nell'information retrieval.\nUn altro motivo per cui lo studio dell'apprendimento automatico fu abbandonato fu la pubblicazione del libro \"Perceptrons: an introduction to computational geometry\" di Marvin Minsky e Seymour Papert, che vi descrivevano alcune delle limitazioni dei percettroni e delle reti neurali. La ricerca sulle reti neurali sub\u00ec un significativo rallentamento a causa dell'interpretazione del libro, che le descriveva come intrinsecamente limitate. Anche la linea di ricerca sulle reti neurali continu\u00f2 al di fuori del campo dell'IA, portata avanti da ricercatori provenienti da altre discipline quali Hopfield, Rumelhart, Hinton e Fukushima. Il loro successo principale fu a met\u00e0 degli anni '80 con la riscoperta della \"backpropagation\" e della self-organization.\nL'apprendimento automatico, sviluppatosi come campo di studi separato dall'IA classica, cominci\u00f2 a rifiorire negli anni '90. Il suo obiettivo cambi\u00f2 dall'ottenere l'intelligenza artificiale ad affrontare problemi risolvibili di natura pratica. Distolse inoltre la propria attenzione dagli approcci simbolici che aveva ereditato dall'IA, e si diresse verso metodi e modelli presi in prestito dalla statistica e dalla teoria della probabilit\u00e0. L'apprendimento automatico ha inoltre beneficiato dalla nascita di Internet, che ha reso l'informazione digitale pi\u00f9 facilmente reperibile e distribuibile.\nTom M. Mitchell ha fornito la definizione pi\u00f9 citata di apprendimento automatico nel suo libro \"\"Machine Learning\"\": \"\"Si dice che un programma apprende dall'esperienza E con riferimento a alcune classi di compiti T e con misurazione della performance P, se le sue performance nel compito T, come misurato da P, migliorano con l'esperienza E.\"\" In poche parole, si potrebbe semplificare dicendo che un programma apprende se c'\u00e8 un miglioramento delle prestazioni dopo un compito svolto. Questa definizione di Mitchell \u00e8 rilevante poich\u00e9 fornisce una definizione operativa dell'apprendimento automatico, invece che in termini cognitivi. Fornendo questa definizione, Mitchell di fatto segue la proposta che Alan Turing fece nel suo articolo \"\"Computing Machinery and Intelligence\"\", sostituendo la domanda \"\"Le macchine possono pensare?\"\" con la domanda \"\"Le macchine possono fare quello che noi (in quanto entit\u00e0 pensanti) possiamo fare?\"\".\nL'obiettivo principe dell'apprendimento automatico \u00e8 che una macchina sia in grado di generalizzare dalla propria esperienza, ossia che sia in grado di svolgere ragionamenti induttivi. In questo contesto, per generalizzazione si intende l'abilit\u00e0 di una macchina di portare a termine in maniera accurata esempi o compiti nuovi, che non ha mai affrontato, dopo aver fatto esperienza su un insieme di dati di apprendimento. Gli esempi di addestramento (in inglese chiamati \"training examples\") si assume provengano da una qualche distribuzione di probabilit\u00e0, generalmente sconosciuta e considerata rappresentativa dello spazio delle occorrenze del fenomeno da apprendere; la macchina ha il compito di costruire un modello probabilistico generale dello spazio delle occorrenze, in maniera tale da essere in grado di produrre previsioni sufficientemente accurate quando sottoposta a nuovi casi.\nL'analisi computazionale degli algoritmi di apprendimento automatico e delle loro prestazioni \u00e8 una branca dell'Informatica teorica chiamata teoria dell'apprendimento. Dato che gli esempi di addestramento sono insiemi finiti di dati e non c'\u00e8 modo di sapere l'evoluzione futura di un modello, la teoria dell'apprendimento non offre alcuna garanzia sulle prestazioni degli algoritmi. D'altro canto, \u00e8 piuttosto comune che tali prestazioni siano vincolate da limiti probabilistici. Il bias-variance tradeoff \u00e8 uno dei modi di quantificare l'errore di generalizzazione.\nAffinch\u00e9 la generalizzazione offra le migliori prestazioni possibili, la complessit\u00e0 dell'ipotesi induttiva deve essere pari alla complessit\u00e0 della funzione sottostante i dati. Se l'ipotesi \u00e8 meno complessa della funzione, allora il modello manifesta \"underfitting\". Quando la complessit\u00e0 del modello viene aumentata in risposta, allora l'errore di apprendimento diminuisce. Al contrario invece se l'ipotesi \u00e8 troppo complessa, allora il modello manifesta overfitting e la generalizzazione sar\u00e0 pi\u00f9 scarsa.\nOltre ai limiti di prestazioni, i teorici dell'apprendimento studiano la complessit\u00e0 temporale e la fattibilit\u00e0 dell'apprendimento stesso. Una computazione \u00e8 considerata fattibile se pu\u00f2 essere svolta in tempo polinomiale.\nI compiti dell'apprendimento automatico vengono tipicamente classificati in tre ampie categorie, a seconda della natura del \"segnale\" utilizzato per l'apprendimento o del \"feedback\" disponibile al sistema di apprendimento. Queste categorie, anche dette paradigmi, sono:\nA met\u00e0 strada tra l'apprendimento supervisionato e quello non supervisionato c'\u00e8 l'apprendimento semi-supervisionato, nel quale l'insegnante fornisce un dataset incompleto per l'allenamento, cio\u00e8 un insieme di dati per l'allenamento tra i quali ci sono dati senza il rispettivo output desiderato. La trasduzione \u00e8 un caso speciale di questo principio, nel quale l'intero insieme delle istanze del problema \u00e8 noto durante l'apprendimento, eccetto la parte degli output desiderati che \u00e8 mancante.\nUn'altra categorizzazione dei compiti dell'apprendimento automatico si rileva quando si considera l'output desiderato del sistema di apprendimento automatico.\nL'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo Michael I. Jordan, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. Jordan ha anche suggerito il termine data science come nome con cui chiamare l'intero campo di studi.\nLeo Breiman ha distinto due paradigmi statistici di modellazione: modello basato sui dati e modello basato sugli algoritmi, dove \"modello basato sugli algoritmi\" indica approssimativamente algoritmi di apprendimento automatico come la foresta casuale.\nAlcuni statistici hanno adottato metodi provenienti dall'apprendimento automatico, il che ha portato alla creazione di una disciplina combinata chiamata \"apprendimento statistico\".\nL'apprendimento automatico viene a volte unito al data mining, che si focalizza maggiormente sull'analisi esplorativa dei dati ed utilizza principalmente il paradigma di apprendimento chiamato \"apprendimento non supervisionato\". Invece, l'apprendimento automatico pu\u00f2 essere anche supervisionato.\nL'apprendimento automatico e il \"data mining\" infatti si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione basata su propriet\u00e0 note apprese dai dati, il data mining si concentra sulla scoperta di propriet\u00e0 prima \"sconosciute\" nei dati. Il data mining sfrutta i metodi dell'apprendimento automatico, ma con obiettivi differenti; d'altro canto, l'apprendimento automatico utilizza i metodi di data mining come metodi di apprendimento non supervisionato o come passi di preprocessing per aumentare l'accuratezza dell'apprendimento. Gran parte della confusione tra le due comunit\u00e0 di ricerca scaturisce dall'assunzione di base del loro operato: nell'apprendimento automatico, le prestazioni sono generalmente valutate in base all'abilit\u00e0 di riprodurre conoscenza gi\u00e0 acquisita, mentre in data mining il compito chiave \u00e8 la scoperta di conoscenza che prima non si aveva.\nL'apprendimento automatico ha legami molto stretti con l'ottimizzazione: molti problemi di apprendimento sono formulati come la minimizzazione di una qualche funzione di costo su un insieme di esempi di apprendimento. La funzione di costo (o funzione di perdita) rappresenta la discrepanza tra le previsioni del modello che si sta addestrando e le istanze del problema reale. Le differenze tra i due campi (l'apprendimento automatico e l'ottimizzazione) sorgono dall'obiettivo della generalizzazione: mentre gli algoritmi di ottimizzazione possono minimizzare la perdita su un insieme di apprendimento, l'apprendimento automatico si preoccupa di minimizzare la perdita su campioni mai visti dalla macchina.\nLa risoluzione automatica di problemi avviene, nel campo dell'informatica, in due modi differenti: tramite paradigmi di \"hard computing\" o tramite paradigmi di \"soft computing\". Per \"hard computing\" si intende la risoluzione di un problema tramite l'esecuzione di un algoritmo ben definito e decidibile. La maggior parte dei paradigmi di \"hard computing\" sono metodi ormai consolidati, ma presentano alcuni lati negativi: infatti richiedono sempre un modello analitico preciso e definibile, e spesso un alto tempo di computazione. \nLe tecniche di \"soft computing\" d'altro canto antepongono il guadagno nella comprensione del comportamento di un sistema a scapito della precisione, spesso non necessaria. I paradigmi di \"soft computing\" si basano su due principi: \nL'apprendimento automatico si avvale delle tecniche di \"soft computing\".\nLa programmazione logica induttiva (anche ILP, dall'inglese \"inductive logic programming\") \u00e8 un approccio all'apprendimento di regole che usa la programmazione logica come rappresentazione uniforme per gli esempi di input, per la conoscenza di base della macchina, e per le ipotesi. Data una codifica della (nota) conoscenza di base e un insieme di esempi rappresentati come fatti in una base di dati logica, un sistema ILP deriva un programma logico ipotetico da cui conseguono tutti gli esempi positivi, e nessuno di quelli negativi. La programmazione induttiva \u00e8 un campo simile che considera ogni tipo di linguaggio di programmazione per rappresentare le ipotesi invece che soltanto la programmazione logica, come ad esempio programmi funzionali.\nL'albero di decisione \u00e8 un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende \u00e8 rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilit\u00e0 umana.\nL'apprendimento automatico basato su regole di associazione \u00e8 un metodo di apprendimento che identifica, apprende ed evolve delle \"regole\" con l'intento di immagazzinare, manipolare e applicare conoscenza. La caratteristica principale di questo tipo di apprendimento \u00e8 l'identificazione ed utilizzo di un insieme di regole relazionali che rappresenta nel suo insieme la conoscenza catturata dal sistema. Ci\u00f2 si pone in controtendenza con altri tipi di apprendimento automatico che normalmente identificano un singolo modello che pu\u00f2 essere applicato universalmente ad ogni istanza per riuscire a fare su di essa una previsione. Gli approcci dell'apprendimento basato su regole di associazione includono il sistema immunitario artificiale.\nUna rete neurale artificiale \u00e8 un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento.\nIn termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.\nGli algoritmi genetici forniscono un approccio all'apprendimento che \u00e8 liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi pi\u00f9 adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una variet\u00e0 di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.\nIl ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantit\u00e0 di interesse sono disciplinate da distribuzioni di probabilit\u00e0 e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilit\u00e0 insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana \u00e8 importante perch\u00e9 fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilit\u00e0.\nMacchine a vettori di supporto (\"Support Vector Machine\", SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.\nLa discesa dei prezzi per l'hardware e lo sviluppo di GPU per uso personale negli ultimi anni hanno contribuito allo sviluppo del concetto di apprendimento profondo, che consiste nello sviluppare livelli nascosti multipli nelle reti neurali artificiali. Questo approccio tenta di modellizzare il modo in cui il cervello umano processa luce e suoni e li interpreta in vista e udito. Alcune delle applicazioni pi\u00f9 affermate dell'apprendimento profondo sono la visione artificiale e il riconoscimento vocale.\nLa cluster analisi, o clustering, \u00e8 in grado di rilevare similarit\u00e0 strutturali tra le osservazioni di un dataset attraverso l'assegnazione di un insieme di osservazioni in sottogruppi (\"cluster\") di elementi tra loro omogenei. Il clustering \u00e8 un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.\nTutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.\nMetodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.\nMetodi di apprendimento automatico sono stati applicati ad una variet\u00e0 di database di grandi dimensioni per imparare regolarit\u00e0 generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema \u00e8 oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.\nI programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.\nL'apprendimento automatico solleva un numero di problematiche etiche. I sistemi addestrati con insiemi di dati faziosi o pregiudizievoli possono esibire questi pregiudizi quando vengono interpellati: in questo modo possono essere digitalizzati pregiudizi culturali quali il razzismo istituzionale e il classismo. Di conseguenza la raccolta responsabile dei dati pu\u00f2 diventare un aspetto critico dell'apprendimento automatico.\nIn ragione dell'innata ambiguit\u00e0 dei linguaggi naturali, le macchine addestrate su corpi linguistici necessariamente apprenderanno questa ambiguit\u00e0."], "concept_A": "Apprendimento automatico", "wikipedia_passage_concept_B": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_B": "K-means", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["40388", "Funzione di densit\u00e0 di probabilit\u00e0", "In matematica, una funzione di densit\u00e0 di probabilit\u00e0 (o PDF dall'inglese \"probability density function\") \u00e8 l'analogo della funzione di probabilit\u00e0 di una variabile casuale nel caso in cui la variabile casuale formula_1 sia continua, cio\u00e8 l'insieme dei possibili valori che ha la potenza del continuo.\nEssa descrive la \"densit\u00e0\" di probabilit\u00e0 in ogni punto nello spazio campionario.\nLa funzione di densit\u00e0 di probabilit\u00e0 di una variabile casuale formula_1 \u00e8 un'applicazione formula_3 non negativa integrabile secondo Lebesgue e reale di variabile reale tale che la probabilit\u00e0 dell'insieme \"A\" sia data da\nper tutti i sottinsiemi \"A\" dello spazio campionario.\nIntuitivamente, se una distribuzione di probabilit\u00e0 ha densit\u00e0 formula_3, allora l'intervallo formula_6 ha probabilit\u00e0 formula_7. Da ci\u00f2 deriva che la funzione formula_3 \u00e8 un'applicazione definita come\nAssumendo formula_10, ci\u00f2 corrisponde al limite della probabilit\u00e0 che formula_11 si trovi nell'intervallo formula_6 per formula_13 che tende a zero. Di qui il nome di funzione di 'densit\u00e0', in quanto essa rappresenta il rapporto tra una probabilit\u00e0 e un'ampiezza.\nPer la condizione di normalizzazione l'integrale su tutto lo spazio di formula_3 deve essere 1. Di conseguenza ogni funzione non negativa, integrabile secondo Lebesgue, con integrale su tutto lo spazio uguale a 1, \u00e8 la funzione densit\u00e0 di probabilit\u00e0 di una ben definita distribuzione di probabilit\u00e0. Una variabile casuale che possiede densit\u00e0 si dice \"variabile casuale continua\".\nPer le variabili casuali multivariate (o vettoriali) la trattazione formale \u00e8 assolutamente identica: formula_15 si dice assolutamente continua se esiste una funzione a valori reali definita in formula_16, detta densit\u00e0 congiunta, tale che per ogni sottoinsieme \"A\" dello spazio campionario\nEssa conserva tutte le propriet\u00e0 di una densit\u00e0 scalare: \u00e8 una funzione non negativa a integrale unitario su tutto lo spazio. Una propriet\u00e0 importante \u00e8 che se formula_15 \u00e8 assolutamente continua allora lo \u00e8 ogni sua componente; il viceversa invece non vale. La densit\u00e0 di una componente, detta densit\u00e0 marginale, si ottiene con un ragionamento analogo al teorema della probabilit\u00e0 assoluta, cio\u00e8 fissando l'insieme di suoi valori di cui si vuole determinare la probabilit\u00e0 e lasciando libere di variare tutte le altre componenti. Infatti (nel caso bivariato per semplicit\u00e0) l'evento formula_19 \u00e8 l'evento formula_20, dunque\nutilizzando il teorema di Fubini. La densit\u00e0 marginale di formula_1 \u00e8 data dunque da\nLa funzione di densit\u00e0 della variabile casuale normale di media 0\ne varianza 1 (detta \"normale standard\"), di cui a destra \u00e8 riportato il grafico e l'espressione analitica della corrispondente densit\u00e0 nel caso generico (media formula_24 e varianza formula_25).\nUn altro esempio pu\u00f2 essere dato dalla densit\u00e0 di probabilit\u00e0 uniforme su un segmento (0,1). Si pu\u00f2 verificare immediatamente che \u00e8 densit\u00e0 di probabilit\u00e0 facendo l'integrale tra (0,1)."], "concept_A": "Funzione di densit\u00e0 di probabilit\u00e0", "wikipedia_passage_concept_B": ["263204", "Macchine a vettori di supporto", "Le macchine a vettori di supporto (SVM, dall'inglese \"Support-Vector Machines\") sono dei modelli di apprendimento supervisionato associati ad algoritmi di apprendimento per la regressione e la classificazione. Dato un insieme di esempi per l'addestramento (training set), ognuno dei quali etichettato con la classe di appartenenza fra le due possibili classi, un algoritmo di addestramento per le SVM costruisce un modello che assegna i nuovi esempi ad una delle due classi, ottenendo quindi un classificatore lineare binario non probabilistico. Un modello SVM \u00e8 una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi appartenenti alle due diverse categorie siano chiaramente separati da uno spazio il pi\u00f9 possibile ampio. I nuovi esempi sono quindi mappati nello stesso spazio e la predizione della categoria alla quale appartengono viene fatta sulla base del lato nel quale ricade.\nOltre alla classificazione lineare \u00e8 possibile fare uso delle SVM per svolgere efficacemente la classificazione non-lineare utilizzando il metodo kernel, mappando implicitamente i loro input in uno spazio delle feature multi-dimensionale.\nQuando gli esempi non sono etichettati \u00e8 impossibile addestrare in modo supervisionato e si rende necessario l'apprendimento non supervisionato, questo approccio cerca di identificare i naturali cluster in cui si raggruppano i dati, mappando successivamente i nuovi dati nei cluster ottenuti. L'algoritmo di clustering a vettori di supporto, creato da Hava Siegelmann e Vladimir N. Vapnik, applica le statistiche dei vettori di supporto, sviluppate negli algoritmi delle SVM, per classificare dati non etichettati, ed \u00e8 uno degli algoritmi di clustering maggiormente utilizzato nelle applicazioni industriali.\nLe macchine a vettori di supporto possono essere pensate come una tecnica alternativa per l'apprendimento di classificatori polinomiali, contrapposta alle tecniche classiche di addestramento delle reti neurali artificiali.\nLe reti neurali ad un solo strato hanno un algoritmo di apprendimento efficiente, ma sono utili soltanto nel caso di dati linearmente separabili. Viceversa, le reti neurali multistrato possono rappresentare funzioni non lineari, ma sono difficili da addestrare a causa dell'alto numero di dimensioni dello spazio dei pesi e poich\u00e9 le tecniche pi\u00f9 diffuse, come la \"back-propagation\", permettono di ottenere i pesi della rete risolvendo un problema di ottimizzazione non convesso e non vincolato che, di conseguenza, presenta un numero indeterminato di minimi locali.\nLa tecnica di addestramento SVM risolve entrambi i problemi: presenta un algoritmo efficiente ed \u00e8 in grado di rappresentare funzioni non lineari complesse. I parametri caratteristici della rete sono ottenuti mediante la soluzione di un problema di programmazione quadratica convesso con vincoli di uguaglianza o di tipo box (in cui il valore del parametro deve essere mantenuto all'interno di un intervallo), che prevede un unico minimo globale.\nFormalmente, una macchina a vettori di supporto costruisce un iperpiano o un insieme di iperpiani in uno spazio a pi\u00f9 dimensioni o a infinite dimensioni, il quale pu\u00f2 essere usato per classificazione, regressione e altri scopi come il rilevamento delle anomalie. Intuitivamente una buona separazione si pu\u00f2 ottenere dall'iperpiano che ha la distanza maggiore dal punto (del training set) pi\u00f9 vicino di ognuna delle classi; in generale maggiore \u00e8 il margine fra questi punti, minore \u00e8 l'errore di generalizzazione commesso dal classificatore.\nMentre il problema originale pu\u00f2 essere definito in uno spazio di finite dimensioni, spesso succede che gli insiemi da distinguere non siano linearmente separabili in quello spazio. Per questo motivo \u00e8 stato proposto che lo spazio originale di dimensioni finite venisse mappato in uno spazio con un numero di dimensioni maggiore, rendendo presumibilmente pi\u00f9 facile trovare una separazione in questo nuovo spazio. Per mantenere il carico computazionale accettabile, i mapping utilizzati dalle SVM sono fatti in modo tale che i prodotti scalari dei vettori delle coppie di punti in input siano calcolati facilmente in termini delle variabili dello spazio originale, attraverso la loro definizione in termini di una funzione kernel formula_1scelta in base al problema da risolvere. Gli iperpiani in uno spazio multidimensionale sono definiti come l'insieme di punti il cui prodotto scalare con un vettore in quello spazio \u00e8 costante, dove tale insieme di vettori \u00e8 un insieme ortogonale (e quindi minimale) di vettori che definiscono un iperpiano. I vettori che definiscono gli iperpiani possono essere scelti come combinazioni lineari con parametri formula_2delle immagini dei vettori delle feature formula_3. Con tale scelta dell'iperpiano, i punti formula_4 nello spazio delle feature che sono mappati nell'iperpiano sono definiti dalla relazione formula_5. Si noti che se formula_1 diventa pi\u00f9 piccolo al crescere di formula_7 rispetto ad formula_4, ogni termine della somma misura il grado di vicinanza del punto di test formula_4 al corrispondente punto di base formula_3. Si noti che l'insieme di punti formula_4 mappato in un qualsiasi iperpiano pu\u00f2 produrre un risultato piuttosto complicato, permettendo discriminazioni molto pi\u00f9 complesse fra insiemi non completamente convessi nello spazio originario.\nL'originale algoritmo SVM \u00e8 stato inventato da Vladimir Vapnik e Aleksej \u010cervonenkis nel 1963.\nNel 1992 Bernhard Boser, Isabelle Guyon e lo stesso Vapnik suggerirono un modo per creare un classificatore non lineare applicando il metodo kernel all'iperpiano con il massimo margine. Lo standard corrente che propone l'utilizzo di un margine leggero fu invece proposto da Corinna Cortes e Vapnik nel 1993 e pubblicato nel 1995.\nAlcune applicazioni per cui le SVM sono state utilizzate con successo\nsono:\nI seguenti framework mettono a disposizione un'implementazione di SVM:"], "concept_B": "Macchine a vettori di supporto", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["253357", "Massimo e minimo di una funzione", "In matematica si dice che una funzione a valori reali:\nha in un punto formula_2 del proprio dominio formula_3 un massimo globale (o assoluto) se in formula_2 assume un valore maggiore o uguale a quello che assume negli altri punti di formula_3, ovvero\nViceversa formula_7 ha un minimo globale (o assoluto) in un punto formula_2 di formula_3 se\nSi dice che una funzione formula_7 ha in formula_2 un massimo locale (o relativo) se formula_2 appartiene al dominio formula_3 di formula_7, \u00e8 di accumulazione per formula_3, e inoltre formula_17 in un intorno di formula_2. \nformula_7 ha invece un minimo locale (o relativo) in formula_2 se formula_2 appartiene al dominio formula_3 di formula_7, \u00e8 di accumulazione per formula_3, e inoltre formula_25 in un intorno di formula_2.\nIn tutti questi casi, si parla di formula_2 come di \"punto di massimo\" (o \"di minimo\") \"assoluto\" (o \"relativo\").\nI punti di massimo e minimo vengono anche detti punti estremanti, e i valori assunti dalla funzione in questi punti sono detti estremi della funzione.\nNel caso di una funzione derivabile di una variabile reale la condizione necessaria, ma non sufficiente, affinch\u00e9 un punto possa, eventualmente, essere di massimo o di minimo locale \u00e8 data dal teorema di Fermat, in base al quale la derivata prima di una funzione deve annullarsi se calcolata in corrispondenza di un punto di massimo o minimo locale:\nTale condizione permette di trovare un certo numero di punti (\"x\", \"x\", ...) che si chiamano punti critici o stazionari. Naturalmente questa condizione vale per tutti i punti interni al dominio di derivabilit\u00e0, cio\u00e8 nei punti interni di questo insieme, mentre negli estremi dell'insieme non \u00e8 detto che la derivata esista e proprio per questo motivo la condizione vale per gli intervalli aperti. Questa condizione si pu\u00f2 dimostrare: infatti se formula_2 \u00e8 un punto di massimo locale, allora in un intorno formula_30 di \"x\" vale che il rapporto incrementale:\nformula_31\nper cui passando al limite di una funzione per formula_32 si deduce che necessariamente formula_33.\nGeometricamente questa condizione significa che la retta tangente nel punto \"x\" \u00e8 orizzontale. Tale condizione non \u00e8 n\u00e9 necessaria n\u00e9 sufficiente per avere un massimo o un minimo locale: infatti da un lato ci possono essere punti di massimo o minimo locale anche laddove la funzione non \u00e8 derivabile, e dall'altro ci possono essere punti (di flesso) dove la derivata si annulla ma la funzione non ha massimo o minimo locale.\nPossiamo utilizzare la derivata prima per classificare i punti critici. Un punto formula_2 \u00e8 di massimo locale per \"f\" se nei suoi intorni destro e sinistro:\nViceversa \u00e8 di minimo locale se:\nSe infine il valore della derivata non cambia attraversando il punto formula_2 allora questo \u00e8 un punto di flesso ascendente o discendente a seconda che la derivata prima rimanga sempre positiva o sempre negativa.\nAlternativamente se la funzione ammette la derivata seconda in un punto, un punto \u00e8 di massimo o minimo relativo se la derivata prima della funzione si annulla (quindi formula_2 \u00e8 un punto stazionario) e la derivata seconda non si annulla. Pi\u00f9 precisamente, posto che la derivata prima si annulli, se la derivata seconda risulta essere maggiore di 0, allora significa che la concavit\u00e0 sar\u00e0 rivolta verso l'alto, perci\u00f2 il punto \u00e8 di minimo. Mentre, se la derivata seconda \u00e8 minore di zero, significa che la concavit\u00e0 \u00e8 rivolta verso il basso e quindi si tratter\u00e0 di un punto di massimo. Se invece la derivata seconda si annulla, nel caso in cui la derivata terza sia diversa da zero, avremo in quel punto un flesso a tangenza orizzontale ascendente o discendente e, per la definizione di flesso, la funzione cambier\u00e0 concavit\u00e0 in tale punto.\nNel caso di funzioni in pi\u00f9 variabili, il discorso fatto \u00e8 analogo, ma ad annullarsi \u00e8 il differenziale (e quindi il gradiente) della funzione. \nNel caso di funzioni di 2 variabili, per verificare se il punto \u00e8 di massimo o minimo, si guarda il segno del determinante della matrice hessiana e il primo termine della matrice: \nNel caso di funzioni di 3 o pi\u00f9 variabili, invece, si deve studiare il segno degli autovalori della matrice hessiana (nei punti critici, cio\u00e8 dove si annulla il gradiente) e:\nIn caso di funzioni di due o pi\u00f9 variabili, la ricerca dei punti di massimo e minimo non si esaurisce all'interno del dominio dove la funzione \u00e8 derivabile, ma si devono cercare i massimi e i minimi anche sulla frontiera, in cui in generale la funzione non \u00e8 differenziabile. In tal caso, nelle funzioni di due variabili si parametrizza la frontiera e si cercano i punti di massimo e di minimo come visto per una variabile reale.\nSi consideri \nCalcoliamo la derivata prima:\nCalcoliamo la derivata seconda: \nLa derivata prima si annulla nei punti \nNel punto formula_43 la derivata seconda \u00e8 negativa, quindi \u00e8 un punto di massimo, mentre nel punto formula_44 la derivata seconda \u00e8 positiva, quindi \u00e8 un punto di minimo.\nSi consideri la funzione di 2 variabili\nCalcoliamo le derivate parziali prime:\nQuindi il gradiente di formula_48 \u00e8:\nI punti critici sono dati dalla soluzione del sistema:\nQuindi... \nformula_51 \noppure\nformula_52 \nCalcoliamo le derivate parziali seconde:\nQuindi la matrice hessiana di z sar\u00e0:\nBasandosi sul modello:\nCalcoliamo la matrice hessiana nei punti critici (anche detti \"punti stazionari\"):\nQuesta matrice ha determinante negativo (-9), quindi \u00e8 un punto di sella.\nQuesta seconda matrice ha invece determinante positivo (27) e primo termine (-6) negativo quindi \u00e8 un punto di massimo relativo."], "concept_A": "Massimo e minimo di una funzione", "wikipedia_passage_concept_B": ["480718", "Discesa del gradiente", "In ottimizzazione e analisi numerica il metodo di discesa del gradiente (detto anche \"metodo del gradiente\", \"metodo steepest descent\" o \"metodo di discesa pi\u00f9 ripida\") \u00e8 una tecnica che consente di determinare i punti di massimo e minimo di una funzione di pi\u00f9 variabili.\nIl metodo \u00e8 stato sviluppato - e pubblicato nel 1847 - dal matematico francese Augustin-Louis Cauchy nel tentativo di risolvere il problema di determinare l'orbita di un corpo celeste a partire dalle sue equazioni del moto.\nSi supponga di voler minimizzare la funzioneformula_1 e si scelga come soluzione iniziale il vettore formula_2. Allora\ne, muovendosi in un intorno di formula_4:\nQuesti calcoli mostrano che, per individuare dei punti - \"vicini\" a formula_4 - in corrispondenza dei quali la funzione assuma un valore minore di formula_7, conviene spostarsi lungo direzioni che abbiano la prima e la terza componente formula_8 pi\u00f9 piccole o seconda componente formula_9 pi\u00f9 grande. Inoltre esistono delle direzioni \"preferenziali\" lungo le quali la funzione formula_10 decresce pi\u00f9 velocemente (ad esempio scegliere una coordinata formula_11 pi\u00f9 piccola \u00e8 preferibile, ad esempio, rispetto a far diminuire formula_12).\nLa procedura pu\u00f2 essere iterata partendo da un nuovo punto, ad esempio formula_13, fino ad individuare un minimo per formula_10. L'esempio mostra che una procedura che aggiorni la soluzione in modo iterativo sulla base delle informazioni disponibili \"localmente\" pu\u00f2 portare ad individuare un punto di minimo per la funzione assegnata.\nSi voglia risolvere il seguente problema di ottimizzazione non vincolata nello spazio formula_15-dimensionale formula_16\nLa tecnica di discesa secondo gradiente si basa sul fatto che, per una data funzione formula_18, la direzione di massima discesa in un assegnato punto formula_19 corrisponde a quella determinata dall'opposto del suo gradiente in quel punto formula_20. Questa scelta per la direzione di discesa garantisce che la soluzione tenda a un punto di minimo di formula_10. Il metodo del gradiente prevede dunque di partire da una soluzione iniziale formula_4 scelta arbitrariamente e di procedere iterativamente aggiornandola come\ndove formula_24 corrisponde alla lunghezza del passo di discesa, la cui scelta diventa cruciale nel determinare la velocit\u00e0 con cui l'algoritmo converger\u00e0 alla soluzione richiesta.\nSi parla di metodo \"stazionario\" nel caso in cui si scelga un passo formula_25 costante per ogni formula_26, viceversa il metodo si definisce \"dinamico\". In quest'ultimo caso una scelta conveniente, ma computazionalmente pi\u00f9 onerosa rispetto a un metodo stazionario, consiste nell'ottimizzare, una volta determinata la direzione di discesa formula_27, la funzione di una variabile formula_28 in maniera analitica o in maniera approssimata. Si noti che, a seconda della scelta del passo di discesa, l'algoritmo potr\u00e0 convergere a uno qualsiasi dei minimi della funzione formula_10, sia esso locale o globale.\nLo schema generale per l'ottimizzazione di una funzione formula_18 mediante metodo del gradiente \u00e8 il seguente:\nUn caso particolare di applicazione del metodo del gradiente consiste nella risoluzione di sistemi lineari della forma\ndove formula_33 \u00e8 una matrice simmetrica e definita positiva.\nPer le propriet\u00e0 di formula_33 la soluzione di tale problema \u00e8 equivalente alla procedura di minimizzazione della forma quadratica associata:\nInfatti:\nda cui\nPer la funzione formula_38 si ha che la direzione di massima discesa nel punto formula_39 \u00e8:\ncoincidente con il residuo formula_41 del sistema lineare. Dunque la direzione di discesa scelta a ogni iterazione \u00e8 formula_42.\nInoltre vale la seguente relazione:\nche permette di calcolare analiticamente il passo formula_44 ottimale. Infatti, imponendo la condizione di stazionariet\u00e0\nsi ricava\nL'algoritmo del metodo del gradiente per la risoluzione di sistemi lineari \u00e8 dunque\nIn aritmetica floating point la condizione del ciclo while pu\u00f2 essere valutata verificando che la norma del residuo formula_48 non sia pi\u00f9 piccola di una tolleranza impostata dall'utente.\nIn molti casi \u00e8 possibile accelerare la velocit\u00e0 di convergenza dell'algoritmo migliorando le propriet\u00e0 di condizionamento della matrice formula_33. Si introduca a tal fine una matrice di precondizionamento formula_50 simmetrica e definita positiva.\nLo schema risolutivo in questo caso diventa:\nIl metodo del gradiente coniugato costituisce una variante del metodo del gradiente in cui viene effettuata una scelta diversa, ma particolarmente conveniente nel caso di sistemi lineari simmetrici e definiti positivi, per le direzioni di discesa formula_27. Tale scelta garantisce la convergenza del metodo (in aritmetica esatta) in un numero di iterazioni pari al pi\u00f9 alla dimensione del sistema da risolvere.\n\u00c8 possibile dimostrare che l'errore commesso alla formula_26-esima iterazione del metodo del gradiente soddisfa la seguente stima:\ndove\nformula_56 indica il numero di condizionamento in norma formula_57 di formula_33 e formula_59 \u00e8 la norma indotta da formula_33.\nNel caso precondizionato vale la stessa stima con\nSi riporta un esempio di possibile implementazione del metodo del gradiente nella versione precondizionata compatibile con i linguaggi di programmazione Octave e MATLAB.\nQuando la funzione obiettivo \u00e8 troppo costosa da calcolare ad ogni iterazione, ma pu\u00f2 essere scomposta in una somma di molti addendi (ad esempio, la somma del costo calcolato su ogni singolo record in un dataset), il gradiente pu\u00f2 essere approssimato stocasticamente restringendo la somma su un sottinsieme di addendi ad ogni iterazione, metodo noto come discesa stocastica del gradiente.\nLa discesa del gradiente \u00e8 ampiamente utilizzata in statistica e apprendimento automatico per l'addestramento tramite apprendimento supervisionato di modelli come reti neurali artificiali e modelli grafici. Il principio \u00e8 noto come regola delta, e consiste nel valutare il modello su un input il cui corrispondente output esatto sia noto, e correggere ciascun parametro del modello in una quantit\u00e0 proporzionale (ma di segno opposto) rispetto al suo contributo all'errore sul risultato. L'algoritmo usato nelle reti neurali per implementare questo principio \u00e8 noto come retropropagazione dell'errore, che consiste in un'applicazione della discesa del gradiente, essendo il contributo di ciascun parametro all'errore del modello dato dalla derivata parziale della funzione di perdita rispetto al parametro stesso.\nLa regola, classificabile fra i metodi per l'apprendimento supervisionato, pu\u00f2 essere applicata a reti neurali di tipo \"in avanti\" (cio\u00e8 con propagazione unidirezionale dei segnali, in inglese: \"feedforward\") e permette di calcolare la differenza tra i valori di output che la rete ottiene e quelli che invece dovrebbe apprendere. La regola deve essere applicata a reti che usano unit\u00e0 di output ad attivazione continua e differenziabile ed \u00e8 l'elemento fondamentale dell'algoritmo di retropropagazione dell'errore (\"backpropagation\"), alla base dell'approccio connessionista.\nData una rete \"in avanti\" con le propriet\u00e0 sopra descritte, l'obiettivo che ci si prefigge \u00e8 minimizzare la diversit\u00e0 tra i valori di attivazione delle unit\u00e0 di output formula_62 della rete (ottenuti sommando i segnali provenienti dalle diverse unit\u00e0 di input formula_63 moltiplicati per l'efficacia, o \"pesi sinaptici\" formula_64 delle connessioni in ingresso), e i valori formula_65 della risposta desiderata. Tale diversit\u00e0 viene quantificata attraverso una funzione di perdita. La funzione obiettivo che si vuole minimizzare \u00e8 il valore atteso della perdita (in pratica la perdita media sui dati).\nPer applicare il metodo del gradiente, la funzione di perdita deve essere derivabile rispetto ai valori di output formula_62. Una scelta adatta a problemi di regressione \u00e8 lo scarto quadratico medio tra formula_62 e formula_65 (valutato per tutte le unit\u00e0 di output e per tutti i pattern d'apprendimento); per problemi di classificazione si pu\u00f2 utilizzare la divergenza di Kullback-Leibler o equivalentemente l'entropia incrociata.\nNella fase di addestramento, variando i pesi sinaptici formula_64 (parametri del modello) si pu\u00f2 aumentare o diminuire la funzione obiettivo; la \"prestazione\" della rete sar\u00e0 funzione delle variabili formula_64, e sar\u00e0 massima quando si raggiunge il minimo della funzione obiettivo, il che si ottiene applicando il metodo del gradiente e aggiornando iterativamente i valori dei pesi sinaptici.\nPoich\u00e9 nelle applicazioni pratiche le dimensioni dei modelli e dei relativi dataset usati nell'addestramento sono molto grandi, in pratica si fa generalmente uso della discesa stocastica del gradiente per l'addestramento delle reti neurali e di altri modelli statistici e di apprendimento automatico."], "concept_B": "Discesa del gradiente", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["847", "Campionamento statistico", "In statistica il campionamento statistico (che si appoggia alla teoria dei campioni o teoria del campionamento), sta alla base dell'inferenza statistica, la quale si divide in due grandi capitoli: la teoria della stima e la verifica d'ipotesi.\nIn particolare, una rilevazione si dice \"campionaria\" quando \u00e8 utile per fare inferenza ossia per desumere dal campione stesso un'informazione relativa all'intera popolazione.\nLe indagini censuarie riguardano l'intera popolazione e pur essendo pi\u00f9 affidabili riguardo al parametro oggetto d'indagine soffrono di:\nQuindi mentre l'indagine censuaria fornisce il valore vero dei parametri di interesse (proporzioni, percentuali, medie, totali...) quella campionaria restituisce una sua stima al quale \u00e8 associato un certo grado di fiducia (ovvero un'incertezza) quantificabile quando la formazione del campione risponde a determinati criteri di tipo probabilistico.\nIl campionamento si usa quando si vuole conoscere uno o pi\u00f9 parametri di una popolazione, senza doverne analizzare ogni elemento: questo per motivi di costi intesi in termini monetari, di tempo, di qualit\u00e0 o di disagio o perch\u00e9 analizzare un elemento lo distrugge rendendo inutilizzabile l'informazione ottenuta.\nModalit\u00e0 di selezione del campione sono:\nNella pratica quotidiana dei sondaggi di opinione e delle ricerche di mercato vengono usati tutti e quattro gli approcci.\nLa scelta di un tipo di campionamento avviene in base alle propriet\u00e0 degli stimatori di alcuni parametri oppure per tener conto di problemi di costo, mobilit\u00e0 o altro.\nConcetti chiave sono:\nBench\u00e9 gi\u00e0 nel Settecento si sia notato il vantaggio nell'esaminare un sottinsieme della popolazione per generalizzare i risultati alla popolazione complessiva, \u00e8 solo dalla fine dell'Ottocento che la discussione sulla \"scientificit\u00e0\" del campionamento viene posta in modo esplicito alla comunit\u00e0 statistica.\nGi\u00e0 agli inizi del Novecento si vanno delineando le caratteristiche che un campione deve avere, ovvero che deve essere scelto in maniera casuale, e nell'arco di pochi anni compaiono i primi studi che mettono in evidenza che il campione non deve essere necessariamente un campione semplice ma pu\u00f2 essere pi\u00f9 complesso, per esempio stratificando.\nImportanti autori che hanno fatto la storia della teoria dei campioni sono stati tra gli altri: \nNel 1925, durante il congresso di Roma, l'Istituto Internazionale di Statistica accetta definitivamente come scientifico il metodo campionario, distinguendo il campionamento casuale dal campionamento ragionato.\nAltri autori importanti nella ricerca teorica ed applicata sul campionamento furono George Gallup e William G. Cochran."], "concept_A": "Campionamento statistico", "wikipedia_passage_concept_B": ["6394873", "F1 score", "Nell'analisi statistica della classificazione binaria, lF score (nota anche come F-score o F-measure, letteralmente \"misura F\") \u00e8 una misura dell'accuratezza di un test. La misura tiene in considerazione precisione e recupero del test, dove la precisione \u00e8 il numero di veri positivi diviso il numero di tutti i risultati positivi, mentre il recupero \u00e8 il numero di veri positivi diviso il numero di tutti i test che sarebbero dovuti risultare positivi (ovvero veri positivi pi\u00f9 falsi negativi). L'F viene calcolato tramite la media armonica di precisione e recupero:\nPu\u00f2 assumere valori compresi fra 0 e 1. Assume valore 0 solo se almeno uno dei due vale 0, mentre assume valore 1 sia precisione che recupero valgono 1. L'F score \u00e8 anche noto come coefficiente di S\u00f8rensen-Dice (DSC), o semplicemente coefficiente di Dice.\nLa formula generale \u00e8:\nper valori di \u03b2 reali positivi.\nLa formula in termini di errori di primo e secondo tipo:\nDue particolari istanze della formula solitamente utilizzate sono la misura formula_4 (che pone maggiore enfasi sui falsi negativi) ed formula_5 (la quale attenua l'influenza dei falsi negativi).\nIn generale, formula_6 \"misura l'efficacia del recupero rispetto ad un utente attribuisce al recupero un'importanza di \u03b2 volte quella della precisione\".\nL'F-score \u00e8 solitamente usata nel campo del recupero dell'informazione per misurare l'accuratezza delle ricerche o della classificazione dei documenti. Inizialmente l'F score era l'unica misura ad essere considerata, ma con la proliferazione in larga scala di motori di ricerca gli obiettivi di prestazione iniziarono a variare, divenendo necessario porre maggiore enfasi su precisione o recupero.\nL'F-score \u00e8 usata anche nel campo dell'apprendimento automatico ed \u00e8 vastamente impiegata nella letteratura sull'elaborazione del linguaggio naturale.\nDa notare, comunque, che non viene mai preso in considerazione il numero di veri negativi. In tal senso, misure come il coefficiente di correlazione di Matthews o il Kappa di Cohen possono generare risultati pi\u00f9 adeguati alle proprie esigenze.\nMentre l'F-measure \u00e8 una media armonica di recupero e precisione, la cosiddetta G-measure \u00e8 una media geometrica:\nDove \"PPV\" sta per \"Positive Predictive Value\" (\"valore predittivo positivo\") e \"TPR\" per \"True Positive Rate\" (o indice di sensibilit\u00e0).\n\u00c8 nota anche come indice di Fowlkes-Mallows."], "concept_B": "F1 score", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["4145289", "Distribuzione di probabilit\u00e0 a priori", "Nell'ambito dell'inferenza statistica bayesiana, una distribuzione di probabilit\u00e0 a priori, detta spesso anche distribuzione a priori, di una quantit\u00e0 incognita \"p\" (per esempio, supponiamo \"p\" essere la proporzione di votanti che voteranno per il politico Rossi in un'elezione futura) \u00e8 la distribuzione di probabilit\u00e0 che esprimerebbe l'incertezza di \"p\" prima che i \"dati\" (per esempio, un sondaggio di opinione) siano presi in considerazione. Il proposito \u00e8 di attribuire incertezza piuttosto che casualit\u00e0 a una quantit\u00e0 incerta. La quantit\u00e0 incognita pu\u00f2 essere un parametro o una variabile latente.\nSi applica il teorema di Bayes, moltiplicando la distribuzione a priori per la funzione di verosimiglianza e quindi normalizzando, per ottenere la distribuzione di probabilit\u00e0 a posteriori, la quale \u00e8 la distribuzione condizionata della quantit\u00e0 incerta una volta ottenuti i dati.\nSpesso una distribuzione a priori \u00e8 l'accertamento soggettivo (elicitazione) di una persona esperta. Quando possibile, alcuni sceglieranno una \"distribuzione a priori coniugata\" per rendere pi\u00f9 semplice il calcolo della distribuzione a posteriori.\nI parametri di una distribuzione a priori sono chiamati \"iperparametri\", per distinguerli dai parametri del modello dei dati sottostanti. Per esempio, se si sta usando una distribuzione beta per modellare la distribuzione di un parametro \"p\" di una distribuzione di Bernoulli, allora:\nUna \"distribuzione a priori informativa\" esprime una specifica, definita informazione circa una variabile.\nUn esempio \u00e8 la distribuzione a priori per la temperatura di domattina.\nUn approccio ragionevole \u00e8 costruire la distribuzione a priori come una distribuzione normale con valore atteso uguale alla temperatura mattutina di oggi, con una varianza uguale alla varianza giorno per giorno della temperatura atmosferica, oppure come una distribuzione della temperatura per quel tal giorno dell'anno.\nQuesto esempio ha una propriet\u00e0 in comune con molte distribuzioni a priori, ovvero che la distribuzione a posteriori di un problema (temperatura odierna) diventa la distribuzione a priori per un altro problema (temperatura di domani); l'evidenza preesistente, che \u00e8 gi\u00e0 stata tenuta in conto, \u00e8 parte della distribuzione a priori e come ulteriore evidenza viene accumulata. \nLa distribuzione a priori \u00e8 largamente determinata dall'evidenza piuttosto che da qualche assunzione originale, sempre che l'assunzione originale ammetta la possibilit\u00e0 (ossia sia compatibile) con quello che l'evidenza suggerisce. I termini \"a priori\" e \"a posteriori\" sono generalmente relativi a un dato o un'osservazione specifica.\nUna \"distribuzione a priori non informativa\" esprime vaghezza o informazione a carattere generale circa una variabile.\nIl termine \"non informativa\" pu\u00f2 essere un po' fuorviante; spesso, tale tipo di distribuzione \u00e8 chiamata \"a priori non molto informativa\", oppure \"a priori oggettiva\", cio\u00e8 una distribuzione che non \u00e8 soggettivamente esplicitata.\nLe distribuzioni a priori non informative possono esprimere informazione \"oggettiva\" come ad esempio \"la variabile \u00e8 positiva\" oppure \"la variabile \u00e8 minore di tal limite\".\nLa pi\u00f9 semplice e vecchia regola per determinare una distribuzione a priori non informativa \u00e8 il principio d'indifferenza, il quale assegna a tutti gli eventi uguale probabilit\u00e0.\nIn problemi di stima parametrica, l'uso di una distribuzione a priori non informativa d\u00e0 risultati che sono non troppo differenti dall'analisi statistica convenzionale. Questo accade in quanto la funzione di verosimiglianza fornisce la parte maggiore dell'informazione rispetto a quella fornita dalla distribuzione a priori non informativa nel determinare una distribuzione a posteriori.\nVari tentativi sono stati fatti per trovare probabilit\u00e0 a priori, cio\u00e8 distribuzioni di probabilit\u00e0 in un certo senso logicamente richieste dalla natura di uno stato di incertezza; queste sono soggette a controversia filosofica, con i sostenitori del metodo bayesiano approssimativamente divisi in due scuole: i \"bayesiani oggettivistici\", che credono che tali distribuzioni a priori esistano in molte situazioni, e i \"bayesiani soggettivisti\" che credono che in pratica le distribuzioni a priori rappresentino giudizi di opinione che non possono essere rigorosamente giustificati. Per la maggiore le pi\u00f9 forti argomentazioni a favore della scuola oggettivistica furono date da Edwin T. Jaynes.\nCome esempio di una distribuzione a priori, dovuta a, consideriamo una situazione in cui sappiamo che una pallina \u00e8 nascosta sotto una di tre tazze rovesciate, A, B o C, ma nessun'altra informazione \u00e8 disponibile circa la sua posizione. In questo caso una distribuzione a priori uniforme di formula_1 sembra intuitivamente verosimile la sola scelta ragionevole. Pi\u00f9 formalmente, noi possiamo vedere che il problema rimane lo stesso se scambiamo le lettere identificative \"A\", \"B\" e \"C\" delle tazze. Sarebbe perci\u00f2 strano scegliere una distribuzione a priori per la quale una permutazione delle lettere causerebbe un cambio nella nostra predizione circa la posizione dove la pallina sar\u00e0 trovata; la distribuzione a priori uniforme \u00e8 la sola che preserva questa invarianza. Se si accetta questo principio di invarianza allora si pu\u00f2 vedere che la distribuzione a priori uniforme \u00e8 la distribuzione logicamente corretta che rappresenta questo stato di conoscenza a priori. Si avr\u00e0 notato che questa distribuzione a priori \u00e8 \"oggettiva\" nel senso di essere la scelta corretta per rappresentare un particolare stato di conoscenza, ma non \u00e8 oggettiva nel senso di essere una caratteristica del sistema osservato indipendente dall'osservatore: in realt\u00e0 la pallina esiste sotto una specifica tazza e in questa situazione ha solo senso parlare di probabilit\u00e0 se c'\u00e8 un osservatore con una conoscenza limitata del sistema ossia della posizione della pallina sotto le tazze.\nCome esempio pi\u00f9 controverso, Jaynes pubblic\u00f2 un argomento basato sui gruppi di Lie suggerente che la distribuzione a priori rappresentante in maniera completa l'incertezza sarebbe la distribuzione a priori di Haldane \"p\"(1\u00a0\u2212\u00a0\"p\"). L'esempio fornito da Jaynes \u00e8 quello di trovare un chimico in un laboratorio e di chiedergli di eseguire ripetutamente degli esperimenti di dissoluzione in acqua. La distribuzione a priori di Haldane da prevalentemente la maggiore probabilit\u00e0 agli eventi formula_2 and formula_3, indicando che il campione ogni volta si scioglier\u00e0 oppure no, con uguale probabilit\u00e0. Tuttavia se sono stati osservati campioni non disciogliersi in un esperimento e disciogliersi in un altro, allora questa distribuzione a priori \u00e8 aggiornata alla distribuzione uniforme sull'intervallo [0, 1]. Questo risultato si ottiene applicando il teorema di Bayes all'insieme di dati consistente in un'osservazione di dissoluzione e una di non dissoluzione, usando la distribuzione a priori precedente. sulla base che essa fornisce una distribuzione a posteriori impropria che pone il 100% del contenuto di probabilit\u00e0 sia a \"p\" = 0 o a \"p\" = 1 se un numero finito di esperimenti ha dato lo stesso risultato (ad esempio il discioglimento). La distribuzione a priori di Jeffreys \"p\"(1\u00a0\u2212\u00a0\"p\") \u00e8 perci\u00f2 preferita (\"cfr.\" sotto).\nSe lo spazio parametrico X \u00e8 dotato di una struttura di gruppo naturale che lascia invariato il nostro stato di conoscenza bayesiano, allora la distribuzione a priori pu\u00f2 essere costruita proporzionale alla Misura di Haar. Questo pu\u00f2 essere visto come una generalizzazione del principio di invarianza che giustificava la distribuzione a priori uniforme dell'esempio delle tre tazze visto sopra. Per esempio, in fisica ci si aspetta che un esperimento dia i medesimi risultati indipendentemente dalla scelta dell'origine del sistema di coordinate. Questo induce la struttura gruppale del gruppo delle traslazioni su \"X\", il quale determina la distribuzione di probabilit\u00e0 a priori come una distribuzione a priori impropria costante. Analogamente alcuni sistemi fisici presentano un'invarianza di scala (ossia i risultati sperimentali sono indipendenti dal fatto che, ad esempio, usiamo centimetri o pollici). In tal caso il gruppo di scala \u00e8 la struttura di gruppo naturale, e la corrispondente distribuzione a priori su \"X\" \u00e8 proporzionale a 1/\"x\". Qualche volta risulta importante se viene usata la misura di Haar invariante a sinistra piuttosto che quella invariante a destra. Per esempio, le misure di Haar invarianti a destra e a sinistra sul gruppo affine non sono uguali. Berger (1985, p.\u00a0413) arguisce che la scelta corretta \u00e8 la misura di Haar invariante a destra.\nUn'altra idea, supportata da Edwin T. Jaynes, \u00e8 di usare il principio di massima entropia (MAXENT). La motivazione \u00e8 che l'entropia di Shannon di una distribuzione di probabilit\u00e0 misura l'ammontare di informazione contenuta nella distribuzione. Maggiore \u00e8 l'entropia, minore \u00e8 l'informazione fornita dalla distribuzione. Perci\u00f2, mediante la massimizzazione dell'entropia sopra un adeguato insieme di distribuzioni di probabilit\u00e0 su \"X\", si trova la distribuzione che \u00e8 meno informativa nel senso che essa contiene il minore ammontare di informazione consistente con le costrizioni definite dall'insieme scelto. Per esempio, la distribuzione a priori di massima entropia su uno spazio discreto, dato solo il fatto che la probabilit\u00e0 \u00e8 normalizzata a 1, \u00e8 la distribuzione a priori che assegna uguale probabilit\u00e0 ad ogni stato. Mentre nel caso continuo, la distribuzione a priori di massima entropia con densit\u00e0 normalizzata, media nulla e varianza unitaria, \u00e8 la ben nota distribuzione normale. Il principio di minima entropia incrociata generalizza il principio di massima entropia al caso di \"aggiornamento\" di una distribuzione a priori arbitraria con adeguate costrizioni nel senso di massima entropia.\nUn'idea collegata, la distribuzione a priori di riferimento, fu introdotta da Jos\u00e9-Miguel Bernardo. Qui l'idea \u00e8 di massimizzare il valore atteso della divergenza di Kullback\u2013Leibler della distribuzione a posteriori rispetto alla distribuzione a priori. Questo massimizza l'informazione attesa riguardante \"X\" quando la densit\u00e0 a priori \u00e8 \"p\"(\"x\"); perci\u00f2, in un certo senso, \"p\"(\"x\") \u00e8 la distribuzione a priori \"meno informativa\" riguardo X. La distribuzione a priori di riferimento \u00e8 definita nel limite asintotico, cio\u00e8 si considera il limite delle distribuzioni a priori cos\u00ec ottenute come il numero di dati va all'infinito. Nei problemi multivariati spesso vengono scelte come distribuzioni a priori oggettive le distribuzioni a priori di riferimento, dato che altre scelte (ad esempio la regola di Jeffreys possono portare a distribuzioni a priori dal comportamento problematico.\nDistribuzioni a priori oggettive possono anche essere derivate da altri principi, come le teorie dell'informazione o le teorie della codifica (vedi ad esempio lunghezza di descrizione minima) oppure della statistica frequentista.\nProblemi filosofici legati alle distribuzioni a priori non informative sono associati alla scelta di una metrica appropriata o scala di misurazione. Supponiamo di volere una distribuzione a priori per la valocit\u00e0 di un corridore a noi sconosciuto. Potremmo specificare, diciamo, per la sua velocit\u00e0 una distribuzione a priori di tipo normale, ma in alternativa potremmo specificare una distribuzione a priori normale per il tempo impiegato a percorrere 100 metri, il quale \u00e8 proporzionale al reciproco della prima distribuzione a priori. Queste due distribuzioni a priori sono effettivamente differenti, ma non \u00e8 chiaro quale delle due preferire. Il metodo, spesso sopravvalutato, di trasformazione dei gruppi di Jaynes pu\u00f2 rispondere a tale questione in varie situazioni.\nIn maniera simile, se ci \u00e8 chiesto di stimare una proporzione incognita tra 0 e 1, noi possiamo affermare che tutte le proporzioni sono ugualmente probabili ed usare una distribuzione a priori uniforme. Alternativamente, potremmo dire che tutti gli ordini di grandezza per la proporzione sono ugualmente probabili, e scegliere la distribuzione a priori logaritmica, la quale \u00e8 la distribuzione a priori uniforme sul logaritmo della proporzione. La distribuzione a priori di Jeffreys tenta di risolvere questo problema calcolando una distribuzione a priori che esprime la medesima credenza indipendentemente dalla metrica utilizzata. La distribuzione a priori di Jeffreys per una proporzione incognita \"p\" \u00e8 \"p\"(1\u00a0\u2212\u00a0\"p\"), che differisce da quella raccomandata da Jaynes.\nDistribuzioni a priori basate sulla nozione di probabilit\u00e0 algoritmica vengono impiegate nel campo dell'inferenza induttiva come base induttiva in configurazioni del tutto generali.\nProblemi pratici associati con le distribuzioni a priori non informative includono il requisito che la distribuzione a posteriori sia propria. Le distribuzioni a priori non informative su variabili continue, non limitate sono improprie. Questo non \u00e8 necessariamente un problema se la distribuzione a posteriori \u00e8 propria. Un altro argomento importante \u00e8 quello in cui se una distribuzione a priori non informativa viene usata in maniera regolare, cio\u00e8 con svariati insiemi di dati, allora essa avrebbe buone propriet\u00e0 frequentiste. Normalmente un bayesiano non dovrebbe porsi questo problema, ma potrebbe essere importante farlo in questa situazione. Per esempio, uno potrebbe volere che qualsiasi regola di decisione basata sulla distribuzione a posteriori sia ammissibile sotto la funzionedi perdita adottata. Sfortunatamente, l'ammissibilit\u00e0 \u00e8 difficile da verificare, nonostante vari risultati siano noti (\"cfr.\" ad esempio, Berger and Strawderman, 1996). Il problema \u00e8 particolarmente acuto con i modelli di Bayes gerarchici; le distribuzioni a priori usuali (ad esempio la distribuzione a priori di Jeffreys) possono dare regole di decisione praticamente inammissibili se impiegate ai livelli gerarchici pi\u00f9 elevati.\nSe il teorema di Bayes viene scritto come\nallora \u00e8 chiaro che si otterrebbe il medesimo risultato se tutte le probabilit\u00e0 a priori \"P\"(\"A\") e \"P\"(\"A\") fossero moltiplicate per una data costante; lo stesso sarebbe vero per una variabile casuale continua. Se la sommatoria al denominatore converge, le probabilit\u00e0 a posteriori sommeranno (o integreranno) ancora a 1 anche se i valori della distribuzione a priori non lo fanno, e in tal modo pu\u00f2 solo essere necessario richiedere alle distribuzioni a priori di essere specificate nella proporzione corretta. Spingendo oltre questa idea, in molti casi non \u00e8 neanche richiesto che la somma o l'integrale dei valori della distribuzione a priori sia finita per ottenere risposte significative circa le probabilit\u00e0 a posteriori. Quando questo \u00e8 il caso, la distribuzione a priori \u00e8 chiamata distribuzione a priori impropria. Tuttavia, se la distribuzione a priori \u00e8 impropria, allora non \u00e8 necessario che la distribuzione a posteriori sia propria. Questo \u00e8 chiaro nella situazione in cui l'evento \"B\" \u00e8 indipendente da tutti gli altri eventi \"A\".\nVari statistici usano le distribuzioni a priori improprie come distribuzioni a priori non informative. Per esempio, se hanno bisogno di una distribuzione a priori per la media e la varianza di una variabile casuale, allora essi assumono \"p\"(\"m\",\u00a0\"v\")\u00a0~\u00a01/\"v\" (per \"v\" > 0) il che suggerirebbe che qualsiasi valore per la media \u00e8 \"ugualmente probabile\" e che un valore per la varianza positiva diventa \"meno probabile\" in proporzione inversa al suo valore. Molti autori (Lindley, 1973; De Groot, 1937; Kass and Wasserman, 1996) mettono in guardia contro il pericolo di sovra-interpretare tali distribuzioni a priori poich\u00e9 non sono densit\u00e0 di probabilit\u00e0. La loro sola rilevanza che esse hanno si trova nella distribuzione a posteriori corrispondente, fintanto che questa \u00e8 ben definita per tutte le osservazioni. (La distribuzione a priori di Haldane \u00e8 un tipico controesempio.)\nEsempi di distribuzioni a priori includono:\nIl concetto di probabilit\u00e0 algoritmica fornisce una via per specificare la probabilit\u00e0 delle distribuzioni a priori basata sulla complessit\u00e0 relativa di modelli presi in considerazione e tra loro alternativi."], "concept_A": "Distribuzione di probabilit\u00e0 a priori", "wikipedia_passage_concept_B": ["558366", "Rete bayesiana", "Una rete bayesiana (BN, \"Bayesian network\") \u00e8 un modello grafico probabilistico che rappresenta un insieme di variabili stocastiche con le loro dipendenze condizionali attraverso l'uso di un grafo aciclico diretto (DAG). Per esempio una rete Bayesiana potrebbe rappresentare la relazione probabilistica esistente tra i sintomi e le malattie. Dati i sintomi, la rete pu\u00f2 essere usata per calcolare la probabilit\u00e0 della presenza di diverse malattie.\nIl termine \"modello gerarchico\" \u00e8 talvolta considerato un particolare tipo di rete Bayesiana, ma non ha nessuna definizione formale. Qualche volta viene usato per modelli con tre o pi\u00f9 livelli di variabili stocastiche; in altri casi viene usato per modelli con variabili latenti. Comunque in generale qualsiasi rete Bayesiana moderatamente complessa viene usualmente detta \"gerarchica\".\nFormalmente le reti Bayesiane sono grafi diretti aciclici i cui nodi rappresentano variabili casuali in senso Bayesiano: possono essere quantit\u00e0 osservabili, variabili latenti, parametri sconosciuti o ipotesi. Gli archi rappresentano condizioni di dipendenza; i nodi che non sono connessi rappresentano variabili che sono condizionalmente indipendenti tra di loro. Ad ogni nodo \u00e8 associata una funzione di probabilit\u00e0 che prende in input un particolare insieme di valori per le variabili del nodo genitore e restituisce la probabilit\u00e0 della variabile rappresentata dal nodo. Per esempio, se i genitori del nodo sono variabili booleane allora la funzione di probabilit\u00e0 pu\u00f2 essere rappresentata da una tabella in cui ogni entry rappresenta una possibile combinazione di valori vero o falso che i suoi genitori possono assumere.\nEsistono algoritmi efficienti che effettuano inferenza e apprendimento a partire dalle reti Bayesiane. Le reti Bayesiane che modellano sequenze di variabili che variano nel tempo sono chiamate reti Bayesiane dinamiche.\nMatematicamente, una rete bayesiana \u00e8 un grafo aciclico orientato in cui:\nUna rete bayesiana rappresenta la distribuzione della probabilit\u00e0 congiunta di un insieme di variabili."], "concept_B": "Rete bayesiana", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["1105351", "Dbscan", "Il DBSCAN (\"Density-Based Spatial Clustering of Applications with Noise\") \u00e8 un metodo di clustering proposto nel 1996 da Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander and Xiaowei Xu. \u00c8 basato sulla densit\u00e0 perch\u00e9 connette regioni di punti con densit\u00e0 sufficientemente alta. DBSCAN \u00e8 l'algoritmo pi\u00f9 comunemente usato ed \u00e8 anche il pi\u00f9 citato nella letteratura scientifica.\nDBSCAN usa una definizione di cluster basata sulla nozione di \"density-reachability\". Un punto formula_1 \u00e8 direttamente raggiungibile da un punto formula_2 se la loro distanza \u00e8 minore di un assegnato formula_3 (cio\u00e8, \u00e8 parte del suo formula_3-vicinato) e se formula_2 \u00e8 circondato da un sufficiente numero di punti, allora formula_2 e formula_1 possono essere considerati parti di un cluster. Il punto formula_1 \u00e8 \"density-reachable\" da formula_2 se c'\u00e8 una sequenza formula_10 di punti con formula_11 e formula_12 dove ogni formula_13 \u00e8 density-reachable direttamente da formula_14. Si osservi che la relazione density-reachable non \u00e8 simmetrica dato che formula_1 potrebbe situarsi su una periferia del cluster, avendo un numero insufficiente di vicini per considerarlo un elemento genuino del cluster. Di conseguenza la nozione \"density-connected\" diventa: due punti formula_2 e formula_1 sono density-connected se c'\u00e8 un punto formula_18 tale che sia formula_18 e formula_2 sia formula_18 e formula_1 sono density-reachable.\nUn cluster, che \u00e8 un sotto-insieme dei punti del database, soddisfa due propriet\u00e0:\nDBSCAN necessita di due parametri: formula_3 (eps) e del numero minimo di punti richiesti per formare un cluster (minPts). Si comincia con un punto casuale che non \u00e8 stato ancora visitato. Viene calcolato il suo formula_3-vicinato e se contiene un numero sufficiente di punti viene creato un nuovo cluster. Se ci\u00f2 non avviene il punto viene etichettato come rumore e successivamente potrebbe essere ritrovato in un formula_3-vicinato sufficientemente grande riconducibile ad un punto differente entrando a far parte di un cluster.\nSe un punto \u00e8 associato ad un cluster anche i punti del suo formula_3-vicinato sono parte del cluster. Conseguentemente tutti i punti trovati all'interno del suo formula_3-vicinato sono aggiunti al cluster, cos\u00ec come i loro formula_3-vicinati. Questo processo continua fino a quando il cluster viene completato. Il processo continua fino a quando non sono stati visitati tutti i punti.\n DBSCAN(D, eps, MinPts)\nDBSCAN visita ogni punto del database, anche pi\u00f9 volte nel caso di punti candidati a cluster differenti. Tuttavia per considerazioni pratiche la complessit\u00e0 temporale \u00e8 per lo pi\u00f9 governata dal numero di invocazioni a getVicini, in riferimento allo pseudo codice di cui sopra. DBSCAN esegue esattamente una invocazione per ogni punto e se viene utilizzata una struttura indicizzata che esegue un'interrogazione del vicinato in formula_29, si ottiene un tempo globale di esecuzione pari a formula_30. Senza l'uso di strutture indicizzate, il tempo di esecuzione \u00e8 pari a formula_31. Spesso la matrice delle distanze di dimensione formula_32 viene creata per evitare appunto il ricalcolo delle distanze riducendo il tempo di elaborazione a spese della memoria utilizzata pari a formula_31.\nDBSCAN presenta i seguenti vantaggi:\nIl rilevamento del vicinato pi\u00f9 vicino avviene nella funzione getVicini(P,epsilon). Per ogni punto P vengono determinati tutti gli altri punti che sono all'interno dell'intervallo epsilon, basandosi sulla funzione della distanza usata nell'algoritmo. L'analisi richiede che sia calcolata una matrice delle distanze per l'intero data set. La generazione della matrice delle distanze ha una complessit\u00e0 di formula_34dato che \u00e8 necessaria solo una matrice triangolare superiore. All'interno della matrice delle distanze il vicinato pi\u00f9 vicino pu\u00f2 essere calcolato selezionando la tupla che ha come valori il minimo delle funzioni su riga e colonna. La ricerca ha spinto il rilevamento del vicinato, nei database tradizionali, per migliorare la velocit\u00e0. Questi ultimi risolvono il problema utilizzando indici specificamente progettati per questo tipo di applicazioni.\nOgni processo di data mining ha il problema dei parametri. Ogni parametro influenza l'algoritmo in modo specifico. Per il DBSCAN i parametri epsilon e MinPnts sono necessari. I parametri devono essere specificati dall'utente dato che ogni data set richiede parametri differenti. Un valore iniziale per formula_3 pu\u00f2 essere determinato come un k-distance graph. Come per le regole del pollice, formula_36 pu\u00f2 essere derivato dal numero di dimensioni nel data set formula_37 come formula_38. Tuttavia valori maggiori sono usualmente migliori per data set con rumore.\nAnche se questa stima dei parametri restituisce un insieme sufficiente di parametri, la classificazione risultante pu\u00f2 rivelarsi diversa da ci\u00f2 che si aspetta, pertanto la ricerca ha realizzato un'incrementale ottimizzazione dei parametri su particolari valori.\nPer ogni oggetto vengono trovati i vicini che ricadono in un raggio dato come parametro in ingresso; se il numero di questi vicini \u00e8 superiore ad un fattore di soglia, anch'esso fornito in input all'algoritmo, allora questi punti fanno parte del medesimo cluster di quello dell'oggetto che si sta osservando e in questo caso il punto \u00e8 denominato core point.\nAl termine dell'algoritmo ci potrebbero essere alcuni punti non appartenenti a cluster catalogati come \"rumore\".\nSe c'\u00e8 una catena di oggetti da attraversare (con i consueti vincoli) per raggiungere un punto \"q\" da uno \"p\", allora \"q\" sar\u00e0 detto semplicemente rintracciabile.\nUltimo caso \u00e8 quello in cui due oggetti \"p\" e \"q\" sono detti connessi: per essere definiti in tal modo, deve esistere un terzo punto \"o\", per cui \"p\" e \"q\" sono entrambi rintracciabili."], "concept_B": "Dbscan", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_A": "Clustering", "wikipedia_passage_concept_B": ["2354612", "Clustering gerarchico", "In statistica e apprendimento automatico, il clustering gerarchico \u00e8 un approccio di clustering che mira a costruire una gerarchia di cluster. Le strategie per il clustering gerarchico sono tipicamente di due tipi:\nIl risultato di un clustering gerarchico \u00e8 rappresentato in un dendrogramma.\nPer decidere quali cluster devono essere combinati (approccio agglomerativo) o quale cluster deve essere suddiviso (approccio divisivo) \u00e8 necessario definire una misura di dissimilarit\u00e0 tra cluster. Nella maggior parte dei metodi di clustering gerarchico si fa uso di metriche specifiche che quantificano la distanza tra coppie di elementi e di un criterio di collegamento che specifica la dissimilarit\u00e0 di due insiemi di elementi (cluster) come funzione della distanza a coppie tra elementi nei due insiemi.\nLa scelta di una metrica appropriata influenza la forma dei cluster, poich\u00e9 alcuni elementi possono essere pi\u00f9 \"vicini\" utilizzando una distanza e pi\u00f9 \"lontani\" utilizzandone un'altra. Per esempio, in uno spazio a 2 dimensioni, la distanza tra il punto (1, 1) e l'origine (0, 0) \u00e8 2, formula_1 or 1 se si utilizzando rispettivamente le norme 1, 2 o infinito.\nMetriche comuni sono le seguenti:\nIl criterio di collegamento (\"linkage criterion\") specifica la distanza tra insiemi di elementi come funzione di distanze tra gli elementi negli insiemi.\nDati due insiemi di elementi \"A\" e \"B\" alcuni criteri comunemente utilizzati sono:\ndove \"d\" \u00e8 la metrica prescelta per determinare la similarit\u00e0 tra coppie di elementi."], "concept_B": "Clustering gerarchico", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["2292", "Ipotesi nulla", "Un'ipotesi nulla (in inglese \"null hypothesis,\" che significa letteralmente ipotesi zero) \u00e8 un'affermazione sulla distribuzione di probabilit\u00e0 di una o pi\u00f9 variabili casuali. Si intende per ipotesi nulla l'affermazione secondo la quale non ci sia differenza oppure non vi sia relazione tra due fenomeni misurati, o associazione tra due gruppi. Solitamente viene assunta vera finch\u00e9 non si trova evidenza che la confuti.\nNel test statistico viene verificata in termini probabilistici la validit\u00e0 di un'ipotesi statistica, detta appunto ipotesi nulla, di solito indicata con \"H\".\nAttraverso una funzione dei dati campionari si decide se accettare l'ipotesi nulla o meno. Nel caso l'ipotesi nulla venga rifiutata si accetter\u00e0 l'ipotesi alternativa, indicata con \"H\".\nSe si rifiuta un'ipotesi nulla che nella realt\u00e0 \u00e8 vera allora si dice che si \u00e8 commesso un errore di prima specie (o falso positivo). Accettando invece un'ipotesi nulla falsa si commette un errore di seconda specie (o falso negativo).\nL'ipotesi pu\u00f2 essere di tipo funzionale se riferita alla forma della f (x;\u03b8) con f funzione di densit\u00e0 o di probabilit\u00e0, o parametrica se riferita al vettore incognito \u03b8.\nL'ipotesi \u00e8 semplice quando specifica completamente la f (x;\u03b8). Nel caso un'ipotesi non sia semplice si dir\u00e0 composta.\nQuando si considera un solo parametro l'ipotesi semplice \u00e8 del tipo \u03b8=\u03b8, dove \u03b8 \u00e8 un valore particolare. Un'ipotesi \u00e8 unilaterale se \u00e8 del tipo \u03b8 > \u03b8 oppure del tipo \u03b8 < \u03b8.\nUn'ipotesi \u00e8 bilaterale se \u00e8 del tipo \u03b8 \u2260 \u03b8 oppure del tipo \u03b8 < \u03b8 e \u03b8 > \u03b8."], "concept_A": "Ipotesi nulla", "wikipedia_passage_concept_B": ["2246484", "Precisione e recupero", ", o richiamo (in inglese \"precision\" e \"recall\") sono due comuni classificazioni statistiche, utilizzate in diversi ambiti del sapere, come per es. l'information retrieval. La precisione pu\u00f2 essere vista come una misura di \"esattezza\" o fedelt\u00e0, mentre il recupero \u00e8 una misura di \"completezza\".\nNell'Information Retrieval, la precisione \u00e8 definita come il numero di documenti attinenti recuperati da una ricerca diviso il numero totale di documenti recuperati dalla stessa ricerca, e il recupero \u00e8 definito come il numero di documenti attinenti recuperati da una ricerca diviso il numero totale di documenti attinenti esistenti (che dovrebbe essere stato recuperato).\nIn un processo di classificazione statistica, la precisione per una classe \u00e8 il numero di veri positivi (il numero di oggetti etichettati correttamente come appartenenti alla classe) diviso il numero totale di elementi etichettati come appartenenti alla classe (la somma di veri positivi e falsi positivi, che sono oggetti etichettati erroneamente come appartenenti alla classe).\nRecupero in questo contesto \u00e8 definito come il numero di veri positivi diviso il numero totale di elementi che attualmente appartengono alla classe (per esempio la somma di veri positivi e falsi negativi, che sono oggetti che non sono stati etichettati come appartenenti alla classe ma dovrebbero esserlo).\nNell'Information Retrieval, un valore di precisione di 1.0 significa che ogni risultato recuperato da una ricerca \u00e8 attinente mentre un valore di recupero pari a 1.0 significa che tutti i documenti attinenti sono stati recuperati dalla ricerca.\nIn un processo di classificazione, un valore di precisione di 1.0 per la classe C significa che ogni oggetto che \u00e8 stato etichettato come appartenente alla classe C vi appartiene davvero (ma non dice niente sul numero di elementi della classe C che non sono stati etichettati correttamente) mentre un valore di recupero pari ad 1.0 significa che ogni oggetto della classe C \u00e8 stato etichettato come appartenente ad essa (ma non dice niente sul numero di elementi etichettati non correttamente con C).\nNell'information retrieval, precisione e recupero sono definite in termini di insieme di documenti recuperati (lista di documenti restituiti da un motore di ricerca rispetto ad una query) e un insieme di documenti attinenti (lista di tutti i documenti che sono attinenti per l'argomento cercato).\nformula_1\nformula_2\nIn un processo di classificazione, i termini vero positivo, vero negativo, falso positivo e falso negativo sono usati per confrontare la classificazione di un oggetto (l'etichetta di classe assegnata all'oggetto da un classificatore) con la corretta classificazione desiderata (la classe a cui in realt\u00e0 appartiene l'oggetto).\nPrecisione e recupero sono definite come:"], "concept_B": "Precisione e recupero", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["3587354", "Distribuzione congiunta", "In probabilit\u00e0, date due variabili aleatorie \"X\" e \"Y\", definite sullo stesso spazio di probabilit\u00e0, si definisce la loro distribuzione congiunta come la distribuzione di probabilit\u00e0 associata al vettore formula_1. Nel caso di due sole variabili, si parla di distribuzione bivariata, mentre nel caso di pi\u00f9 variabili si parla di distribuzione multivariata.\nLa funzione di ripartizione di una distribuzione congiunta \u00e8 definita come\no pi\u00f9 generalmente\nNel caso di variabili aleatorie discrete, la densit\u00e0 discreta congiunta (o funzione di massa di probabilit\u00e0 congiunta) \u00e8 data da\nSiccome la densit\u00e0 congiunta \u00e8 anch'essa una densit\u00e0, \u00e8 soddisfatta la seguente equazione:\nNel caso di variabili aleatorie continue, la densit\u00e0 congiunta \u00e8 data da\ndove \"f\"(\"y\"|\"x\") e \"f\"(\"x\"|\"y\") sono le distribuzioni condizionate di Y dato X=x e di X dato Y=y, mentre \"f\"(\"x\") e \"f\"(\"y\") sono le distribuzioni marginali della densit\u00e0 congiunta, rispettivamente per X e Y.\nAnche in questo caso, \u00e8 soddisfatto"], "concept_A": "Distribuzione congiunta", "wikipedia_passage_concept_B": ["255044", "Intervallo di confidenza", "statistica, quando si stima un parametro, la semplice individuazione di un singolo valore \u00e8 spesso non sufficiente.\n\u00c8 opportuno allora accompagnare la stima di un parametro con un intervallo di valori plausibili per quel parametro, che viene definito intervallo di confidenza (o intervallo di fiducia).\nSe formula_1 e formula_2 sono variabili casuali con distribuzioni di probabilit\u00e0 che dipendono da qualche parametro formula_3 e formula_4 (dove formula_5 \u00e8 un numero tra 0 e 1), allora l'intervallo casuale formula_6 \u00e8 un intervallo di confidenza al formula_7 per formula_8. I valori estremi dell'intervallo di confidenza si chiamano \"limiti di confidenza\".\nAd esso si associa quindi un valore di probabilit\u00e0 cumulativa che caratterizza, indirettamente in termini di probabilit\u00e0, la sua ampiezza rispetto ai valori massimi assumibili dalla variabile aleatoria misurando cio\u00e8 la probabilit\u00e0 che l'evento casuale descritto dalla variabile aleatoria in oggetto cada all'interno di tale intervallo, graficamente pari all'area sottesa dalla curva di distribuzione di probabilit\u00e0 della variabile aleatoria nell'intervallo considerato.\n\u00c8 bene non confondere l'intervallo di confidenza con la probabilit\u00e0. Data l'espressione \"vi \u00e8 un livello di confidenza del 95% che formula_9 sia nell'intervallo\", nulla si pu\u00f2 dire sulla probabilit\u00e0 che l'intervallo ottenuto contenga formula_10\nSi ipotizzi di voler calcolare l'et\u00e0 media degli abitanti di un luogo. Supponiamo che non si conosca l'et\u00e0 per ogni singolo abitante. Viene allora estratto un campione casuale di abitanti di cui \u00e8 possibile sapere l'et\u00e0, e dal campione si tenta di inferire (\"predire\") l'et\u00e0 media per tutta la popolazione residente e la variabilit\u00e0 di tale dato. Questo pu\u00f2 essere fatto calcolando, ad esempio, l'et\u00e0 media delle persone presenti nel campione e ipotizzando che questo valore coincida con l'et\u00e0 media di tutta la popolazione inclusa quella non scelta nel campione. In questo caso si \u00e8 fatta una \"stima puntuale\". Alternativamente, a partire dalle et\u00e0 delle persone nel campione, si pu\u00f2 calcolare un intervallo di valori entro il quale si ritenga ci sia il valore della media di tutta la popolazione e, se la procedura \u00e8 fatta in modo rigoroso e statisticamente corretto, \u00e8 possibile stabilire un valore di \"confidenza\" di quanto sia \"credibile\" che l'intervallo ottenuto contenga effettivamente il valore cercato. In questo caso si \u00e8 fatta una \"stima per intervalli\" e l'intervallo ottenuto \u00e8 detto \"intervallo di confidenza\".\nRiassumendo: la stima puntuale fornisce un valore singolo che varia a seconda del campione, e difficilmente coincide con il valore vero della popolazione; la stima per intervalli fornisce un insieme di valori (intervallo) che con una certa \"confidenza\" contiene il valore vero della popolazione.\nSe formula_11 \u00e8 una variabile aleatoria di media formula_9 e varianza formula_13 con formula_14 si indica la variabile campionaria corrispondente che ha media aritmetica degli formula_15 dati osservati nel campione\ne deviazione standard\nIl livello di confidenza \u00e8 fissato dal ricercatore. Il valore scelto pi\u00f9 di frequente \u00e8 95%. Tuttavia, meno di frequente, viene scelto anche un livello di confidenza del 90%, oppure del 99%.\nSe il valore di formula_18 non differisce molto dalla variabilit\u00e0 formula_19 della popolazione, pu\u00f2 essere assunto come suo stimatore (ad esempio con un numero di soggetti osservati e replicazioni complessivamente maggiore di 60; in alternativa si ipotizza una distribuzione t di Student caratterizzata da una maggiore dispersione rispetto alla normale standard). In questa prima ipotesi, l'intervallo di confidenza per la media formula_9 (\"vera media\", della popolazione) al 99% (al livello formula_21), \u00e8 dato da:\nAl 95% \u00e8 dato da:\nPrima della diffusione dei computer si cercava di utilizzare l\u2019approssimazione normale ogni qualvolta possibile. Adesso non \u00e8 pi\u00f9 strettamente necessario, e nella formula possono essere utilizzati percentili di altre distribuzioni, facendo rifierimento a campioni di dimensione pi\u00f9 ridotta).\nDalle formule risulta che i due intervalli di confidenza possono essere scritti in funzione dei \"soli dati campionari\" formula_24.\nOltre a diminuire con il livello di confidenza, l'ampiezza dell'intervallo dipende dall'errore della stima formula_25 e diminuisce se:\nQualora la popolazione non segua il modello gaussiano, se il campione \u00e8 grande a sufficienza, la variabile campionaria tende a seguire comunque una legge normale (teorema centrale del limite). In altre parole, le due formule precedenti per l'intervallo di confidenza si possono usare anche nel caso in cui non \u00e8 nota la sua legge di probabilit\u00e0.\nIl livello di confidenza o copertura \u00e8 il complemento a uno del livello di significativit\u00e0 formula_27: ad esempio, un intervallo di confidenza al formula_28 corrisponde a un livello di significativit\u00e0 di formula_29.\nGli intervalli di confidenza sono spesso confusi con altri concetti della statistica, e talora oggetto di errate interpretazioni anche da parte di ricercatori professionisti. Alcuni errori comuni:\nGli intervalli di confidenza furono introdotti da Jerzy Neyman in un articolo pubblicato nel 1937.\nC'\u00e8 un metodo agevole per il calcolo degli intervalli di confidenza attraverso il test di verifica d'ipotesi (secondo l'impostazione di Neyman).\nUn intervallo di confidenza al 95% si pu\u00f2 quindi ricavare da un test di verifica d'ipotesi di significativit\u00e0 5%."], "concept_B": "Intervallo di confidenza", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["3550", "Probabilit\u00e0 condizionata", "In teoria della probabilit\u00e0 la probabilit\u00e0 condizionata di un evento \"A\" rispetto a un evento \"B\" \u00e8 la probabilit\u00e0 che si verifichi \"A\", sapendo che \"B\" \u00e8 verificato. Questa probabilit\u00e0, indicata formula_1 o formula_2, esprime una \"correzione\" delle aspettative per \"A\", dettata dall'osservazione di \"B\".\nPoich\u00e9, come si vedr\u00e0 nella successiva definizione, formula_3 compare al denominatore, formula_1 ha senso solo se \"B\" ha una probabilit\u00e0 non nulla di verificarsi. \n\u00c8 utile osservare che la notazione con il simbolo \"Barra verticale\" \u00e8 comune con la definizione del connettivo logico NAND.\nPer esempio, la probabilit\u00e0 di ottenere \"4\" con il lancio di un dado a sei facce (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nSi consideri questo secondo esempio, la probabilit\u00e0 di ottenere \"1\" con il lancio di un comune dado (evento \"A\") ha probabilit\u00e0 \"P(A)=1/6\" di verificarsi. \"Sapendo\" per\u00f2 che il risultato del lancio \u00e8 un numero tra \"4\", \"5\" e \"6\" (evento \"B\"), la probabilit\u00e0 di \"A\" diventa \nLa probabilit\u00e0 di \"A\" condizionata da \"B\" \u00e8\ndove formula_8 \u00e8 la probabilit\u00e0 congiunta dei due eventi, ovvero la probabilit\u00e0 che si verifichino entrambi.\nIn termini pi\u00f9 rigorosi, dato uno spazio misurabile formula_9 di misura \"P\", ogni evento \"B\" eredita una struttura di spazio misurato formula_10, restringendo gli insiemi misurabili a quelli contenuti in \"B\", ed induce una nuova misura formula_11 su formula_9, con formula_13.\nSe formula_14 \u00e8 uno spazio probabilizzato (formula_15) e \"B\" non \u00e8 trascurabile (formula_16), allora riscalando formula_17 a formula_18 si ottiene lo spazio probabilizzato formula_19 delle probabilit\u00e0 condizionate da \"B\".\nLa formula della probabilit\u00e0 condizionata permette di descrivere la probabilit\u00e0 congiunta come\nOvvero, la probabilit\u00e0 che si verifichino sia \"A\" sia \"B\" \u00e8 pari alla probabilit\u00e0 che si verifichi \"B\" moltiplicata per la probabilit\u00e0 che si verifichi \"A\" supponendo che \"B\" sia verificato.\nDue eventi \"A\" e \"B\" sono indipendenti quando vale una delle tre equazioni equivalenti\nPer trovare la probabilit\u00e0 dell'evento a destra negato si pu\u00f2 usare la seguente formula:\nformula_24.\nSe \"A\" e \"B\" sono eventi disgiunti, cio\u00e8 se formula_25, le loro probabilit\u00e0 condizionate sono nulle: sapendo che uno dei due eventi si \u00e8 verificato, \u00e8 impossibile che si sia verificato \"anche\" l'altro.\nSe l'evento \"A\" implica l'evento \"B\", cio\u00e8 se formula_26, allora la loro intersezione \u00e8 \"A\", per cui formula_27 e:\nNel caso di una misura di probabilit\u00e0 uniforme su uno spazio \u03a9 finito, questa formula per \"P(A|B)\" esprime la definizione classica di probabilit\u00e0 come \"casi favorevoli (\"A\") su casi possibili (\"B\")\". \nInvece, per \"P(B|A)\" otteniamo il valore 1 che, per un numero finito di valori lo stesso Bayes interpret\u00f2 in senso lato come la certezza che il tutto sia condizionato dalla parte.\nLa speranza condizionata formula_30 di una variabile aleatoria \"X\" ad un evento \"B\" \u00e8 la speranza di \"X\" calcolata sulle probabilit\u00e0 formula_31 (condizionate da \"B\").\nLa probabilit\u00e0 di un evento \"A\" pu\u00f2 essere condizionata da una variabile aleatoria discreta \"X\", originando una nuova variabile aleatoria, formula_32, che per \"X=x\" assume il valore formula_33.\nIl teorema di Bayes esprime l'uguaglianza simmetrica formula_34 del teorema della probabilit\u00e0 composta come\nQuesto teorema \u00e8 alla base dell'inferenza bayesiana in statistica, dove \"P\" \u00e8 detta \"probabilit\u00e0 \"a priori\" di \"B\"\" e \"P\" \"probabilit\u00e0 \"a posteriori\" di \"B\"\".\nMolti paradossi sono legati alla probabilit\u00e0 condizionata e derivano sia da un'errata formulazione del problema sia dalla confusione di \"P(A|B)\" con \"P(A)\" o con \"P(B|A)\".\nEsempi particolari sono il paradosso delle due buste, il paradosso dei due bambini, il problema di Monty Hall e il paradosso di Simpson."], "concept_A": "Probabilit\u00e0 condizionata", "wikipedia_passage_concept_B": ["4145289", "Distribuzione di probabilit\u00e0 a priori", "Nell'ambito dell'inferenza statistica bayesiana, una distribuzione di probabilit\u00e0 a priori, detta spesso anche distribuzione a priori, di una quantit\u00e0 incognita \"p\" (per esempio, supponiamo \"p\" essere la proporzione di votanti che voteranno per il politico Rossi in un'elezione futura) \u00e8 la distribuzione di probabilit\u00e0 che esprimerebbe l'incertezza di \"p\" prima che i \"dati\" (per esempio, un sondaggio di opinione) siano presi in considerazione. Il proposito \u00e8 di attribuire incertezza piuttosto che casualit\u00e0 a una quantit\u00e0 incerta. La quantit\u00e0 incognita pu\u00f2 essere un parametro o una variabile latente.\nSi applica il teorema di Bayes, moltiplicando la distribuzione a priori per la funzione di verosimiglianza e quindi normalizzando, per ottenere la distribuzione di probabilit\u00e0 a posteriori, la quale \u00e8 la distribuzione condizionata della quantit\u00e0 incerta una volta ottenuti i dati.\nSpesso una distribuzione a priori \u00e8 l'accertamento soggettivo (elicitazione) di una persona esperta. Quando possibile, alcuni sceglieranno una \"distribuzione a priori coniugata\" per rendere pi\u00f9 semplice il calcolo della distribuzione a posteriori.\nI parametri di una distribuzione a priori sono chiamati \"iperparametri\", per distinguerli dai parametri del modello dei dati sottostanti. Per esempio, se si sta usando una distribuzione beta per modellare la distribuzione di un parametro \"p\" di una distribuzione di Bernoulli, allora:\nUna \"distribuzione a priori informativa\" esprime una specifica, definita informazione circa una variabile.\nUn esempio \u00e8 la distribuzione a priori per la temperatura di domattina.\nUn approccio ragionevole \u00e8 costruire la distribuzione a priori come una distribuzione normale con valore atteso uguale alla temperatura mattutina di oggi, con una varianza uguale alla varianza giorno per giorno della temperatura atmosferica, oppure come una distribuzione della temperatura per quel tal giorno dell'anno.\nQuesto esempio ha una propriet\u00e0 in comune con molte distribuzioni a priori, ovvero che la distribuzione a posteriori di un problema (temperatura odierna) diventa la distribuzione a priori per un altro problema (temperatura di domani); l'evidenza preesistente, che \u00e8 gi\u00e0 stata tenuta in conto, \u00e8 parte della distribuzione a priori e come ulteriore evidenza viene accumulata. \nLa distribuzione a priori \u00e8 largamente determinata dall'evidenza piuttosto che da qualche assunzione originale, sempre che l'assunzione originale ammetta la possibilit\u00e0 (ossia sia compatibile) con quello che l'evidenza suggerisce. I termini \"a priori\" e \"a posteriori\" sono generalmente relativi a un dato o un'osservazione specifica.\nUna \"distribuzione a priori non informativa\" esprime vaghezza o informazione a carattere generale circa una variabile.\nIl termine \"non informativa\" pu\u00f2 essere un po' fuorviante; spesso, tale tipo di distribuzione \u00e8 chiamata \"a priori non molto informativa\", oppure \"a priori oggettiva\", cio\u00e8 una distribuzione che non \u00e8 soggettivamente esplicitata.\nLe distribuzioni a priori non informative possono esprimere informazione \"oggettiva\" come ad esempio \"la variabile \u00e8 positiva\" oppure \"la variabile \u00e8 minore di tal limite\".\nLa pi\u00f9 semplice e vecchia regola per determinare una distribuzione a priori non informativa \u00e8 il principio d'indifferenza, il quale assegna a tutti gli eventi uguale probabilit\u00e0.\nIn problemi di stima parametrica, l'uso di una distribuzione a priori non informativa d\u00e0 risultati che sono non troppo differenti dall'analisi statistica convenzionale. Questo accade in quanto la funzione di verosimiglianza fornisce la parte maggiore dell'informazione rispetto a quella fornita dalla distribuzione a priori non informativa nel determinare una distribuzione a posteriori.\nVari tentativi sono stati fatti per trovare probabilit\u00e0 a priori, cio\u00e8 distribuzioni di probabilit\u00e0 in un certo senso logicamente richieste dalla natura di uno stato di incertezza; queste sono soggette a controversia filosofica, con i sostenitori del metodo bayesiano approssimativamente divisi in due scuole: i \"bayesiani oggettivistici\", che credono che tali distribuzioni a priori esistano in molte situazioni, e i \"bayesiani soggettivisti\" che credono che in pratica le distribuzioni a priori rappresentino giudizi di opinione che non possono essere rigorosamente giustificati. Per la maggiore le pi\u00f9 forti argomentazioni a favore della scuola oggettivistica furono date da Edwin T. Jaynes.\nCome esempio di una distribuzione a priori, dovuta a, consideriamo una situazione in cui sappiamo che una pallina \u00e8 nascosta sotto una di tre tazze rovesciate, A, B o C, ma nessun'altra informazione \u00e8 disponibile circa la sua posizione. In questo caso una distribuzione a priori uniforme di formula_1 sembra intuitivamente verosimile la sola scelta ragionevole. Pi\u00f9 formalmente, noi possiamo vedere che il problema rimane lo stesso se scambiamo le lettere identificative \"A\", \"B\" e \"C\" delle tazze. Sarebbe perci\u00f2 strano scegliere una distribuzione a priori per la quale una permutazione delle lettere causerebbe un cambio nella nostra predizione circa la posizione dove la pallina sar\u00e0 trovata; la distribuzione a priori uniforme \u00e8 la sola che preserva questa invarianza. Se si accetta questo principio di invarianza allora si pu\u00f2 vedere che la distribuzione a priori uniforme \u00e8 la distribuzione logicamente corretta che rappresenta questo stato di conoscenza a priori. Si avr\u00e0 notato che questa distribuzione a priori \u00e8 \"oggettiva\" nel senso di essere la scelta corretta per rappresentare un particolare stato di conoscenza, ma non \u00e8 oggettiva nel senso di essere una caratteristica del sistema osservato indipendente dall'osservatore: in realt\u00e0 la pallina esiste sotto una specifica tazza e in questa situazione ha solo senso parlare di probabilit\u00e0 se c'\u00e8 un osservatore con una conoscenza limitata del sistema ossia della posizione della pallina sotto le tazze.\nCome esempio pi\u00f9 controverso, Jaynes pubblic\u00f2 un argomento basato sui gruppi di Lie suggerente che la distribuzione a priori rappresentante in maniera completa l'incertezza sarebbe la distribuzione a priori di Haldane \"p\"(1\u00a0\u2212\u00a0\"p\"). L'esempio fornito da Jaynes \u00e8 quello di trovare un chimico in un laboratorio e di chiedergli di eseguire ripetutamente degli esperimenti di dissoluzione in acqua. La distribuzione a priori di Haldane da prevalentemente la maggiore probabilit\u00e0 agli eventi formula_2 and formula_3, indicando che il campione ogni volta si scioglier\u00e0 oppure no, con uguale probabilit\u00e0. Tuttavia se sono stati osservati campioni non disciogliersi in un esperimento e disciogliersi in un altro, allora questa distribuzione a priori \u00e8 aggiornata alla distribuzione uniforme sull'intervallo [0, 1]. Questo risultato si ottiene applicando il teorema di Bayes all'insieme di dati consistente in un'osservazione di dissoluzione e una di non dissoluzione, usando la distribuzione a priori precedente. sulla base che essa fornisce una distribuzione a posteriori impropria che pone il 100% del contenuto di probabilit\u00e0 sia a \"p\" = 0 o a \"p\" = 1 se un numero finito di esperimenti ha dato lo stesso risultato (ad esempio il discioglimento). La distribuzione a priori di Jeffreys \"p\"(1\u00a0\u2212\u00a0\"p\") \u00e8 perci\u00f2 preferita (\"cfr.\" sotto).\nSe lo spazio parametrico X \u00e8 dotato di una struttura di gruppo naturale che lascia invariato il nostro stato di conoscenza bayesiano, allora la distribuzione a priori pu\u00f2 essere costruita proporzionale alla Misura di Haar. Questo pu\u00f2 essere visto come una generalizzazione del principio di invarianza che giustificava la distribuzione a priori uniforme dell'esempio delle tre tazze visto sopra. Per esempio, in fisica ci si aspetta che un esperimento dia i medesimi risultati indipendentemente dalla scelta dell'origine del sistema di coordinate. Questo induce la struttura gruppale del gruppo delle traslazioni su \"X\", il quale determina la distribuzione di probabilit\u00e0 a priori come una distribuzione a priori impropria costante. Analogamente alcuni sistemi fisici presentano un'invarianza di scala (ossia i risultati sperimentali sono indipendenti dal fatto che, ad esempio, usiamo centimetri o pollici). In tal caso il gruppo di scala \u00e8 la struttura di gruppo naturale, e la corrispondente distribuzione a priori su \"X\" \u00e8 proporzionale a 1/\"x\". Qualche volta risulta importante se viene usata la misura di Haar invariante a sinistra piuttosto che quella invariante a destra. Per esempio, le misure di Haar invarianti a destra e a sinistra sul gruppo affine non sono uguali. Berger (1985, p.\u00a0413) arguisce che la scelta corretta \u00e8 la misura di Haar invariante a destra.\nUn'altra idea, supportata da Edwin T. Jaynes, \u00e8 di usare il principio di massima entropia (MAXENT). La motivazione \u00e8 che l'entropia di Shannon di una distribuzione di probabilit\u00e0 misura l'ammontare di informazione contenuta nella distribuzione. Maggiore \u00e8 l'entropia, minore \u00e8 l'informazione fornita dalla distribuzione. Perci\u00f2, mediante la massimizzazione dell'entropia sopra un adeguato insieme di distribuzioni di probabilit\u00e0 su \"X\", si trova la distribuzione che \u00e8 meno informativa nel senso che essa contiene il minore ammontare di informazione consistente con le costrizioni definite dall'insieme scelto. Per esempio, la distribuzione a priori di massima entropia su uno spazio discreto, dato solo il fatto che la probabilit\u00e0 \u00e8 normalizzata a 1, \u00e8 la distribuzione a priori che assegna uguale probabilit\u00e0 ad ogni stato. Mentre nel caso continuo, la distribuzione a priori di massima entropia con densit\u00e0 normalizzata, media nulla e varianza unitaria, \u00e8 la ben nota distribuzione normale. Il principio di minima entropia incrociata generalizza il principio di massima entropia al caso di \"aggiornamento\" di una distribuzione a priori arbitraria con adeguate costrizioni nel senso di massima entropia.\nUn'idea collegata, la distribuzione a priori di riferimento, fu introdotta da Jos\u00e9-Miguel Bernardo. Qui l'idea \u00e8 di massimizzare il valore atteso della divergenza di Kullback\u2013Leibler della distribuzione a posteriori rispetto alla distribuzione a priori. Questo massimizza l'informazione attesa riguardante \"X\" quando la densit\u00e0 a priori \u00e8 \"p\"(\"x\"); perci\u00f2, in un certo senso, \"p\"(\"x\") \u00e8 la distribuzione a priori \"meno informativa\" riguardo X. La distribuzione a priori di riferimento \u00e8 definita nel limite asintotico, cio\u00e8 si considera il limite delle distribuzioni a priori cos\u00ec ottenute come il numero di dati va all'infinito. Nei problemi multivariati spesso vengono scelte come distribuzioni a priori oggettive le distribuzioni a priori di riferimento, dato che altre scelte (ad esempio la regola di Jeffreys possono portare a distribuzioni a priori dal comportamento problematico.\nDistribuzioni a priori oggettive possono anche essere derivate da altri principi, come le teorie dell'informazione o le teorie della codifica (vedi ad esempio lunghezza di descrizione minima) oppure della statistica frequentista.\nProblemi filosofici legati alle distribuzioni a priori non informative sono associati alla scelta di una metrica appropriata o scala di misurazione. Supponiamo di volere una distribuzione a priori per la valocit\u00e0 di un corridore a noi sconosciuto. Potremmo specificare, diciamo, per la sua velocit\u00e0 una distribuzione a priori di tipo normale, ma in alternativa potremmo specificare una distribuzione a priori normale per il tempo impiegato a percorrere 100 metri, il quale \u00e8 proporzionale al reciproco della prima distribuzione a priori. Queste due distribuzioni a priori sono effettivamente differenti, ma non \u00e8 chiaro quale delle due preferire. Il metodo, spesso sopravvalutato, di trasformazione dei gruppi di Jaynes pu\u00f2 rispondere a tale questione in varie situazioni.\nIn maniera simile, se ci \u00e8 chiesto di stimare una proporzione incognita tra 0 e 1, noi possiamo affermare che tutte le proporzioni sono ugualmente probabili ed usare una distribuzione a priori uniforme. Alternativamente, potremmo dire che tutti gli ordini di grandezza per la proporzione sono ugualmente probabili, e scegliere la distribuzione a priori logaritmica, la quale \u00e8 la distribuzione a priori uniforme sul logaritmo della proporzione. La distribuzione a priori di Jeffreys tenta di risolvere questo problema calcolando una distribuzione a priori che esprime la medesima credenza indipendentemente dalla metrica utilizzata. La distribuzione a priori di Jeffreys per una proporzione incognita \"p\" \u00e8 \"p\"(1\u00a0\u2212\u00a0\"p\"), che differisce da quella raccomandata da Jaynes.\nDistribuzioni a priori basate sulla nozione di probabilit\u00e0 algoritmica vengono impiegate nel campo dell'inferenza induttiva come base induttiva in configurazioni del tutto generali.\nProblemi pratici associati con le distribuzioni a priori non informative includono il requisito che la distribuzione a posteriori sia propria. Le distribuzioni a priori non informative su variabili continue, non limitate sono improprie. Questo non \u00e8 necessariamente un problema se la distribuzione a posteriori \u00e8 propria. Un altro argomento importante \u00e8 quello in cui se una distribuzione a priori non informativa viene usata in maniera regolare, cio\u00e8 con svariati insiemi di dati, allora essa avrebbe buone propriet\u00e0 frequentiste. Normalmente un bayesiano non dovrebbe porsi questo problema, ma potrebbe essere importante farlo in questa situazione. Per esempio, uno potrebbe volere che qualsiasi regola di decisione basata sulla distribuzione a posteriori sia ammissibile sotto la funzionedi perdita adottata. Sfortunatamente, l'ammissibilit\u00e0 \u00e8 difficile da verificare, nonostante vari risultati siano noti (\"cfr.\" ad esempio, Berger and Strawderman, 1996). Il problema \u00e8 particolarmente acuto con i modelli di Bayes gerarchici; le distribuzioni a priori usuali (ad esempio la distribuzione a priori di Jeffreys) possono dare regole di decisione praticamente inammissibili se impiegate ai livelli gerarchici pi\u00f9 elevati.\nSe il teorema di Bayes viene scritto come\nallora \u00e8 chiaro che si otterrebbe il medesimo risultato se tutte le probabilit\u00e0 a priori \"P\"(\"A\") e \"P\"(\"A\") fossero moltiplicate per una data costante; lo stesso sarebbe vero per una variabile casuale continua. Se la sommatoria al denominatore converge, le probabilit\u00e0 a posteriori sommeranno (o integreranno) ancora a 1 anche se i valori della distribuzione a priori non lo fanno, e in tal modo pu\u00f2 solo essere necessario richiedere alle distribuzioni a priori di essere specificate nella proporzione corretta. Spingendo oltre questa idea, in molti casi non \u00e8 neanche richiesto che la somma o l'integrale dei valori della distribuzione a priori sia finita per ottenere risposte significative circa le probabilit\u00e0 a posteriori. Quando questo \u00e8 il caso, la distribuzione a priori \u00e8 chiamata distribuzione a priori impropria. Tuttavia, se la distribuzione a priori \u00e8 impropria, allora non \u00e8 necessario che la distribuzione a posteriori sia propria. Questo \u00e8 chiaro nella situazione in cui l'evento \"B\" \u00e8 indipendente da tutti gli altri eventi \"A\".\nVari statistici usano le distribuzioni a priori improprie come distribuzioni a priori non informative. Per esempio, se hanno bisogno di una distribuzione a priori per la media e la varianza di una variabile casuale, allora essi assumono \"p\"(\"m\",\u00a0\"v\")\u00a0~\u00a01/\"v\" (per \"v\" > 0) il che suggerirebbe che qualsiasi valore per la media \u00e8 \"ugualmente probabile\" e che un valore per la varianza positiva diventa \"meno probabile\" in proporzione inversa al suo valore. Molti autori (Lindley, 1973; De Groot, 1937; Kass and Wasserman, 1996) mettono in guardia contro il pericolo di sovra-interpretare tali distribuzioni a priori poich\u00e9 non sono densit\u00e0 di probabilit\u00e0. La loro sola rilevanza che esse hanno si trova nella distribuzione a posteriori corrispondente, fintanto che questa \u00e8 ben definita per tutte le osservazioni. (La distribuzione a priori di Haldane \u00e8 un tipico controesempio.)\nEsempi di distribuzioni a priori includono:\nIl concetto di probabilit\u00e0 algoritmica fornisce una via per specificare la probabilit\u00e0 delle distribuzioni a priori basata sulla complessit\u00e0 relativa di modelli presi in considerazione e tra loro alternativi."], "concept_B": "Distribuzione di probabilit\u00e0 a priori", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_A": "Data mining", "wikipedia_passage_concept_B": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_B": "Boosting", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["480718", "Discesa del gradiente", "In ottimizzazione e analisi numerica il metodo di discesa del gradiente (detto anche \"metodo del gradiente\", \"metodo steepest descent\" o \"metodo di discesa pi\u00f9 ripida\") \u00e8 una tecnica che consente di determinare i punti di massimo e minimo di una funzione di pi\u00f9 variabili.\nIl metodo \u00e8 stato sviluppato - e pubblicato nel 1847 - dal matematico francese Augustin-Louis Cauchy nel tentativo di risolvere il problema di determinare l'orbita di un corpo celeste a partire dalle sue equazioni del moto.\nSi supponga di voler minimizzare la funzioneformula_1 e si scelga come soluzione iniziale il vettore formula_2. Allora\ne, muovendosi in un intorno di formula_4:\nQuesti calcoli mostrano che, per individuare dei punti - \"vicini\" a formula_4 - in corrispondenza dei quali la funzione assuma un valore minore di formula_7, conviene spostarsi lungo direzioni che abbiano la prima e la terza componente formula_8 pi\u00f9 piccole o seconda componente formula_9 pi\u00f9 grande. Inoltre esistono delle direzioni \"preferenziali\" lungo le quali la funzione formula_10 decresce pi\u00f9 velocemente (ad esempio scegliere una coordinata formula_11 pi\u00f9 piccola \u00e8 preferibile, ad esempio, rispetto a far diminuire formula_12).\nLa procedura pu\u00f2 essere iterata partendo da un nuovo punto, ad esempio formula_13, fino ad individuare un minimo per formula_10. L'esempio mostra che una procedura che aggiorni la soluzione in modo iterativo sulla base delle informazioni disponibili \"localmente\" pu\u00f2 portare ad individuare un punto di minimo per la funzione assegnata.\nSi voglia risolvere il seguente problema di ottimizzazione non vincolata nello spazio formula_15-dimensionale formula_16\nLa tecnica di discesa secondo gradiente si basa sul fatto che, per una data funzione formula_18, la direzione di massima discesa in un assegnato punto formula_19 corrisponde a quella determinata dall'opposto del suo gradiente in quel punto formula_20. Questa scelta per la direzione di discesa garantisce che la soluzione tenda a un punto di minimo di formula_10. Il metodo del gradiente prevede dunque di partire da una soluzione iniziale formula_4 scelta arbitrariamente e di procedere iterativamente aggiornandola come\ndove formula_24 corrisponde alla lunghezza del passo di discesa, la cui scelta diventa cruciale nel determinare la velocit\u00e0 con cui l'algoritmo converger\u00e0 alla soluzione richiesta.\nSi parla di metodo \"stazionario\" nel caso in cui si scelga un passo formula_25 costante per ogni formula_26, viceversa il metodo si definisce \"dinamico\". In quest'ultimo caso una scelta conveniente, ma computazionalmente pi\u00f9 onerosa rispetto a un metodo stazionario, consiste nell'ottimizzare, una volta determinata la direzione di discesa formula_27, la funzione di una variabile formula_28 in maniera analitica o in maniera approssimata. Si noti che, a seconda della scelta del passo di discesa, l'algoritmo potr\u00e0 convergere a uno qualsiasi dei minimi della funzione formula_10, sia esso locale o globale.\nLo schema generale per l'ottimizzazione di una funzione formula_18 mediante metodo del gradiente \u00e8 il seguente:\nUn caso particolare di applicazione del metodo del gradiente consiste nella risoluzione di sistemi lineari della forma\ndove formula_33 \u00e8 una matrice simmetrica e definita positiva.\nPer le propriet\u00e0 di formula_33 la soluzione di tale problema \u00e8 equivalente alla procedura di minimizzazione della forma quadratica associata:\nInfatti:\nda cui\nPer la funzione formula_38 si ha che la direzione di massima discesa nel punto formula_39 \u00e8:\ncoincidente con il residuo formula_41 del sistema lineare. Dunque la direzione di discesa scelta a ogni iterazione \u00e8 formula_42.\nInoltre vale la seguente relazione:\nche permette di calcolare analiticamente il passo formula_44 ottimale. Infatti, imponendo la condizione di stazionariet\u00e0\nsi ricava\nL'algoritmo del metodo del gradiente per la risoluzione di sistemi lineari \u00e8 dunque\nIn aritmetica floating point la condizione del ciclo while pu\u00f2 essere valutata verificando che la norma del residuo formula_48 non sia pi\u00f9 piccola di una tolleranza impostata dall'utente.\nIn molti casi \u00e8 possibile accelerare la velocit\u00e0 di convergenza dell'algoritmo migliorando le propriet\u00e0 di condizionamento della matrice formula_33. Si introduca a tal fine una matrice di precondizionamento formula_50 simmetrica e definita positiva.\nLo schema risolutivo in questo caso diventa:\nIl metodo del gradiente coniugato costituisce una variante del metodo del gradiente in cui viene effettuata una scelta diversa, ma particolarmente conveniente nel caso di sistemi lineari simmetrici e definiti positivi, per le direzioni di discesa formula_27. Tale scelta garantisce la convergenza del metodo (in aritmetica esatta) in un numero di iterazioni pari al pi\u00f9 alla dimensione del sistema da risolvere.\n\u00c8 possibile dimostrare che l'errore commesso alla formula_26-esima iterazione del metodo del gradiente soddisfa la seguente stima:\ndove\nformula_56 indica il numero di condizionamento in norma formula_57 di formula_33 e formula_59 \u00e8 la norma indotta da formula_33.\nNel caso precondizionato vale la stessa stima con\nSi riporta un esempio di possibile implementazione del metodo del gradiente nella versione precondizionata compatibile con i linguaggi di programmazione Octave e MATLAB.\nQuando la funzione obiettivo \u00e8 troppo costosa da calcolare ad ogni iterazione, ma pu\u00f2 essere scomposta in una somma di molti addendi (ad esempio, la somma del costo calcolato su ogni singolo record in un dataset), il gradiente pu\u00f2 essere approssimato stocasticamente restringendo la somma su un sottinsieme di addendi ad ogni iterazione, metodo noto come discesa stocastica del gradiente.\nLa discesa del gradiente \u00e8 ampiamente utilizzata in statistica e apprendimento automatico per l'addestramento tramite apprendimento supervisionato di modelli come reti neurali artificiali e modelli grafici. Il principio \u00e8 noto come regola delta, e consiste nel valutare il modello su un input il cui corrispondente output esatto sia noto, e correggere ciascun parametro del modello in una quantit\u00e0 proporzionale (ma di segno opposto) rispetto al suo contributo all'errore sul risultato. L'algoritmo usato nelle reti neurali per implementare questo principio \u00e8 noto come retropropagazione dell'errore, che consiste in un'applicazione della discesa del gradiente, essendo il contributo di ciascun parametro all'errore del modello dato dalla derivata parziale della funzione di perdita rispetto al parametro stesso.\nLa regola, classificabile fra i metodi per l'apprendimento supervisionato, pu\u00f2 essere applicata a reti neurali di tipo \"in avanti\" (cio\u00e8 con propagazione unidirezionale dei segnali, in inglese: \"feedforward\") e permette di calcolare la differenza tra i valori di output che la rete ottiene e quelli che invece dovrebbe apprendere. La regola deve essere applicata a reti che usano unit\u00e0 di output ad attivazione continua e differenziabile ed \u00e8 l'elemento fondamentale dell'algoritmo di retropropagazione dell'errore (\"backpropagation\"), alla base dell'approccio connessionista.\nData una rete \"in avanti\" con le propriet\u00e0 sopra descritte, l'obiettivo che ci si prefigge \u00e8 minimizzare la diversit\u00e0 tra i valori di attivazione delle unit\u00e0 di output formula_62 della rete (ottenuti sommando i segnali provenienti dalle diverse unit\u00e0 di input formula_63 moltiplicati per l'efficacia, o \"pesi sinaptici\" formula_64 delle connessioni in ingresso), e i valori formula_65 della risposta desiderata. Tale diversit\u00e0 viene quantificata attraverso una funzione di perdita. La funzione obiettivo che si vuole minimizzare \u00e8 il valore atteso della perdita (in pratica la perdita media sui dati).\nPer applicare il metodo del gradiente, la funzione di perdita deve essere derivabile rispetto ai valori di output formula_62. Una scelta adatta a problemi di regressione \u00e8 lo scarto quadratico medio tra formula_62 e formula_65 (valutato per tutte le unit\u00e0 di output e per tutti i pattern d'apprendimento); per problemi di classificazione si pu\u00f2 utilizzare la divergenza di Kullback-Leibler o equivalentemente l'entropia incrociata.\nNella fase di addestramento, variando i pesi sinaptici formula_64 (parametri del modello) si pu\u00f2 aumentare o diminuire la funzione obiettivo; la \"prestazione\" della rete sar\u00e0 funzione delle variabili formula_64, e sar\u00e0 massima quando si raggiunge il minimo della funzione obiettivo, il che si ottiene applicando il metodo del gradiente e aggiornando iterativamente i valori dei pesi sinaptici.\nPoich\u00e9 nelle applicazioni pratiche le dimensioni dei modelli e dei relativi dataset usati nell'addestramento sono molto grandi, in pratica si fa generalmente uso della discesa stocastica del gradiente per l'addestramento delle reti neurali e di altri modelli statistici e di apprendimento automatico."], "concept_A": "Discesa del gradiente", "wikipedia_passage_concept_B": ["5960768", "Rete neurale feed-forward", "Una rete neurale feed-forward (\"rete neurale con flusso in avanti\") o rete feed-forward \u00e8 una rete neurale artificiale dove le connessioni tra le unit\u00e0 non formano cicli, differenziandosi dalle reti neurali ricorrenti. Questo tipo di rete neurale fu la prima e pi\u00f9 semplice tra quelle messe a punto. In questa rete neurale le informazioni si muovono solo in una direzione, avanti, rispetto a nodi d'ingresso, attraverso nodi nascosti (se esistenti) fino ai nodi d'uscita. Nella rete non ci sono cicli. Le reti feed-forward non hanno memoria di input avvenuti a tempi precedenti, per cui l'output \u00e8 determinato solamente dall'attuale input.\nLa pi\u00f9 semplice rete feed-forward \u00e8 il \"percettrone a singolo strato\" (SLP dall'inglese single layer perceptron), utilizzato verso la fine degli anni '60. Un SLP \u00e8 costituito da un strato in ingresso, seguito direttamente dall'uscita. Ogni unit\u00e0 di ingresso \u00e8 collegata ad ogni unit\u00e0 di uscita. In pratica questo tipo di rete neurale ha un solo strato che effettua l'elaborazione dei dati, e non presenta nodi nascosti, da cui il nome.\nGli SLP sono molto limitati a causa del piccolo numero di connessioni e dell'assenza di gerarchia nelle caratteristiche che la rete pu\u00f2 estrarre dai dati (questo significa che \u00e8 capace di combinare i dati in ingresso una sola volta). Famosa fu la dimostrazione che un SLP non riesce neanche a rappresentare la funzione XOR. Questo risultato, apparso nel 1969, scoraggi\u00f2 i ricercatori e blocc\u00f2 la ricerca sulle reti neurali per diversi anni.\nQuesta classe di reti feedforward si distingue dalla precedente dal fatto che tra lo strato di input e quello di output abbiamo uno o pi\u00f9 strati di neuroni nascosti (hidden layers). Ogni strato ha connessioni entranti dal precedente strato e uscenti in quello successivo, quindi la propagazione del segnale avviene in avanti senza cicli e senza connessioni trasversali.\nQuesto tipo di architettura fornisce alla rete una prospettiva globale in quanto aumentano le interazioni tra neuroni."], "concept_B": "Rete neurale feed-forward", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["2354612", "Clustering gerarchico", "In statistica e apprendimento automatico, il clustering gerarchico \u00e8 un approccio di clustering che mira a costruire una gerarchia di cluster. Le strategie per il clustering gerarchico sono tipicamente di due tipi:\nIl risultato di un clustering gerarchico \u00e8 rappresentato in un dendrogramma.\nPer decidere quali cluster devono essere combinati (approccio agglomerativo) o quale cluster deve essere suddiviso (approccio divisivo) \u00e8 necessario definire una misura di dissimilarit\u00e0 tra cluster. Nella maggior parte dei metodi di clustering gerarchico si fa uso di metriche specifiche che quantificano la distanza tra coppie di elementi e di un criterio di collegamento che specifica la dissimilarit\u00e0 di due insiemi di elementi (cluster) come funzione della distanza a coppie tra elementi nei due insiemi.\nLa scelta di una metrica appropriata influenza la forma dei cluster, poich\u00e9 alcuni elementi possono essere pi\u00f9 \"vicini\" utilizzando una distanza e pi\u00f9 \"lontani\" utilizzandone un'altra. Per esempio, in uno spazio a 2 dimensioni, la distanza tra il punto (1, 1) e l'origine (0, 0) \u00e8 2, formula_1 or 1 se si utilizzando rispettivamente le norme 1, 2 o infinito.\nMetriche comuni sono le seguenti:\nIl criterio di collegamento (\"linkage criterion\") specifica la distanza tra insiemi di elementi come funzione di distanze tra gli elementi negli insiemi.\nDati due insiemi di elementi \"A\" e \"B\" alcuni criteri comunemente utilizzati sono:\ndove \"d\" \u00e8 la metrica prescelta per determinare la similarit\u00e0 tra coppie di elementi."], "concept_A": "Clustering gerarchico", "wikipedia_passage_concept_B": ["91024", "Data mining", "Il data mining (letteralmente dall'inglese \"estrazione di dati\") \u00e8 l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di informazioni utili da grandi quantit\u00e0 di dati (es. database, datawarehouse ecc...), attraverso metodi automatici o semi-automatici (es. machine learning) e l'utilizzo scientifico, aziendale/industriale o operativo delle stesse.\nLa statistica pu\u00f2 essere definita altrimenti come \"\"estrazione di informazione utile da insiemi di dati\"\".\nIl concetto di \"data mining\" \u00e8 simile, ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite), mentre il \"data mining \"viene utilizzato per cercare correlazioni tra pi\u00f9 variabili relativamente ai singoli individui; ad esempio conoscendo il comportamento medio dei clienti di una compagnia telefonica cerco di prevedere quanto spender\u00e0 il cliente medio nell'immediato futuro.\nIn sostanza il data mining \u00e8 \"\"l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni\"\", preceduta tipicamente da altre fasi di preparazione/trasformazione/filtraggio dei dati come il data cleaning. Il termine \"data mining\" \u00e8 diventato popolare nei tardi anni novanta come versione abbreviata della definizione appena esposta; oggi il \"data mining\" ha una duplice valenza:\nIn entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato pu\u00f2 essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare.\nQuesto tipo di attivit\u00e0 \u00e8 cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale \u00e8 utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web.\nI fattori principali che hanno contribuito allo sviluppo del data mining sono:\nLe tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati.\nUn concetto correlato al data mining \u00e8 quello di apprendimento automatico (\"Machine learning\"); infatti, l'identificazione di pattern pu\u00f2 paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining \u00e8 sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti.\nTra le tecniche maggiormente utilizzate in questo ambito vi sono:\nUn'altra tecnica molto diffusa per il data mining \u00e8 l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto \"con supervisione\" (\"supervised\"), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti \"training examples\", ovvero \"esempi per l'addestramento\". La conoscenza acquisita per apprendimento mediante classificazione pu\u00f2 essere rappresentata con un albero di decisione.\nL'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cos\u00ec acquisita.\nVi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi.\nChe cosa \"\u00e8\" \"data mining\"?\nChe cosa \"non \u00e8\" \"data mining\"?\n\u00c8 una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti \"destrutturati\". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo \u00e8 sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti.\nHa avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilit\u00e0 di applicazioni complesse attraverso gli \"Application service provider\" (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.\nUna delle evoluzioni pi\u00f9 recenti del data mining \u00e8 la \"data visualisation\". Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo, ma entra in relazione pi\u00f9 diretta con la strutturazione dei database e l'esportazione di grafici dai dati.\nUn'altra nuova frontiera \u00e8 il \u00absocial data mining\u00bb: l'analisi di informazioni generate dalle reti sociali online, come ad esempio l'analisi del sentiment.\nL'utilizzo del data mining nella ricerca di mercato \u00e8 volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining \u00e8 considerato parte del processo che porta alla creazione di un data warehouse. \u00c8 efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinch\u00e9 l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere:\nIn questo contesto, un pattern (schema) non \u00e8 altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneit\u00e0, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (\"query\") selettiva ad un data warehouse di probabili compratori pu\u00f2 essere usata per generare un elenco di indirizzi promozionali.\nL'esempio classico spesso usato nei corsi universitari \u00e8 quello di una catena non meglio specificata di supermercati (probabilmente statunitense) che avrebbe scoperto, analizzando gli scontrini, qualcosa altrimenti difficilmente immaginabile: le persone che acquistavano pannolini spesso compravano pi\u00f9 birra degli altri, per cui mettendo la birra pi\u00f9 costosa non lontano dai pannolini, poteva incrementarne le vendite. Infatti quelle persone che avevano figli piccoli passavano pi\u00f9 serate in casa a guardare la TV bevendo birra in casa non potendo uscire con gli amici. \u00c8 doveroso tuttavia precisare che non \u00e8 chiaro quale sia la catena di supermercati in questione, e l'esempio, seppur ottimo per scopi didattici e largamente utilizzato anche in ambito giornalistico, potrebbe essere stato inventato cos\u00ec come potrebbe essere vero."], "concept_B": "Data mining", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_A": "Outlier", "wikipedia_passage_concept_B": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_B": "Clustering", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["5960768", "Rete neurale feed-forward", "Una rete neurale feed-forward (\"rete neurale con flusso in avanti\") o rete feed-forward \u00e8 una rete neurale artificiale dove le connessioni tra le unit\u00e0 non formano cicli, differenziandosi dalle reti neurali ricorrenti. Questo tipo di rete neurale fu la prima e pi\u00f9 semplice tra quelle messe a punto. In questa rete neurale le informazioni si muovono solo in una direzione, avanti, rispetto a nodi d'ingresso, attraverso nodi nascosti (se esistenti) fino ai nodi d'uscita. Nella rete non ci sono cicli. Le reti feed-forward non hanno memoria di input avvenuti a tempi precedenti, per cui l'output \u00e8 determinato solamente dall'attuale input.\nLa pi\u00f9 semplice rete feed-forward \u00e8 il \"percettrone a singolo strato\" (SLP dall'inglese single layer perceptron), utilizzato verso la fine degli anni '60. Un SLP \u00e8 costituito da un strato in ingresso, seguito direttamente dall'uscita. Ogni unit\u00e0 di ingresso \u00e8 collegata ad ogni unit\u00e0 di uscita. In pratica questo tipo di rete neurale ha un solo strato che effettua l'elaborazione dei dati, e non presenta nodi nascosti, da cui il nome.\nGli SLP sono molto limitati a causa del piccolo numero di connessioni e dell'assenza di gerarchia nelle caratteristiche che la rete pu\u00f2 estrarre dai dati (questo significa che \u00e8 capace di combinare i dati in ingresso una sola volta). Famosa fu la dimostrazione che un SLP non riesce neanche a rappresentare la funzione XOR. Questo risultato, apparso nel 1969, scoraggi\u00f2 i ricercatori e blocc\u00f2 la ricerca sulle reti neurali per diversi anni.\nQuesta classe di reti feedforward si distingue dalla precedente dal fatto che tra lo strato di input e quello di output abbiamo uno o pi\u00f9 strati di neuroni nascosti (hidden layers). Ogni strato ha connessioni entranti dal precedente strato e uscenti in quello successivo, quindi la propagazione del segnale avviene in avanti senza cicli e senza connessioni trasversali.\nQuesto tipo di architettura fornisce alla rete una prospettiva globale in quanto aumentano le interazioni tra neuroni."], "concept_A": "Rete neurale feed-forward", "wikipedia_passage_concept_B": ["5960762", "Retropropagazione dell'errore", "La retropropagazione dell'errore (in lingua inglese \"backward propagation of errors\", solitamente abbreviato in backpropagation), \u00e8 un algoritmo per l'allenamento delle reti neurali artificiali, usato in combinazione con un metodo di ottimizzazione come per esempio la discesa stocastica del gradiente.\nLa retropropagazione richiede un'uscita desiderata per ogni valore in ingresso per poter calcolare il gradiente della funzione di perdita (funzione di costo). Viene considerato quindi un metodo di apprendimento supervisionato, sebbene venga usato anche in reti non supervisionate come gli autocodificatori o Reti Diabolo.\n\u00c8 una generalizzazione della regola delta di reti feed-forward multistrato, resa possibile usando la regola di catena che iterativamente calcola i gradienti per ogni strato.\nLa retropropagazione richiede che la funzione d'attivazione usata dai neuroni artificiali (o \"nodi\") sia differenziabile.\nUna delle principali difficolt\u00e0 nell'uso della retropropagazione dell'errore \u00e8 il problema noto come scomparsa del gradiente, dovuto all'uso di funzioni di attivazione non lineari che causano una diminuzione esponenziale del valore del gradiente all'aumentare della profondit\u00e0 della rete neurale."], "concept_B": "Retropropagazione dell'errore", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["6539843", "Boosting", "Il boosting \u00e8 una tecnica di machine learning che rientra nella categoria dell'Apprendimento ensemble. Nel boosting pi\u00f9 modelli vengono generati consecutivamente dando sempre pi\u00f9 peso agli errori effettuati nei modelli precedenti. In questo modo si creano modelli via via pi\u00f9 \"attenti\" agli aspetti che hanno causato inesattezze nei modelli precedenti, ottenendo infine un modello aggregato avente migliore accuratezza di ciascun modello che lo costituisce.\nIn algoritmi come Adaboost, l'output del meta-classificatore \u00e8 dato dalla somma pesata delle predizioni dei singoli modelli. Ogni qual volta un modello viene addestrato, ci sar\u00e0 una fase di ripesaggio delle istanze. L'algoritmo di boosting tender\u00e0 a dare un peso maggiore alle istanze misclassificate, nella speranza che il successivo modello sia pi\u00f9 esperto su quest'ultime.\nIn generale si ha che l'errore di predizione in un problema di apprendimento supervisionato \u00e8 dato da:\nformula_1\nIl boosting mira a ridurre la varianza."], "concept_A": "Boosting", "wikipedia_passage_concept_B": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_B": "Foresta casuale", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["434228", "Information retrieval", "L'information retrieval (IR) (in italiano \"recupero delle informazioni\") \u00e8 l'insieme delle tecniche utilizzate per gestire la rappresentazione, la memorizzazione, l'organizzazione e l'accesso ad oggetti contenenti informazioni quali documenti, pagine web, cataloghi online e oggetti multimediali. Il termine \u00e8 stato coniato da Calvin Mooers alla fine degli anni quaranta del Novecento ed oggi \u00e8 usato quasi esclusivamente in ambito informatico.\nL'information retrieval \u00e8 un campo interdisciplinare che nasce dall'incrocio di discipline diverse coinvolgendo la psicologia cognitiva, l'architettura informativa, la filosofia (vedi la voce ontologia), il \"design\", il comportamento umano sull'informazione, la linguistica, la semiotica, la scienza dell'informazione e l'informatica. Molte universit\u00e0 e biblioteche pubbliche utilizzano sistemi di information retrieval per fornire accesso a pubblicazioni, libri ed altri documenti.\nLo scopo dell'information retrieval \u00e8 di soddisfare il cosiddetto \"bisogno informativo dell'utente\", ovvero garantire a quest'ultimo, in seguito ad una sua ricerca, i documenti e le informazioni che rispondono alla sua richiesta.\nDue concetti sono di fondamentale importanza per analizzare un sistema di information retrieval: query ed oggetto.\nComunemente, si definisce \"task\" di un sistema di \"information retrieval\" una situazione tipica che un sistema di questo genere deve risolvere.\nNel momento in cui un utente intende usare un qualsiasi sistema di reperimento dell'informazione (per esempio, un motore di ricerca) per acquisire informazioni su un determinato argomento, questi deve tradurre tale necessit\u00e0 in una query; il sistema di information retrieval ha il compito di restituire, a partire da essa, tutti i documenti rilevanti alla richiesta effettuata.\nCi sono molti modi per misurare quanto l'informazione intesa si associa bene all'informazione recuperata.\nLa precisione (in inglese \"precision\") \u00e8 la proporzione di documenti pertinenti fra quelli recuperati:\nNella classificazione binaria la precisione \u00e8 analoga al valore positivo di previsione. \nLa precisione pu\u00f2 anche essere valutata rispetto a un certo valore soglia, indicato con \"P@n\", piuttosto che relativamente a tutti i documenti recuperati: in questo modo, si pu\u00f2 valutare quanti fra i primi \"n\" documenti recuperati sono rilevanti per la query.\nIl significato e l'uso del termine \"precisione\" nel campo dell'information retrieval differiscono quindi dalla definizione di accuratezza e precisione tipiche di altre discipline scientifiche e tecnologiche.\nIl recupero o richiamo (in inglese \"recall\") \u00e8 la proporzione fra il numero di documenti rilevanti recuperati e il numero di tutti i documenti rilevanti disponibili nella collezione considerata:\nNella classificazione binaria, questo valore \u00e8 chiamato sensitivit\u00e0.\nLa misura F (in inglese \"F-measure\") \u00e8 la media armonica pesata fra precisione e recupero. La versione tradizionale, detta anche \"bilanciata\", \u00e8 data da:\nQuesta misura \u00e8 anche detta formula_2, perch\u00e9 sia la precisione che il recupero nella formula precedente hanno appunto il peso 1.\nIn generale, la formula \u00e8:\nAltre due formule comuni sono formula_4, che assegna alla precisione un peso doppio rispetto al recupero, e la formula_5, che al contrario pesa il recupero al doppio della precisione.\nPer concludere con successo una ricerca di informazioni, \u00e8 necessario rappresentare i documenti in qualche modo. C'\u00e8 un certo numero di modelli aventi tale scopo. Essi possono essere classificati secondo due criteri, come mostrato nella figura a destra: in base ad un criterio matematico e in base alle propriet\u00e0 del modello (tradotto da fonte originale logos-verlag.de).\nSistemi di Information Retrieval in campo scientifico\nSoftware di Information Retrieval Open Source\nPrincipali gruppi di ricerca sull'Information Retrieval\nApprofondimenti"], "concept_A": "Information retrieval", "wikipedia_passage_concept_B": ["19781", "Clustering", "In statistica, il clustering o analisi dei gruppi (dal termine inglese \"cluster analysis\" introdotto da Robert Tryon nel 1939) \u00e8 un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati. Le tecniche di \"clustering\" si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarit\u00e0, o meglio, dissimilarit\u00e0, \u00e8 concepita in termini di distanza in uno spazio multidimensionale. La bont\u00e0 delle analisi ottenute dagli algoritmi di \"clustering\" dipende molto dalla scelta della metrica, e quindi da come \u00e8 calcolata la distanza. Gli algoritmi di \"clustering\" raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame \u00e8 distante dall'insieme stesso.\nLe tecniche di \"clustering\" si possono basare principalmente su due \"filosofie\":\nEsistono varie classificazioni delle tecniche di clustering comunemente utilizzate. Una prima categorizzazione dipende dalla possibilit\u00e0 che un elemento possa o meno essere assegnato a pi\u00f9 cluster:\nUn'altra suddivisione delle tecniche di clustering tiene conto del tipo di algoritmo utilizzato per dividere lo spazio:\nQueste due suddivisioni sono del tutto trasversali, e molti algoritmi nati come \"esclusivi\" sono stati in seguito adattati nel caso \"non-esclusivo\" e viceversa.\nGli algoritmi di clustering di questa famiglia creano una partizione delle osservazioni minimizzando una certa funzione di costo:\ndove formula_2 \u00e8 il numero dei cluster, formula_3 \u00e8 il formula_4-esimo cluster e formula_5 \u00e8 la funzione di costo associata al singolo cluster. L'algoritmo pi\u00f9 famoso appartenente a questa famiglia \u00e8 il k-means, proposto da MacQueen nel 1967. Un altro algoritmo abbastanza conosciuto appartenente a questa classe \u00e8 il Partitioning Around Medioid (PAM).\nLe tecniche di clustering gerarchico non producono un partizionamento \"flat\" dei punti, ma una rappresentazione gerarchica ad albero. \nQuesti algoritmi sono a loro volta suddivisi in due classi:\nUna rappresentazione grafica del processo di clustering \u00e8 fornita dal dendrogramma.\nIn entrambi i tipi di clustering gerarchico sono necessarie funzioni per selezionare la coppia di cluster da fondere (\"agglomerativo\"), oppure il cluster da dividere (\"divisivo\").\nNel primo caso, sono necessarie funzioni che misurino la \"similarit\u00e0\" (o, indistintamente, la \"distanza\") tra due cluster, in modo da fondere quelli pi\u00f9 simili. Le funzioni utilizzate nel caso agglomerativo sono:\nNei 4 casi precedenti, formula_10 indica una qualsiasi funzione distanza su uno spazio metrico.\nInvece nel clustering divisivo \u00e8 necessario individuare il cluster da suddividere in due sottogruppi. Per questa ragione sono necessarie funzioni che misurino la compattezza del cluster, la densit\u00e0 o la sparsit\u00e0 dei punti assegnati ad un cluster. Le funzioni normalmente utilizzate nel caso divisivo sono:\nNel \"Clustering density-based\", il raggruppamento avviene analizzando l'intorno di ogni punto dello spazio. In particolare, viene considerata la densit\u00e0 di punti in un intorno di raggio fissato.\nUn esempio \u00e8 il metodo di clustering Dbscan.\nAlgoritmi di clustering molto usati sono:\nIl QT (\"Quality Threshold\") Clustering (Heyer et al., 1999) \u00e8 un metodo alternativo di partizionare i dati, inventato per il clustering dei geni. Richiede pi\u00f9 potenza di calcolo rispetto al \"K\"-Means, ma non richiede di specificare il numero di cluster \"a priori\", e restituisce sempre lo stesso risultato quando si ripete diverse volte.\nL'algoritmo \u00e8:\nLa distanza tra un punto ed un gruppo di punti \u00e8 calcolata usando il concatenamento completo, cio\u00e8 come la massima distanza dal punto di ciascun membro del gruppo (vedi il \"Clustering gerarchico agglomerativo\" sulla distanza tra i cluster nella sezione clustering gerarchico)."], "concept_B": "Clustering", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["1555", "Scarto quadratico medio", "Lo scarto quadratico medio (o deviazione standard o scarto tipo) \u00e8 un indice di dispersione statistico, vale a dire una stima della variabilit\u00e0 di una popolazione di dati o di una variabile casuale.\n\u00c8 uno dei modi per esprimere la dispersione dei dati intorno ad un indice di posizione, quale pu\u00f2 essere, ad esempio, la media aritmetica o una sua stima. Ha pertanto la stessa unit\u00e0 di misura dei valori osservati (al contrario della varianza che ha come unit\u00e0 di misura il quadrato dell'unit\u00e0 di misura dei valori di riferimento). In statistica la precisione si pu\u00f2 esprimere come lo scarto quadratico medio.\nIl termine \"\"standard deviation\"\" \u00e8 stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca formula_1 (sigma) che lo rappresenta. Il termine italiano \"deviazione standard\" ne \u00e8 la traduzione pi\u00f9 utilizzata nel linguaggio comune; il termine dell'Ente Nazionale Italiano di Unificazione \u00e8 tuttavia \"scarto tipo\", definito come la radice quadrata positiva della varianza per lo meno fin dal 1984.\nSe non indicato diversamente, lo scarto quadratico medio \u00e8 la radice quadrata della varianza, la quale viene coerentemente rappresentata con il quadrato di sigma (formula_2).\nIn statistica lo scarto quadratico medio di un carattere rilevato su una popolazione di formula_3 unit\u00e0 statistiche si definisce esplicitamente come:\ndove formula_5 \u00e8 la media aritmetica di formula_6.\nFormalmente lo scarto quadratico medio di una variabile pu\u00f2 essere calcolata a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato.\nA partire dallo scarto quadratico medio si definisce anche il coefficiente di variazione o la \"deviazione standard relativa\" come il rapporto tra lo scarto tipo formula_7 e il valore assoluto della media aritmetica della variabile in esame:\nQuesto indice relativo (che viene spesso espresso in termini percentuali) consente di effettuare confronti tra dispersioni di dati di tipo diverso, indipendentemente dalle loro quantit\u00e0 assolute.\nNell'ambito della statistica inferenziale (dove \u00e8 noto solo un campione della popolazione), soprattutto nell'ambito della teoria della stima, a volte si rimpiazza il denominatore formula_3 con formula_10 ottenendo:\nSostanzialmente, poich\u00e9 non \u00e8 nota la media dell'intera popolazione, ma solo una sua stima (la media del campione), bisogna utilizzare formula_10 per ottenere uno stimatore corretto formula_13 della varianza incognita formula_7 di formula_6 sull'intera popolazione a partire dai dati del campione. La sua radice quadrata diviene lo scarto quadratico medio \"corretto\".\nQuesta correzione al denominatore fa s\u00ec che la nuova definizione sia un po' pi\u00f9 grande della precedente, correggendo cos\u00ec la tendenza della precedente a sottostimare le incertezze soprattutto nel caso in cui si lavori con pochi dati (formula_3 piccolo).\nOsserviamo il caso limite di formula_17, cio\u00e8 quando si ha un campione di un solo elemento: la prima definizione d\u00e0 il risultato formula_18, che ovviamente non \u00e8 molto ragionevole nell'ambito della statistica inferenziale, mentre quella \"corretta\" d\u00e0 un risultato non definito del tipo formula_19, rispecchiando cos\u00ec la totale ignoranza inerente all'incertezza su una singola misura. In questo senso, si dice che la statistica non dice nulla sul singolo caso.\nOsserviamo che la differenza tra le due definizioni per campioni molto estesi \u00e8 spesso numericamente insignificante.\nIl calcolo pu\u00f2 essere semplificato come segue:\ncio\u00e8, applicando il tutto alla formula originale:\nSia formula_6 una variabile aleatoria, lo scarto quadratico medio \u00e8 definito come la radice quadrata della varianza di formula_6\nFormalmente lo scarto quadratico medio di una variabile aleatoria pu\u00f2 essere calcolato a partire dalla funzione generatrice dei momenti, in particolare \u00e8 la radice quadrata della differenza tra il momento secondo ed il momento primo elevato al quadrato, cio\u00e8\ndove formula_26 \u00e8 il valore atteso di formula_6.\nIn ambito finanziario, lo scarto quadratico medio viene usato per indicare la variabilit\u00e0 di un'attivit\u00e0 finanziaria e dei suoi payoff (rendimenti). Esso fornisce quindi, implicitamente, una misura della volatilit\u00e0 dell'attivit\u00e0, quindi del suo rischio.\nIn fisica, \u00e8 un ottimo indice dell'errore casuale della misurazione di una grandezza fisica.\nIn ambito sportivo \u00e8 utilizzato per valutare la prestazione di un giocatore di bowling in riferimento ad un certo numero di partite. Il valore trovato non incide sul punteggio ma sintetizza le capacit\u00e0 e i miglioramenti del giocatore.\nIn ingegneria, \u00e8 uno dei parametri da considerare per valutare la capacit\u00e0 di un processo produttivo.\nNelle applicazioni informatiche, \u00e8 a volte conveniente utilizzare la formula\nche consente, con sole tre variabili formula_29, di calcolare lo scarto quadratico medio, oltre che la media, di un flusso di numeri di lunghezza formula_3 senza dover ricorrere ad una memorizzazione degli stessi."], "concept_A": "Scarto quadratico medio", "wikipedia_passage_concept_B": ["4302983", "Foresta casuale", "Una foresta casuale (in inglese: \"random forest\") \u00e8 un classificatore d'insieme ottenuto dall'aggregazione tramite bagging di alberi di decisione\nL'algoritmo per la creazione di una una foresta casuale fu sviluppato orignariamente da Leo Breiman e Adele Cutler.\nIl nome viene dalle foreste di decisione casuali che furono proposte per primo da Tin Kam Ho dei Bell Labs nel 1995.\nIl metodo combina l'idea dell'insaccamento di Breiman della selezione casuale delle caratteristiche, introdotta indipendentemente da Ho e Amit Geman per costruire una collezione di alberi di decisione con la variazione controllata.\nLa selezione di un sottoinsieme di caratteristiche \u00e8 un esempio del metodo del sottoinsieme casuale che, nella formulazione di Ho, \u00e8 un modo di implementare la discriminazione stocastica proposta da Eugene Kleinberg."], "concept_B": "Foresta casuale", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["599528", "K-means", "L'algoritmo K-means \u00e8 un algoritmo di clustering partizionale che permette di suddividere un insieme di oggetti in K gruppi sulla base dei loro attributi. \u00c8 una variante dell'algoritmo di aspettativa-massimizzazione (EM) il cui obiettivo \u00e8 determinare i K gruppi di dati generati da distribuzioni gaussiane. Si assume che gli attributi degli oggetti possano essere rappresentati come vettori, e che quindi formino uno spazio vettoriale.\nL'obiettivo che l'algoritmo si prepone \u00e8 di minimizzare la varianza totale intra-cluster. Ogni cluster viene identificato mediante un centroide o punto medio. L'algoritmo segue una procedura iterativa. Inizialmente crea K partizioni e assegna ad ogni partizione i punti d'ingresso o casualmente o usando alcune informazioni euristiche. Quindi calcola il centroide di ogni gruppo. Costruisce quindi una nuova partizione associando ogni punto d'ingresso al cluster il cui centroide \u00e8 pi\u00f9 vicino ad esso. Quindi vengono ricalcolati i centroidi per i nuovi cluster e cos\u00ec via, finch\u00e9 l'algoritmo non converge.\nDati N oggetti con formula_1 attributi, modellizzati come vettori in uno spazio vettoriale formula_1-dimensionale, definiamo formula_3 come insieme degli oggetti. Ricordiamo che si definisce partizione degli oggetti il gruppo di insiemi formula_4 che soddisfano le seguenti propriet\u00e0:\nOvviamente deve valere anche che formula_8; non avrebbe infatti senso n\u00e9 cercare un solo cluster n\u00e9 avere un numero di cluster pari al numero di oggetti.\nUna partizione viene rappresentata mediante una matrice formula_9, il cui generico elemento formula_10 indica l'appartenenza dell'oggetto formula_11 al cluster formula_1.\nIndichiamo quindi con formula_13 l'insieme dei formula_14 centroidi.\nA questo punto definiamo la funzione obiettivo come:\ne di questa calcoliamo il minimo seguendo la procedura iterativa vista sopra:\nTipici criteri di convergenza sono i seguenti:\nL'algoritmo ha acquistato notoriet\u00e0 dato che converge molto velocemente. Infatti, si \u00e8 osservato che generalmente il numero di iterazioni \u00e8 minore del numero di punti. Comunque, l'algoritmo pu\u00f2 essere molto lento nel caso peggiore: D. Arthur e S. Vassilvitskii hanno mostrato che esistono certi insiemi di punti per i quali l'algoritmo impiega un tempo superpolinomiale, formula_24, a convergere. Pi\u00f9 recentemente, A. Vattani ha migliorato questo risultato mostrando che l'algoritmo pu\u00f2 impiegare tempo esponenziale, formula_25, a convergere anche per certi insiemi di punti sul piano. D'altra parte, D. Arthur, B. Manthey e H. Roeglin hanno mostrato che la smoothed complexity dell'algoritmo \u00e8 polinomiale, la qual cosa \u00e8 a supporto del fatto che l'algoritmo \u00e8 veloce in pratica.\nIn termini di qualit\u00e0 delle soluzioni, l'algoritmo non garantisce il raggiungimento dell'ottimo globale. La qualit\u00e0 della soluzione finale dipende largamente dal set di cluster iniziale e pu\u00f2, in pratica, ottenere una soluzione ben peggiore dell'ottimo globale. Dato che l'algoritmo \u00e8 di solito estremamente veloce, \u00e8 possibile applicarlo pi\u00f9 volte e fra le soluzioni prodotte scegliere quella pi\u00f9 soddisfacente.\nUn altro svantaggio dell'algoritmo \u00e8 che esso richiede di scegliere il numero di cluster(k) da trovare. Se i dati non sono naturalmente partizionati si ottengono risultati strani. Inoltre l'algoritmo funziona bene solo quando sono individuabili cluster sferici nei dati.\n\u00c8 possibile applicare l'algoritmo K-means in Matlab utilizzando la funzione kmeans(DATA, N_CLUSTER), che individua N_CLUSTER numeri di cluster nel data set DATA. Il seguente m-file mostra una possibile applicazione dell'algoritmo per la clusterizzazione di immagini basata sui colori.\n\"img_segm.m\"\nLa funzione legge l'immagine utilizzando la funzione Matlab imread, che riceve in ingresso il nome del file contenente l'immagine e restituisce una matrice il cui elemento formula_26 contiene il codice di colore del pixel i,j. Successivamente costruisce la matrice delle osservazioni con due semplici cicli for. Viene infine passata in ingresso all'algoritmo di clustering la matrice delle osservazioni e, dopo aver generato le matrici utili per visualizzare i cluster prodotti in un'immagine, queste vengono mostrate a video con la funzione image.\nAd esempio, eseguendo il comando:\nimg_segm('kmeans0.jpg',2);\nsi ottiene il seguente risultato:"], "concept_A": "K-means", "wikipedia_passage_concept_B": ["1103542", "K-medoids", "\u00e8 un algoritmo di clustering partizionale correlato all'algoritmo K-means. Prevede in input un insieme di n oggetti e un numero k che determina quanti cluster si vogliono in output.\nEntrambi gli algoritmi sono partizionali (suddividendo il dataset in gruppi) ed entrambi cercano di minimizzare l'errore quadratico medio, la distanza tra punti di un cluster e il punto designato per esserne il centro. In K-means il punto \u00e8 \"artificiale\" \u2014 \u00e8 la pura media di tutti i punti nel cluster. Nel K-medoids \u00e8 usato il punto collocato pi\u00f9 centralmente, in questo modo il centro \u00e8 uno dei datapoint attuali. K-medoids \u00e8 pi\u00f9 robusto al rumore e agli outlier rispetto al k-means.\nUn medoid pu\u00f2 essere definito come un oggetto di un cluster la cui dissimilarit\u00e0 media rispetto a tutti gli oggetti nel cluster \u00e8 minima, in questo modo esso sar\u00e0 il punto pi\u00f9 centrale di un dato dataset.\nL'algoritmo di clustering \u00e8 il seguente:\nSi deve clusterizzare il seguente data set di 10 oggetti in 2 cluster, quindi n \u00e8 10 e k \u00e8 2:\nSi inizializzano i k centri.\nAssumiamo che C1=(3,4) e C2=(7,4) siano i nostri medoid iniziali.\nCalcoliamo la distanza cos\u00ec da associare ogni data object al suo medoid pi\u00f9 vicino.\nIniziamo quindi il clustering:\nEssendo (3,4) (2,6) (3,8) e (4,7) punti vicini a c1 essi formeranno un cluster mentre i punti rimanenti ne formeranno un altro.\nIl costo totale sar\u00e0 20.\nIl costo tra 2 punti qualsiasi \u00e8 trovato usando la formula\nformula_1\nIl costo totale \u00e8 la somma dei costi per gli oggetti dal proprio medoid.\nCosto totale= {cost((3,4),(2,6)) + cost((3,4),(3,8)) + cost((3,4),(4,7))} + {cost((7,4),(6,2)) + cost((7,4),(6,4)) + cost((7,4),(7,3)) + cost((7,4),(8,5)) + cost((7,4),(7,6))} = 3 + 4 + 4 + 3 + 1 + 1 + 2 + 2 = 20\nSelezione di un nonmedoid O' in modo casuale.\nAssumiamo O'=(7,3)\nI medoid sono quindi c1(3,4) e O'(7,3).\nSe c1 e O' sono nuovi medoid, si calcola il costo totale usando la formula al passo 1.\nCosto totale = 3 + 4 + 4 + 2 + 2 + 1 + 3 + 3 = 22\nCos\u00ec il costo per cambiare il medoid da c2 a O' sar\u00e0:\nS = Costo totale attuale \u2013 Costo totale precedente = 22 - 20 = 2 > 0\nQuindi cambiare medoid in O' non \u00e8 una buona idea, la scelta precedente \u00e8 stata buona e l'algoritmo termina in questo punto (in quanto non ci sono cambiamenti per i medoid).\nPu\u00f2 accadere che qualche data point possa migrare da un cluster ad un altro, ci\u00f2 dipende dalla vicinanza rispetto al nuovo medoid scelto."], "concept_B": "K-medoids", "choices": ["False", "True"], "label": 0}
{"wikipedia_passage_concept_A": ["1745121", "Outlier", "\u00e8 un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante. Un valore quindi chiaramente distante dalle altre osservazioni disponibili.\nIn statistica viene definito outlier un valore al di fuori dall'intervallo:\nDove formula_2 e formula_3 sono rispettivamente primo e terzo quartile. formula_4 \u00e8 una costante che regola l'ampiezza dell'intervallo. Normalmente assume il valore unitario.\nGli outlier sono valori numericamente distanti dal resto dei dati raccolti (ad esempio, in un campionamento). Le statistiche che derivano da campioni contenenti outlier possono essere fuorvianti. Per esempio, se misurassimo la temperatura di dieci oggetti presenti in una stanza, la maggior parte dei quali risultasse avere una temperatura compresa fra 20 e 25 gradi Celsius, allora il forno acceso, avente una temperatura di 350 gradi, sarebbe un dato aberrante. La mediana dei valori sarebbe circa 23, mentre la temperatura media salirebbe a circa 55 gradi: un indice chiaramente non rappresentativo della maggioranza dei valori di temperatura riscontrati nella stanza. In questo caso, la mediana rifletterebbe meglio della media aritmetica le misure della temperatura degli oggetti. Gli outliers possono essere indicativi del fatto che, in un dato campione, alcuni dati appartengono ad una popolazione differente rispetto a quella del resto del campione.\nNella maggioranza dei grandi campioni, alcuni dati saranno pi\u00f9 lontani dalla media del campione di quanto sarebbe logico aspettarsi. Ci\u00f2 pu\u00f2 essere dovuto ad un errore sistematico che si \u00e8 verificato nella raccolta dei dati, oppure a una fallacia nella teoria che ha orientato l'assunzione di una data distribuzione campionaria di probabilit\u00e0, ma potrebbe anche essere semplicemente dovuto al caso, che ha fatto s\u00ec che nella raccolta dei dati alcune osservazioni abbiano prodotto dati molto lontani dai valori medi del campione. Inoltre, gli outliers potrebbero essere indicativi di dati errati, procedure erronee o aree sperimentali in cui alcune teorie potrebbero non essere valide. Tuttavia, un piccolo numero di dati aberranti non dovuti a condizioni anomale \u00e8 dato per scontato nei grandi campioni.\nStimatori poco influenzati dai dati aberranti sono detti robusti."], "concept_A": "Outlier", "wikipedia_passage_concept_B": ["3854", "Scarto interquartile", "In statistica lo scarto interquartile (o differenza interquartile o ampiezza interquartile, in inglese \"interquartile range\" o \"IQR\") \u00e8 la differenza tra il terzo e il primo quartile, ovvero l'ampiezza della fascia di valori che contiene la met\u00e0 \"centrale\" dei valori osservati.\nLo scarto interquartile \u00e8 un indice di dispersione, cio\u00e8 una misura di quanto i valori si allontanino da un valore centrale. Viene utilizzato nel disegno del diagramma box-plot.\nLo scarto interquartile di una variabile aleatoria si ottiene tramite la funzione di ripartizione, come differenza formula_1\nPer una variabile casuale normale formula_2 lo scarto interquartile \u00e8 circa formula_3.\nPer una variabile casuale di Cauchy formula_4 lo scarto interquartile \u00e8 formula_5."], "concept_B": "Scarto interquartile", "choices": ["False", "True"], "label": 0}
